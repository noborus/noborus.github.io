<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>12.6. 辞書</title><link rel="stylesheet" type="text/css" href="stylesheet.css" /><link rev="made" href="pgsql-docs@postgresql.org" /><meta name="generator" content="DocBook XSL Stylesheets V1.79.1" /><link rel="prev" href="textsearch-parsers.html" title="12.5. パーサ" /><link rel="next" href="textsearch-configuration.html" title="12.7. 設定例" /><meta name="viewport" content="width=device-width,initial-scale=1.0" /></head><body><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="4" align="center"><a accesskey="h" href="index.html">PostgreSQL 11.1文書</a></th></tr><tr><td width="10%" align="left"></td><td width="10%" align="left"></td><td width="60%" align="center"><a href="textsearch.html" title="第12章 全文検索">第12章 全文検索</a></td><td width="20%" align="right"><div class="actions"><a class="issue" title="github" href="https://github.com/pgsql-jp/jpug-doc/issues/new?title=version 11.1 &#10;                      textsearch-dictionaries.html">誤訳等の報告
                    </a></div></td></tr><tr><td width="10%" align="left"><a accesskey="p" href="textsearch-parsers.html" title="12.5. パーサ">前へ</a> </td><td width="10%" align="left"><a accesskey="u" href="textsearch.html" title="第12章 全文検索">上へ</a></td><td width="60%" align="center">12.6. 辞書</td><td width="20%" align="right"> <a accesskey="n" href="textsearch-configuration.html" title="12.7. 設定例">次へ</a></td></tr></table><hr /></div><div class="sect1" id="TEXTSEARCH-DICTIONARIES"><div class="titlepage"><div><div><h2 class="title" style="clear: both">12.6. 辞書</h2></div></div></div><span class="original">
  &lt;title&gt;Dictionaries&lt;/title&gt;
</span><p>
<span class="original">
   Dictionaries are used to eliminate words that should not be considered in a
   search (&lt;firstterm&gt;stop words&lt;/firstterm&gt;), and to &lt;firstterm&gt;normalize&lt;/firstterm&gt; words so
   that different derived forms of the same word will match.  A successfully
   normalized word is called a &lt;firstterm&gt;lexeme&lt;/firstterm&gt;.  Aside from
   improving search quality, normalization and removal of stop words reduce the
   size of the &lt;type&gt;tsvector&lt;/type&gt; representation of a document, thereby
   improving performance.  Normalization does not always have linguistic meaning
   and usually depends on application semantics.
</span>
辞書は、検索の対象とならない単語(<em class="firstterm">ストップワード</em>)を削除するために使われます。また、同じ単語から派生した異なる形態の単語が照合するようにするために、単語を<em class="firstterm">正規化</em>するためにも使われます。検索の品質を向上するという面以外にも、正規化とストップワードの削除は、<code class="type">tsvector</code>表現の文書のサイズを小さくし、結果として性能を向上させます。正規化は常に言語学的な意味を持つとは限らず、通常は用途の意味論に依存します。
  </p><p>
<span class="original">
   Some examples of normalization:
</span>
   正規化の例を示します。

   </p><div class="itemizedlist"><ul class="itemizedlist compact" style="list-style-type: bullet; "><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      Linguistic - Ispell dictionaries try to reduce input words to a
      normalized form; stemmer dictionaries remove word endings
</span>
言語学的 - Ispell辞書は入力された単語を正規化された形式に変換しようとします。語幹辞書は単語の終了部を削除します。
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      &lt;acronym&gt;URL&lt;/acronym&gt; locations can be canonicalized to make
      equivalent URLs match:
</span>
以下のような<acronym class="acronym">URL</acronym>が同一のURLに一致するように正規化することができます。

      </p><div class="itemizedlist"><ul class="itemizedlist compact" style="list-style-type: bullet; "><li class="listitem" style="list-style-type: disc"><p>
         http://www.pgsql.ru/db/mw/index.html
        </p></li><li class="listitem" style="list-style-type: disc"><p>
         http://www.pgsql.ru/db/mw/
        </p></li><li class="listitem" style="list-style-type: disc"><p>
         http://www.pgsql.ru/db/../db/mw/index.html
        </p></li></ul></div><p>
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      Color names can be replaced by their hexadecimal values, e.g.,
</span>
色の名前は、16進値に変換できます。例：
      <code class="literal">red, green, blue, magenta -&gt; FF0000, 00FF00, 0000FF, FF00FF</code>
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      If indexing numbers, we can
      remove some fractional digits to reduce the range of possible
      numbers, so for example &lt;emphasis&gt;3.14&lt;/emphasis&gt;159265359,
      &lt;emphasis&gt;3.14&lt;/emphasis&gt;15926, &lt;emphasis&gt;3.14&lt;/emphasis&gt; will be the same
      after normalization if only two digits are kept after the decimal point.
</span>
数をインデックス付けする際には、可能な範囲を縮小するために、端数を削除することができます。たとえば、もし正規化後に小数点未満2桁を保持するならば、<span class="emphasis"><em>3.14</em></span>15926, <span class="emphasis"><em>3.14</em></span>は同じことになります。
     </p></li></ul></div><p>

  </p><p>
<span class="original">
   A dictionary is a program that accepts a token as
   input and returns:
</span>
辞書は、トークンを入力し、以下を返すプログラムです。
   </p><div class="itemizedlist"><ul class="itemizedlist compact" style="list-style-type: bullet; "><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      an array of lexemes if the input token is known to the dictionary
      (notice that one token can produce more than one lexeme)
</span>
入力が辞書に登録されていれば語彙素の配列(一つのトークンが一つ以上の語彙素を生成する可能性があることに注意してください)
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      a single lexeme with the &lt;literal&gt;TSL_FILTER&lt;/literal&gt; flag set, to replace
      the original token with a new token to be passed to subsequent
      dictionaries (a dictionary that does this is called a
      &lt;firstterm&gt;filtering dictionary&lt;/firstterm&gt;)
</span>
元々のトークンを新規のトークンに置き換え、それに続く辞書にその新規トークン渡す場合は、<code class="literal">TSL_FILTER</code>フラグセットを伴う単一の語彙素(このような置き換え機能をもつ辞書は<em class="firstterm">フィルタリング辞書</em>と呼ばれます)
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      an empty array if the dictionary knows the token, but it is a stop word
</span>
辞書が入力を認識しないが、ストップワードであることは認識する場合は空の配列
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      &lt;literal&gt;NULL&lt;/literal&gt; if the dictionary does not recognize the input token
</span>
辞書が入力トークンを認識しない場合は<code class="literal">NULL</code>
     </p></li></ul></div><p>
  </p><p>
<span class="original">
   &lt;productname&gt;PostgreSQL&lt;/productname&gt; provides predefined dictionaries for
   many languages.  There are also several predefined templates that can be
   used to create new dictionaries with custom parameters.  Each predefined
   dictionary template is described below.  If no existing
   template is suitable, it is possible to create new ones; see the
   &lt;filename&gt;contrib/&lt;/filename&gt; area of the &lt;productname&gt;PostgreSQL&lt;/productname&gt; distribution
   for examples.
</span>
<span class="productname">PostgreSQL</span>は、多くの言語に定義済の辞書を提供しています。
また、カスタムパラメータを使った新しい辞書を作るために使えるテンプレートもいくつかあります。
定義済の辞書のテンプレートについては、以下で述べています。
今あるテンプレートが適当でないのなら、新しいものを作ることもできます。例は、<span class="productname">PostgreSQL</span>の配布物の<code class="filename">contrib/</code>をご覧下さい。
  </p><p>
<span class="original">
   A text search configuration binds a parser together with a set of
   dictionaries to process the parser's output tokens.  For each token
   type that the parser can return, a separate list of dictionaries is
   specified by the configuration.  When a token of that type is found
   by the parser, each dictionary in the list is consulted in turn,
   until some dictionary recognizes it as a known word.  If it is identified
   as a stop word, or if no dictionary recognizes the token, it will be
   discarded and not indexed or searched for.
   Normally, the first dictionary that returns a non-&lt;literal&gt;NULL&lt;/literal&gt;
   output determines the result, and any remaining dictionaries are not
   consulted; but a filtering dictionary can replace the given word
   with a modified word, which is then passed to subsequent dictionaries.
</span>
テキスト検索設定は、パーサと、パーサの出力トークンを処理する辞書の集合を結び付けます。パーサが返却する各々のトークン型に対して、設定で辞書のリストを指定します。パーサがあるトークン型を見つけると、ある辞書が単語を認識するまでリスト中の辞書が順番に調べられます。
ストップワードであるか、あるいはどの辞書もトークンを認識しない場合はそれは捨てられ、インデックス付けや検索の対象となりません。
通常、非<code class="literal">NULL</code>を返す最初の辞書の出力が結果を決めることになり、他の残りの辞書は参照されません。しかし、フィルタリング辞書は与えられたワードを変更し、それを続く辞書へ渡すことができます。
  </p><p>
<span class="original">
   The general rule for configuring a list of dictionaries
   is to place first the most narrow, most specific dictionary, then the more
   general dictionaries, finishing with a very general dictionary, like
   a &lt;application&gt;Snowball&lt;/application&gt; stemmer or &lt;literal&gt;simple&lt;/literal&gt;, which
   recognizes everything.  For example, for an astronomy-specific search
   (&lt;literal&gt;astro_en&lt;/literal&gt; configuration) one could bind token type
   &lt;type&gt;asciiword&lt;/type&gt; (ASCII word) to a synonym dictionary of astronomical
   terms, a general English dictionary and a &lt;application&gt;Snowball&lt;/application&gt; English
   stemmer:
</span>
辞書をリストする一般的な方法は、まずもっとも範囲の狭い、特定用途向の辞書を配置し、次にもっと一般的な辞書を置き、最後に<span class="application">Snowball</span>語幹処理や<code class="literal">simple</code>辞書のような、すべてを認識する非常に一般的な辞書を置くことです。
たとえば、天文学向の検索では(<code class="literal">astro_en</code>設定)では、<code class="type">asciiword</code> (ASCII単語)型を天文学用語の同義語辞書、一般的な英語辞書、そして<span class="application">Snowball</span>英語語幹辞書に結び付けることができます。

</p><pre class="programlisting">
ALTER TEXT SEARCH CONFIGURATION astro_en
    ADD MAPPING FOR asciiword WITH astrosyn, english_ispell, english_stem;
</pre><p>
  </p><p>
<span class="original">
   A filtering dictionary can be placed anywhere in the list, except at the
   end where it'd be useless.  Filtering dictionaries are useful to partially
   normalize words to simplify the task of later dictionaries.  For example,
   a filtering dictionary could be used to remove accents from accented
   letters, as is done by the &lt;xref linkend="unaccent"/&gt; module.
</span>
フィルタリング辞書は、リスト中の好きな場所へ配置できます。(役に立たなくなるリストの最後を除きます。)
フィルタリング辞書は、後続の辞書の処理を単純化するために、一部の文字の正規化を行うのに有用です。
例えば、フィルタリング辞書は<a class="xref" href="unaccent.html" title="F.43. unaccent">unaccent</a>モジュールで実施される様な、アクセント記号が付与された文字からアクセント記号を取り除くのに使用することができます。
  </p><div class="sect2" id="TEXTSEARCH-STOPWORDS"><div class="titlepage"><div><div><h3 class="title">12.6.1. ストップワード</h3></div></div></div><span class="original">
   &lt;title&gt;Stop Words&lt;/title&gt;
</span><p>
<span class="original">
    Stop words are words that are very common, appear in almost every
    document, and have no discrimination value. Therefore, they can be ignored
    in the context of full text searching. For example, every English text
    contains words like &lt;literal&gt;a&lt;/literal&gt; and &lt;literal&gt;the&lt;/literal&gt;, so it is
    useless to store them in an index.  However, stop words do affect the
    positions in &lt;type&gt;tsvector&lt;/type&gt;, which in turn affect ranking:
</span>
ストップワードは、ほとんどすべての文書に現れるような非常に一般的で、ほかのものと同じようには扱う価値のない単語です。
ですから、全文検索の際には無視して構いません。
たとえば、すべての英語のテキストは<code class="literal">a</code>や<code class="literal">the</code>のような単語を含んでおり、インデックスの中にそれらを入れても役に立ちません。
しかし、ストップワードは<code class="type">tsvector</code>中の位置に影響を与えるので、結局ランキングにも影響があります。

</p><pre class="screen">
SELECT to_tsvector('english','in the list of stop words');
        to_tsvector
----------------------------
 'list':3 'stop':5 'word':6
</pre><p>

<span class="original">
    The missing positions 1,2,4 are because of stop words.  Ranks
    calculated for documents with and without stop words are quite different:
</span>
位置1, 2, 4は、ストップワードのために失われています。
ストップワードの有無により、文書のために計算されたランクは非常に影響を受けます。

</p><pre class="screen">
SELECT ts_rank_cd (to_tsvector('english','in the list of stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
------------
       0.05

SELECT ts_rank_cd (to_tsvector('english','list stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
------------
        0.1
</pre><p>

   </p><p>
<span class="original">
    It is up to the specific dictionary how it treats stop words. For example,
    &lt;literal&gt;ispell&lt;/literal&gt; dictionaries first normalize words and then
    look at the list of stop words, while &lt;literal&gt;Snowball&lt;/literal&gt; stemmers
    first check the list of stop words. The reason for the different
    behavior is an attempt to decrease noise.
</span>
ストップワードをどのように扱うかは、特定の辞書に任されています。
例えば、<code class="literal">ispell</code>辞書はまず単語を正規化し、そして、ストップワードのリストを検索します。一方、<code class="literal">Snowball</code>語幹抽出はまずストップワードのリストを検査します。
動作が異なる理由は、ノイズが紛れ込む可能性を減らすことです。
   </p></div><div class="sect2" id="TEXTSEARCH-SIMPLE-DICTIONARY"><div class="titlepage"><div><div><h3 class="title">12.6.2. simple辞書</h3></div></div></div><span class="original">
   &lt;title&gt;Simple Dictionary&lt;/title&gt;
</span><p>
<span class="original">
    The &lt;literal&gt;simple&lt;/literal&gt; dictionary template operates by converting the
    input token to lower case and checking it against a file of stop words.
    If it is found in the file then an empty array is returned, causing
    the token to be discarded.  If not, the lower-cased form of the word
    is returned as the normalized lexeme.  Alternatively, the dictionary
    can be configured to report non-stop-words as unrecognized, allowing
    them to be passed on to the next dictionary in the list.
</span>
<code class="literal">simple</code>辞書テンプレートは、入力トークンを小文字に変換し、ストップワードのファイルに対してチェックすることによって動作します。
もしファイルの中にあれば、空の配列が返却され、そのトークンは捨てられます。
そうでないときは、小文字形式の単語が正規化された語彙素として返却されます。
別の方法としては、ストップワードではないものは、認識できないものとすることもできます。そうすることにより、それらをリスト中の次の辞書に渡すことができます。
   </p><p>
<span class="original">
    Here is an example of a dictionary definition using the &lt;literal&gt;simple&lt;/literal&gt;
    template:
</span>
<code class="literal">simple</code>テンプレートを使った辞書定義の例を示します。

</p><pre class="programlisting">
CREATE TEXT SEARCH DICTIONARY public.simple_dict (
    TEMPLATE = pg_catalog.simple,
    STOPWORDS = english
);
</pre><p>

<span class="original">
    Here, &lt;literal&gt;english&lt;/literal&gt; is the base name of a file of stop words.
    The file's full name will be
    &lt;filename&gt;$SHAREDIR/tsearch_data/english.stop&lt;/filename&gt;,
    where &lt;literal&gt;$SHAREDIR&lt;/literal&gt; means the
    &lt;productname&gt;PostgreSQL&lt;/productname&gt; installation's shared-data directory,
    often &lt;filename&gt;/usr/local/share/postgresql&lt;/filename&gt; (use &lt;command&gt;pg_config
    &amp;#045;-sharedir&lt;/command&gt; to determine it if you're not sure).
    The file format is simply a list
    of words, one per line.  Blank lines and trailing spaces are ignored,
    and upper case is folded to lower case, but no other processing is done
    on the file contents.
</span>
ここで、<code class="literal">english</code>は、ストップワードファイルのベースネームです。
ファイルのフルネームは、<code class="filename">$SHAREDIR/tsearch_data/english.stop</code>です。<code class="literal">$SHAREDIR</code>は、<span class="productname">PostgreSQL</span>インストール先の共有データディレクトリです。これは、よく<code class="filename">/usr/local/share/postgresql</code>に置いてあります。(良くわからない場合は<code class="command">pg_config --sharedir</code>を使ってください)。
ファイル形式は、単に1行ごとに単語を書くだけです。
空行と、後方の空白は無視されます。大文字は小文字に変換されます。このファイルの内容に関する処理はこれだけです。
   </p><p>
<span class="original">
    Now we can test our dictionary:
</span>
これで辞書のテストができます。

</p><pre class="screen">
SELECT ts_lexize('public.simple_dict','YeS');
 ts_lexize
-----------
 {yes}

SELECT ts_lexize('public.simple_dict','The');
 ts_lexize
-----------
 {}
</pre><p>
   </p><p>
<span class="original">
    We can also choose to return &lt;literal&gt;NULL&lt;/literal&gt;, instead of the lower-cased
    word, if it is not found in the stop words file.  This behavior is
    selected by setting the dictionary's &lt;literal&gt;Accept&lt;/literal&gt; parameter to
    &lt;literal&gt;false&lt;/literal&gt;.  Continuing the example:
</span>
また、ストップワードファイルの中に見つからないときに、小文字に変換した単語を返す代わりに、<code class="literal">NULL</code>を返すことを選ぶこともできます。
この挙動は、辞書の<code class="literal">Accept</code>パラメータを<code class="literal">false</code>に設定することで選択されます。
さらに例を続けます。

</p><pre class="screen">
ALTER TEXT SEARCH DICTIONARY public.simple_dict ( Accept = false );

SELECT ts_lexize('public.simple_dict','YeS');
 ts_lexize
-----------


SELECT ts_lexize('public.simple_dict','The');
 ts_lexize
-----------
 {}
</pre><p>
   </p><p>
<span class="original">
    With the default setting of &lt;literal&gt;Accept&lt;/literal&gt; = &lt;literal&gt;true&lt;/literal&gt;,
    it is only useful to place a &lt;literal&gt;simple&lt;/literal&gt; dictionary at the end
    of a list of dictionaries, since it will never pass on any token to
    a following dictionary.  Conversely, &lt;literal&gt;Accept&lt;/literal&gt; = &lt;literal&gt;false&lt;/literal&gt;
    is only useful when there is at least one following dictionary.
</span>
デフォルト設定の<code class="literal">Accept</code> = <code class="literal">true</code>では、<code class="literal">simple</code>辞書は、辞書リストの最後に置かなければ意味がありません。なぜなら、後続の辞書にトークンを渡すことがないからです。逆に<code class="literal">Accept</code> = <code class="literal">false</code>は、後続の辞書が少なくとも一つはあるときに意味があります。
   </p><div class="caution"><h3 class="title">注意</h3><p>
<span class="original">
     Most types of dictionaries rely on configuration files, such as files of
     stop words.  These files &lt;emphasis&gt;must&lt;/emphasis&gt; be stored in UTF-8 encoding.
     They will be translated to the actual database encoding, if that is
     different, when they are read into the server.
</span>
ほとんどの辞書の形式は、ストップワードファイルのように設定ファイルに依存します。これらのファイルは<span class="emphasis"><em>必ず</em></span>UTF-8エンコーディングにしてください。サーバのエンコーディングがUTF-8でない場合は、サーバに読み込まれる際に実際のデータベースエンコーディングに変換されます。
    </p></div><div class="caution"><h3 class="title">注意</h3><p>
<span class="original">
     Normally, a database session will read a dictionary configuration file
     only once, when it is first used within the session.  If you modify a
     configuration file and want to force existing sessions to pick up the
     new contents, issue an &lt;command&gt;ALTER TEXT SEARCH DICTIONARY&lt;/command&gt; command
     on the dictionary.  This can be a &lt;quote&gt;dummy&lt;/quote&gt; update that doesn't
     actually change any parameter values.
</span>
通常、辞書はデータベースセッションの中で最初に使われる際に、一度だけ読み込まれます。辞書を変更し、現在使われているセッションの中で新しい内容が読み込まれるようにしたい場合は、その辞書に対して<code class="command">ALTER TEXT SEARCH DICTIONARY</code>を発行してください。これは実際にはどんなパラメータ値をも変更しない<span class="quote">「<span class="quote">ダミー</span>」</span>の更新でよいです。
    </p></div></div><div class="sect2" id="TEXTSEARCH-SYNONYM-DICTIONARY"><div class="titlepage"><div><div><h3 class="title">12.6.3. 同義語辞書</h3></div></div></div><span class="original">
   &lt;title&gt;Synonym Dictionary&lt;/title&gt;
</span><p>
<span class="original">
    This dictionary template is used to create dictionaries that replace a
    word with a synonym. Phrases are not supported (use the thesaurus
    template (&lt;xref linkend="textsearch-thesaurus"/&gt;) for that).  A synonym
    dictionary can be used to overcome linguistic problems, for example, to
    prevent an English stemmer dictionary from reducing the word &lt;quote&gt;Paris&lt;/quote&gt; to
    &lt;quote&gt;pari&lt;/quote&gt;.  It is enough to have a &lt;literal&gt;Paris paris&lt;/literal&gt; line in the
    synonym dictionary and put it before the &lt;literal&gt;english_stem&lt;/literal&gt;
    dictionary.  For example:
</span>
この辞書テンプレートは、単語を同義語に置き換える辞書を作るために使われます。語句はサポートされていません(そのためには類語テンプレート(<a class="xref" href="textsearch-dictionaries.html#TEXTSEARCH-THESAURUS" title="12.6.4. 類語辞書">12.6.4</a>)を使ってください)。同義語辞書は、言語学的な問題、たとえば、英語語幹辞書が<span class="quote">「<span class="quote">Paris</span>」</span>という単語を<span class="quote">「<span class="quote">pari</span>」</span>に縮小してしまうのを防ぎます。<code class="literal">Paris paris</code>という行を同義語辞書に登録し、<code class="literal">english_stem</code>辞書の前に置くようにするだけでよいのです。下記はその例です。

</p><pre class="screen">
SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes 
-----------+-----------------+-------+----------------+--------------+---------
 asciiword | Word, all ASCII | Paris | {english_stem} | english_stem | {pari}

CREATE TEXT SEARCH DICTIONARY my_synonym (
    TEMPLATE = synonym,
    SYNONYMS = my_synonyms
);

ALTER TEXT SEARCH CONFIGURATION english
    ALTER MAPPING FOR asciiword
    WITH my_synonym, english_stem;

SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |       dictionaries        | dictionary | lexemes 
-----------+-----------------+-------+---------------------------+------------+---------
 asciiword | Word, all ASCII | Paris | {my_synonym,english_stem} | my_synonym | {paris}
</pre><p>
   </p><p>
<span class="original">
    The only parameter required by the &lt;literal&gt;synonym&lt;/literal&gt; template is
    &lt;literal&gt;SYNONYMS&lt;/literal&gt;, which is the base name of its configuration file
    &amp;mdash; &lt;literal&gt;my_synonyms&lt;/literal&gt; in the above example.
    The file's full name will be
    &lt;filename&gt;$SHAREDIR/tsearch_data/my_synonyms.syn&lt;/filename&gt;
    (where &lt;literal&gt;$SHAREDIR&lt;/literal&gt; means the
    &lt;productname&gt;PostgreSQL&lt;/productname&gt; installation's shared-data directory).
    The file format is just one line
    per word to be substituted, with the word followed by its synonym,
    separated by white space.  Blank lines and trailing spaces are ignored.
</span>
<code class="literal">synonym</code>テンプレートに必要なパラメータは<code class="literal">SYNONYMS</code>だけで、その設定ファイルのベースネームです — 上の例では<code class="literal">my_synonyms</code>です。
ファイルのフルネームは、<code class="filename">$SHAREDIR/tsearch_data/my_synonyms.syn</code> となります(ここで<code class="literal">$SHAREDIR</code>は、<span class="productname">PostgreSQL</span>をインストールした際の、共有データディレクトリです)。
ファイルの形式は、置き換え対象の1単語につき1行で、単語には空白で区切られた同義語が後に続きます。
空行、後方の空白は無視されます。
   </p><p>
<span class="original">
    The &lt;literal&gt;synonym&lt;/literal&gt; template also has an optional parameter
    &lt;literal&gt;CaseSensitive&lt;/literal&gt;, which defaults to &lt;literal&gt;false&lt;/literal&gt;.  When
    &lt;literal&gt;CaseSensitive&lt;/literal&gt; is &lt;literal&gt;false&lt;/literal&gt;, words in the synonym file
    are folded to lower case, as are input tokens.  When it is
    &lt;literal&gt;true&lt;/literal&gt;, words and tokens are not folded to lower case,
    but are compared as-is.
</span>
<code class="literal">synonym</code>テンプレートはまた、<code class="literal">CaseSensitive</code>というオプションパラメータを持っており、デフォルトは<code class="literal">false</code>です。
<code class="literal">CaseSensitive</code>が<code class="literal">false</code>の時は、同義語辞書内の単語は入力トークンと同様に小文字に変換されます。
<code class="literal">true</code>の時は、単語とトークンは小文字に変換されずそのまま比較されます。
   </p><p>
<span class="original">
    An asterisk (&lt;literal&gt;*&lt;/literal&gt;) can be placed at the end of a synonym
    in the configuration file.  This indicates that the synonym is a prefix.
    The asterisk is ignored when the entry is used in
    &lt;function&gt;to_tsvector()&lt;/function&gt;, but when it is used in
    &lt;function&gt;to_tsquery()&lt;/function&gt;, the result will be a query item with
    the prefix match marker (see
    &lt;xref linkend="textsearch-parsing-queries"/&gt;).
    For example, suppose we have these entries in
    &lt;filename&gt;$SHAREDIR/tsearch_data/synonym_sample.syn&lt;/filename&gt;:
</span>
アスタリスク(<code class="literal">*</code>)は設定ファイル中の同義語の最後に付与することができます。
これは同義語を接頭語とすることを意味します。
アスタリスクは、エントリが<code class="function">to_tsvector()</code>で使用される場合には無視されますが、<code class="function">to_tsquery()</code>で使用される場合、結果は前方一致を伴った問い合わせになるでしょう。(詳しくは<a class="xref" href="textsearch-controls.html#TEXTSEARCH-PARSING-QUERIES" title="12.3.2. 問い合わせのパース">12.3.2</a>を見てください。)
例えば、<code class="filename">$SHAREDIR/tsearch_data/synonym_sample.syn</code>に以下の様なエントリをもっていたとします。
</p><pre class="programlisting">
postgres        pgsql
postgresql      pgsql
postgre pgsql
gogle   googl
indices index*
</pre><p>
<span class="original">
    Then we will get these results:
</span>
この場合、次のような結果を得ることになります。
</p><pre class="screen">
mydb=# CREATE TEXT SEARCH DICTIONARY syn (template=synonym, synonyms='synonym_sample');
mydb=# SELECT ts_lexize('syn','indices');
 ts_lexize
-----------
 {index}
(1 row)

mydb=# CREATE TEXT SEARCH CONFIGURATION tst (copy=simple);
mydb=# ALTER TEXT SEARCH CONFIGURATION tst ALTER MAPPING FOR asciiword WITH syn;
mydb=# SELECT to_tsvector('tst','indices');
 to_tsvector
-------------
 'index':1
(1 row)

mydb=# SELECT to_tsquery('tst','indices');
 to_tsquery
------------
 'index':*
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector;
            tsvector             
---------------------------------
 'are' 'indexes' 'useful' 'very'
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector @@ to_tsquery('tst','indices');
 ?column?
----------
 t
(1 row)
</pre><p>
   </p></div><div class="sect2" id="TEXTSEARCH-THESAURUS"><div class="titlepage"><div><div><h3 class="title">12.6.4. 類語辞書</h3></div></div></div><span class="original">
   &lt;title&gt;Thesaurus Dictionary&lt;/title&gt;
</span><p>
<span class="original">
    A thesaurus dictionary (sometimes abbreviated as &lt;acronym&gt;TZ&lt;/acronym&gt;) is
    a collection of words that includes information about the relationships
    of words and phrases, i.e., broader terms (&lt;acronym&gt;BT&lt;/acronym&gt;), narrower
    terms (&lt;acronym&gt;NT&lt;/acronym&gt;), preferred terms, non-preferred terms, related
    terms, etc.
</span>
類語辞書(<acronym class="acronym">TZ</acronym>と略されることがあります)は、単語と語句の関係情報を集めたものです。つまり、広義用語(<acronym class="acronym">BT</acronym>)、狭義用語(<acronym class="acronym">NT</acronym>)、優先用語、非優先用語、関連用語などです。
   </p><p>
<span class="original">
    Basically a thesaurus dictionary replaces all non-preferred terms by one
    preferred term and, optionally, preserves the original terms for indexing
    as well.  &lt;productname&gt;PostgreSQL&lt;/productname&gt;'s current implementation of the
    thesaurus dictionary is an extension of the synonym dictionary with added
    &lt;firstterm&gt;phrase&lt;/firstterm&gt; support.  A thesaurus dictionary requires
    a configuration file of the following format:
</span>
基本的には、類語辞書は、非優先用語を優先用語に置き換え、オプションで元の用語もインデックス付けのため保存します。<span class="productname">PostgreSQL</span>の現在の類語辞書の実装は、同義語辞書を拡張し、<em class="firstterm">語句</em>のサポートを追加したものです。類語辞書は、以下のようなフォーマットの設定ファイルを必要とします。

</p><pre class="programlisting">
# this is a comment
sample word(s) : indexed word(s)
more sample word(s) : more indexed word(s)
...
</pre><p>

<span class="original">
    where  the colon (&lt;symbol&gt;:&lt;/symbol&gt;) symbol acts as a delimiter between a
    phrase and its replacement.
</span>
ここで、コロン(<code class="symbol">:</code>)は、語句とその置き換え対象の区切りです。
   </p><p>
<span class="original">
    A thesaurus dictionary uses a &lt;firstterm&gt;subdictionary&lt;/firstterm&gt; (which
    is specified in the dictionary's configuration) to normalize the input
    text before checking for phrase matches. It is only possible to select one
    subdictionary.  An error is reported if the subdictionary fails to
    recognize a word. In that case, you should remove the use of the word or
    teach the subdictionary about it.  You can place an asterisk
    (&lt;symbol&gt;*&lt;/symbol&gt;) at the beginning of an indexed word to skip applying
    the subdictionary to it, but all sample words &lt;emphasis&gt;must&lt;/emphasis&gt; be known
    to the subdictionary.
</span>
類語辞書は、<em class="firstterm">副辞書</em>(辞書設定で指定します)を、一致する語句をチェックする前に入力テキストを正規化するために使います。
副辞書はただ一つだけ選べます。
副辞書が単語を認識できない場合はエラーが報告されます。
その場合は、その単語の利用を止めるか、副辞書にそのことを教えなければなりません。
アスタリスク(<code class="symbol">*</code>)をインデックス付けされた単語の先頭に置くことにより、副辞書の適用をスキップできます。しかしながら、すべてのサンプルの単語は、副辞書に認識<span class="emphasis"><em>されなければなりません</em></span>。
   </p><p>
<span class="original">
    The thesaurus dictionary chooses the longest match if there are multiple
    phrases matching the input, and ties are broken by using the last
    definition.
</span>
複数の類語が照合するときは、類語辞書はもっとも長いものを選びます。そして、語句は、最後の定義を使って分解されます。
   </p><p>
<span class="original">
    Specific stop words recognized by the subdictionary cannot be
    specified;  instead use &lt;literal&gt;?&lt;/literal&gt; to mark the location where any
    stop word can appear.  For example, assuming that &lt;literal&gt;a&lt;/literal&gt; and
    &lt;literal&gt;the&lt;/literal&gt; are stop words according to the subdictionary:
</span>
特定のストップワードを副辞書に認識するように指定することはできません。その代わり、ストップワードが出現する位置を<code class="literal">?</code>でマークします。
たとえば、<code class="literal">a</code>と<code class="literal">the</code>が副辞書によればストップワードだったとします。

</p><pre class="programlisting">
? one ? two : swsw
</pre><p>

<span class="original">
    matches &lt;literal&gt;a one the two&lt;/literal&gt; and &lt;literal&gt;the one a two&lt;/literal&gt;;
    both would be replaced by &lt;literal&gt;swsw&lt;/literal&gt;.
</span>
は、<code class="literal">a one the two</code>と<code class="literal">the one a two</code>に照合します。そして、両方とも<code class="literal">swsw</code>に置き換えられます。
   </p><p>
<span class="original">
    Since a thesaurus dictionary has the capability to recognize phrases it
    must remember its state and interact with the parser. A thesaurus dictionary
    uses these assignments to check if it should handle the next word or stop
    accumulation.  The thesaurus dictionary must be configured
    carefully. For example, if the thesaurus dictionary is assigned to handle
    only the &lt;literal&gt;asciiword&lt;/literal&gt; token, then a thesaurus dictionary
    definition like &lt;literal&gt;one 7&lt;/literal&gt; will not work since token type
    &lt;literal&gt;uint&lt;/literal&gt; is not assigned to the thesaurus dictionary.
</span>
類語辞書は語句を認識することができるので、状態を記憶してパーサと連携を保たなければなりません。
類語辞書は、この機能を使って次の単語を引き続き処理するのか、単語の蓄積を止めるのかを決定します。
類語辞書の設定は注意深く行わなければなりません。
たとえば、類語辞書が<code class="literal">asciiword</code>トークンだけを扱うようになっている場合、<code class="literal">one 7</code>のような類語辞書の定義は、トークン型<code class="literal">uint</code>が類語辞書にアサインされていないので動きません。
   </p><div class="caution"><h3 class="title">注意</h3><p>
<span class="original">
     Thesauruses are used during indexing so any change in the thesaurus
     dictionary's parameters &lt;emphasis&gt;requires&lt;/emphasis&gt; reindexing.
     For most other dictionary types, small changes such as adding or
     removing stopwords does not force reindexing.
</span>
類語辞書はインデックス付けの際に利用されるので、類語辞書を設定変更すると、再インデックス付けが<span class="emphasis"><em>必要</em></span>になります。他のほとんどの辞書では、ストップワードを追加あるいは削除するような小さな変更は、インデックス付けを必要としません。
    </p></div><div class="sect3" id="TEXTSEARCH-THESAURUS-CONFIG"><div class="titlepage"><div><div><h4 class="title">12.6.4.1. 類語設定</h4></div></div></div><span class="original">
   &lt;title&gt;Thesaurus Configuration&lt;/title&gt;
</span><p>
<span class="original">
    To define a new thesaurus dictionary, use the &lt;literal&gt;thesaurus&lt;/literal&gt;
    template.  For example:
</span>
新しい類語辞書を定義するには、<code class="literal">thesaurus</code>テンプレートを使います。例を示します。

</p><pre class="programlisting">
CREATE TEXT SEARCH DICTIONARY thesaurus_simple (
    TEMPLATE = thesaurus,
    DictFile = mythesaurus,
    Dictionary = pg_catalog.english_stem
);
</pre><p>

<span class="original">
    Here:
</span>
ここで、
    </p><div class="itemizedlist"><ul class="itemizedlist compact" style="list-style-type: bullet; "><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
       &lt;literal&gt;thesaurus_simple&lt;/literal&gt; is the new dictionary's name
</span>
<code class="literal">thesaurus_simple</code>は新しい辞書の名前です。
      </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
       &lt;literal&gt;mythesaurus&lt;/literal&gt; is the base name of the thesaurus
       configuration file.
       (Its full name will be &lt;filename&gt;$SHAREDIR/tsearch_data/mythesaurus.ths&lt;/filename&gt;,
       where &lt;literal&gt;$SHAREDIR&lt;/literal&gt; means the installation shared-data
       directory.)
</span>
<code class="literal">mythesaurus</code>は、類語設定ファイルのベースネームです。
(フルパスは、<code class="filename">$SHAREDIR/tsearch_data/mythesaurus.ths</code>となります。ここで、<code class="literal">$SHAREDIR</code>はインストール時の共有データディレクトリです。)
      </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
       &lt;literal&gt;pg_catalog.english_stem&lt;/literal&gt; is the subdictionary (here,
       a Snowball English stemmer) to use for thesaurus normalization.
       Notice that the subdictionary will have its own
       configuration (for example, stop words), which is not shown here.
</span>
類語正規化で使用する<code class="literal">pg_catalog.english_stem</code>は副辞書です(ここでは、Snowball英語語幹辞書)。
副辞書にはそれ用の設定(たとえばストップワード)があることに注意してください。ここではそれは表示していません。
      </p></li></ul></div><p>

<span class="original">
    Now it is possible to bind the thesaurus dictionary &lt;literal&gt;thesaurus_simple&lt;/literal&gt;
    to the desired token types in a configuration, for example:
</span>
これで、類語辞書<code class="literal">thesaurus_simple</code>を、設定中の希望のトークンにバインドすることができるようになります。例を示します。

</p><pre class="programlisting">
ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_simple;
</pre><p>
   </p></div><div class="sect3" id="TEXTSEARCH-THESAURUS-EXAMPLES"><div class="titlepage"><div><div><h4 class="title">12.6.4.2. 類語の例</h4></div></div></div><span class="original">
   &lt;title&gt;Thesaurus Example&lt;/title&gt;
</span><p>
<span class="original">
    Consider a simple astronomical thesaurus &lt;literal&gt;thesaurus_astro&lt;/literal&gt;,
    which contains some astronomical word combinations:
</span>
天文学の単語の組合わせを含む単純な天文学用の<code class="literal">thesaurus_astro</code>類語を考えます。

</p><pre class="programlisting">
supernovae stars : sn
crab nebulae : crab
</pre><p>

<span class="original">
    Below we create a dictionary and bind some token types to
    an astronomical thesaurus and English stemmer:
</span>
以下で辞書を作り、トークン型を天文学類語辞書と英語の語幹辞書に結び付けます。

</p><pre class="programlisting">
CREATE TEXT SEARCH DICTIONARY thesaurus_astro (
    TEMPLATE = thesaurus,
    DictFile = thesaurus_astro,
    Dictionary = english_stem
);

ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_astro, english_stem;
</pre><p>

<span class="original">
    Now we can see how it works.
    &lt;function&gt;ts_lexize&lt;/function&gt; is not very useful for testing a thesaurus,
    because it treats its input as a single token.  Instead we can use
    &lt;function&gt;plainto_tsquery&lt;/function&gt; and &lt;function&gt;to_tsvector&lt;/function&gt;
    which will break their input strings into multiple tokens:
</span>
さあ、これでどのように動くか試せます。<code class="function">ts_lexize</code>は類語をテストする目的にはあまり有用ではありません。なぜなら、それは入力を単一のトークンとして扱うからです。
その代わりに、<code class="function">plainto_tsquery</code>と<code class="function">to_tsvector</code>を使って入力文字列を複数のトークンに分解します。

</p><pre class="screen">
SELECT plainto_tsquery('supernova star');
 plainto_tsquery
-----------------
 'sn'

SELECT to_tsvector('supernova star');
 to_tsvector
-------------
 'sn':1
</pre><p>

<span class="original">
    In principle, one can use &lt;function&gt;to_tsquery&lt;/function&gt; if you quote
    the argument:
</span>
原則として、引数を引用符で囲めば<code class="function">to_tsquery</code>が使えます。

</p><pre class="screen">
SELECT to_tsquery('''supernova star''');
 to_tsquery
------------
 'sn'
</pre><p>

<span class="original">
    Notice that &lt;literal&gt;supernova star&lt;/literal&gt; matches &lt;literal&gt;supernovae
    stars&lt;/literal&gt; in &lt;literal&gt;thesaurus_astro&lt;/literal&gt; because we specified
    the &lt;literal&gt;english_stem&lt;/literal&gt; stemmer in the thesaurus definition.
    The stemmer removed the &lt;literal&gt;e&lt;/literal&gt; and &lt;literal&gt;s&lt;/literal&gt;.
</span>
<code class="literal">english_stem</code>語幹辞書を同義語辞書の定義時に指定したので、<code class="literal">supernova star</code>が<code class="literal">thesaurus_astro</code>中の<code class="literal">supernovae stars</code>に照合していることに注意してください。
語幹処理が<code class="literal">e</code>と<code class="literal">s</code>を削除しています。
   </p><p>
<span class="original">
    To index the original phrase as well as the substitute, just include it
    in the right-hand part of the definition:
</span>
置き換え後の語句とオリジナルの語句の両方をインデックス付けするには、定義の右項にオリジナルを追加するだけで良いです。

</p><pre class="screen">
supernovae stars : sn supernovae stars

SELECT plainto_tsquery('supernova star');
       plainto_tsquery
-----------------------------
 'sn' &amp; 'supernova' &amp; 'star'
</pre><p>
   </p></div></div><div class="sect2" id="TEXTSEARCH-ISPELL-DICTIONARY"><div class="titlepage"><div><div><h3 class="title">12.6.5. <span class="application">Ispell</span>辞書</h3></div></div></div><span class="original">
   &lt;title&gt;&lt;application&gt;Ispell&lt;/application&gt; Dictionary&lt;/title&gt;
</span><p>
<span class="original">
    The &lt;application&gt;Ispell&lt;/application&gt; dictionary template supports
    &lt;firstterm&gt;morphological dictionaries&lt;/firstterm&gt;, which can normalize many
    different linguistic forms of a word into the same lexeme.  For example,
    an English &lt;application&gt;Ispell&lt;/application&gt; dictionary can match all declensions and
    conjugations of the search term &lt;literal&gt;bank&lt;/literal&gt;, e.g.,
    &lt;literal&gt;banking&lt;/literal&gt;, &lt;literal&gt;banked&lt;/literal&gt;, &lt;literal&gt;banks&lt;/literal&gt;,
    &lt;literal&gt;banks'&lt;/literal&gt;, and &lt;literal&gt;bank's&lt;/literal&gt;.
</span>
<span class="application">Ispell</span>辞書テンプレートは、<em class="firstterm">形態論辞書</em>を提供します。これによって、言語学的に多様な単語の形態を同じ語彙素に変換することができます。
たとえば、英語<span class="application">Ispell</span>辞書は、検索語<code class="literal">bank</code>の語形変化と活用変化、たとえば<code class="literal">banking</code>, <code class="literal">banked</code>, <code class="literal">banks</code>, <code class="literal">banks'</code>, <code class="literal">bank's</code>に照合します。
   </p><p>
<span class="original">
    The standard &lt;productname&gt;PostgreSQL&lt;/productname&gt; distribution does
    not include any &lt;application&gt;Ispell&lt;/application&gt; configuration files.
    Dictionaries for a large number of languages are available from &lt;ulink
    url="https://www.cs.hmc.edu/~geoff/ispell.html"&gt;Ispell&lt;/ulink&gt;.
    Also, some more modern dictionary file formats are supported &amp;mdash; &lt;ulink
    url="https://en.wikipedia.org/wiki/MySpell"&gt;MySpell&lt;/ulink&gt; (OO &amp;lt; 2.0.1)
    and &lt;ulink url="https://sourceforge.net/projects/hunspell/"&gt;Hunspell&lt;/ulink&gt;
    (OO &amp;gt;= 2.0.2).  A large list of dictionaries is available on the &lt;ulink
    url="https://wiki.openoffice.org/wiki/Dictionaries"&gt;OpenOffice
    Wiki&lt;/ulink&gt;.
</span>
<span class="productname">PostgreSQL</span>の標準配布には、<span class="application">Ispell</span>の設定ファイルは含まれていません。
多くの言語用の辞書が<a class="ulink" href="https://ficus-www.cs.ucla.edu/geoff/ispell.html" target="_top">Ispell</a>で入手できます。
また、より新しい辞書のフォーマットもサポートされています — <a class="ulink" href="https://en.wikipedia.org/wiki/MySpell" target="_top">MySpell</a>(OO &lt; 2.0.1)と<a class="ulink" href="https://sourceforge.net/projects/hunspell/" target="_top">Hunspell</a>(OO &gt;= 2.0.2)。
多数の辞書のリストが <a class="ulink" href="https://wiki.openoffice.org/wiki/Dictionaries" target="_top">OpenOffice Wiki</a>で入手できます。
   </p><p>
<span class="original">
    To create an &lt;application&gt;Ispell&lt;/application&gt; dictionary perform these steps:
</span>
<span class="application">Ispell</span>辞書を作るには、以下の手順を実行します。
   </p><div class="itemizedlist"><ul class="itemizedlist compact" style="list-style-type: bullet; "><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      download dictionary configuration files. &lt;productname&gt;OpenOffice&lt;/productname&gt;
      extension files have the &lt;filename&gt;.oxt&lt;/filename&gt; extension. It is necessary
      to extract &lt;filename&gt;.aff&lt;/filename&gt; and &lt;filename&gt;.dic&lt;/filename&gt; files, change
      extensions to &lt;filename&gt;.affix&lt;/filename&gt; and &lt;filename&gt;.dict&lt;/filename&gt;. For some
      dictionary files it is also needed to convert characters to the UTF-8
      encoding with commands (for example, for a Norwegian language dictionary):
</span>
辞書の設定ファイルをダウンロードします。
<span class="productname">OpenOffice</span>の拡張ファイルは拡張子<code class="filename">.oxt</code>があります。
<code class="filename">.aff</code>ファイルと<code class="filename">.dic</code>ファイルを抽出し、拡張子を<code class="filename">.affix</code>と<code class="filename">.dict</code>に変更する必要があります。
一部の辞書ファイルでは、以下のコマンドで文字をUTF-8の符号化に変換する必要もあります（例えば、ノルウェー語の辞書では次のようになります）。
</p><pre class="programlisting">
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.affix nn_NO.aff
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.dict nn_NO.dic
</pre><p>
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      copy files to the &lt;filename&gt;$SHAREDIR/tsearch_data&lt;/filename&gt; directory
</span>
ファイルを<code class="filename">$SHAREDIR/tsearch_data</code>ディレクトリにコピーします。
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      load files into PostgreSQL with the following command:
</span>
以下のコマンドでファイルをPostgreSQLにロードします。
</p><pre class="programlisting">
CREATE TEXT SEARCH DICTIONARY english_hunspell (
    TEMPLATE = ispell,
    DictFile = en_us,
    AffFile = en_us,
    Stopwords = english);
</pre><p>
     </p></li></ul></div><p>
<span class="original">
    Here, &lt;literal&gt;DictFile&lt;/literal&gt;, &lt;literal&gt;AffFile&lt;/literal&gt;, and &lt;literal&gt;StopWords&lt;/literal&gt;
    specify the base names of the dictionary, affixes, and stop-words files.
    The stop-words file has the same format explained above for the
    &lt;literal&gt;simple&lt;/literal&gt; dictionary type.  The format of the other files is
    not specified here but is available from the above-mentioned web sites.
</span>
ここで、<code class="literal">DictFile</code>, <code class="literal">AffFile</code>, および<code class="literal">StopWords</code>は、辞書のベースネーム、接辞ファイル、ストップワードファイルを指定します。
ストップワードファイルは、上で説明した<code class="literal">simple</code>辞書と同じ形式です。
ほかのファイルの形式はここでは説明されませんが、上にあげたウェブサイトに説明があります。
   </p><p>
<span class="original">
    Ispell dictionaries usually recognize a limited set of words, so they
    should be followed by another broader dictionary; for
    example, a Snowball dictionary, which recognizes everything.
</span>
Ispell辞書は通常限られた数の単語を認識します。ですので、なんでも認識できるSnowball辞書のような、より適用範囲の広い辞書による後処理が必要です。
   </p><p>
<span class="original">
    The &lt;filename&gt;.affix&lt;/filename&gt; file of &lt;application&gt;Ispell&lt;/application&gt; has the following
    structure:
</span>
<span class="application">Ispell</span>の<code class="filename">.affix</code>ファイルは次のような構造になっています。
</p><pre class="programlisting">
prefixes
flag *A:
    .           &gt;   RE      # As in enter &gt; reenter
suffixes
flag T:
    E           &gt;   ST      # As in late &gt; latest
    [^AEIOU]Y   &gt;   -Y,IEST # As in dirty &gt; dirtiest
    [AEIOU]Y    &gt;   EST     # As in gray &gt; grayest
    [^EY]       &gt;   EST     # As in small &gt; smallest
</pre><p>
   </p><p>
<span class="original">
    And the &lt;filename&gt;.dict&lt;/filename&gt; file has the following structure:
</span>
そして、<code class="filename">.dict</code>ファイルは次のような構造になっています。
</p><pre class="programlisting">
lapse/ADGRS
lard/DGRS
large/PRTY
lark/MRS
</pre><p>
   </p><p>
<span class="original">
    Format of the &lt;filename&gt;.dict&lt;/filename&gt; file is:
</span>
<code class="filename">.dict</code>ファイルのフォーマットは次の通りです。
</p><pre class="programlisting">
basic_form/affix_class_name
</pre><p>
   </p><p>
<span class="original">
    In the &lt;filename&gt;.affix&lt;/filename&gt; file every affix flag is described in the
    following format:
</span>
<code class="filename">.affix</code>ファイルで、すべてのaffix(接辞)フラグは次のフォーマットで記述されています。
</p><pre class="programlisting">
condition &gt; [-stripping_letters,] adding_affix
</pre><p>
   </p><p>
<span class="original">
    Here, condition has a format similar to the format of regular expressions.
    It can use groupings &lt;literal&gt;[...]&lt;/literal&gt; and &lt;literal&gt;[^...]&lt;/literal&gt;.
    For example, &lt;literal&gt;[AEIOU]Y&lt;/literal&gt; means that the last letter of the word
    is &lt;literal&gt;"y"&lt;/literal&gt; and the penultimate letter is &lt;literal&gt;"a"&lt;/literal&gt;,
    &lt;literal&gt;"e"&lt;/literal&gt;, &lt;literal&gt;"i"&lt;/literal&gt;, &lt;literal&gt;"o"&lt;/literal&gt; or &lt;literal&gt;"u"&lt;/literal&gt;.
    &lt;literal&gt;[^EY]&lt;/literal&gt; means that the last letter is neither &lt;literal&gt;"e"&lt;/literal&gt;
    nor &lt;literal&gt;"y"&lt;/literal&gt;.
</span>
ここで、condition(条件)は正規表現の形式と同じような形式になります。
<code class="literal">[...]</code>および<code class="literal">[^...]</code>のグループ化を使うことができます。
例えば<code class="literal">[AEIOU]Y</code>は、単語の最後の文字が<code class="literal">"y"</code>で、その前の文字が<code class="literal">"a"</code>、<code class="literal">"e"</code>、<code class="literal">"i"</code>、<code class="literal">"o"</code>、<code class="literal">"u"</code>のいずれかであることを意味します。
<code class="literal">[^EY]</code>は最後の文字が<code class="literal">"e"</code>でも<code class="literal">"y"</code>でもないことを意味します。
   </p><p>
<span class="original">
    Ispell dictionaries support splitting compound words;
    a useful feature.
    Notice that the affix file should specify a special flag using the
    &lt;literal&gt;compoundwords controlled&lt;/literal&gt; statement that marks dictionary
    words that can participate in compound formation:
</span>
Ispell辞書を使って複合語を分割することができます。これは優れた機能です。
接辞ファイルは、複合語形式の候補になる辞書中の単語に印を付ける<code class="literal">compoundwords controlled</code>文を使う特別なフラグを指定しなければならないことに注意してください。

</p><pre class="programlisting">
compoundwords  controlled z
</pre><p>

<span class="original">
    Here are some examples for the Norwegian language:
</span>
ノルウェー語の例をいくつか示します。

</p><pre class="programlisting">
SELECT ts_lexize('norwegian_ispell', 'overbuljongterningpakkmesterassistent');
   {over,buljong,terning,pakk,mester,assistent}
SELECT ts_lexize('norwegian_ispell', 'sjokoladefabrikk');
   {sjokoladefabrikk,sjokolade,fabrikk}
</pre><p>
   </p><p>
<span class="original">
    &lt;application&gt;MySpell&lt;/application&gt; format is a subset of &lt;application&gt;Hunspell&lt;/application&gt;.
    The &lt;filename&gt;.affix&lt;/filename&gt; file of &lt;application&gt;Hunspell&lt;/application&gt; has the following
    structure:
</span>
<span class="application">MySpell</span>のフォーマットは<span class="application">Hunspell</span>の部分集合です。
<span class="application">Hunspell</span>の<code class="filename">.affix</code>ファイルは以下のような構造になっています。
</p><pre class="programlisting">
PFX A Y 1
PFX A   0     re         .
SFX T N 4
SFX T   0     st         e
SFX T   y     iest       [^aeiou]y
SFX T   0     est        [aeiou]y
SFX T   0     est        [^ey]
</pre><p>
   </p><p>
<span class="original">
    The first line of an affix class is the header. Fields of an affix rules are
    listed after the header:
</span>
接辞(affix)クラスの1行目はヘッダです。
接辞ルールのフィールドはヘッダの後に列挙されます。
   </p><div class="itemizedlist"><ul class="itemizedlist compact" style="list-style-type: bullet; "><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      parameter name (PFX or SFX)
</span>
パラメータ名（PFXまたはSFX）
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      flag (name of the affix class)
</span>
フラグ（接辞クラスの名前）
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      stripping characters from beginning (at prefix) or end (at suffix) of the
      word
</span>
単語の先頭（接頭辞）から、あるいは終わり（接尾辞）から文字を削除する
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      adding affix
</span>
接辞を追加する
     </p></li><li class="listitem" style="list-style-type: disc"><p>
<span class="original">
      condition that has a format similar to the format of regular expressions.
</span>
正規表現の形式と類似の形式の条件
     </p></li></ul></div><p>
<span class="original">
    The &lt;filename&gt;.dict&lt;/filename&gt; file looks like the &lt;filename&gt;.dict&lt;/filename&gt; file of
    &lt;application&gt;Ispell&lt;/application&gt;:
</span>
<code class="filename">.dict</code>ファイルは<span class="application">Ispell</span>の<code class="filename">.dict</code>ファイルと同じように見えます。
</p><pre class="programlisting">
larder/M
lardy/RT
large/RSPMYT
largehearted
</pre><p>
   </p><div class="note"><h3 class="title">注記</h3><p>
<span class="original">
     &lt;application&gt;MySpell&lt;/application&gt; does not support compound words.
     &lt;application&gt;Hunspell&lt;/application&gt; has sophisticated support for compound words. At
     present, &lt;productname&gt;PostgreSQL&lt;/productname&gt; implements only the basic
     compound word operations of Hunspell.
</span>
<span class="application">MySpell</span>は複合語をサポートしていません。<span class="application">Hunspell</span>は複合語の高度なサポートを提供しています。いまのところ、<span class="productname">PostgreSQL</span>はHunspellの基本的な複合語操作しかサポートしていません。
    </p></div></div><div class="sect2" id="TEXTSEARCH-SNOWBALL-DICTIONARY"><div class="titlepage"><div><div><h3 class="title">12.6.6. <span class="application">Snowball</span>辞書</h3></div></div></div><span class="original">
   &lt;title&gt;&lt;application&gt;Snowball&lt;/application&gt; Dictionary&lt;/title&gt;
</span><p>
<span class="original">
    The &lt;application&gt;Snowball&lt;/application&gt; dictionary template is based on a project
    by Martin Porter, inventor of the popular Porter's stemming algorithm
    for the English language.  Snowball now provides stemming algorithms for
    many languages (see the &lt;ulink url="http://snowballstem.org/"&gt;Snowball
    site&lt;/ulink&gt; for more information).  Each algorithm understands how to
    reduce common variant forms of words to a base, or stem, spelling within
    its language.  A Snowball dictionary requires a &lt;literal&gt;language&lt;/literal&gt;
    parameter to identify which stemmer to use, and optionally can specify a
    &lt;literal&gt;stopword&lt;/literal&gt; file name that gives a list of words to eliminate.
    (&lt;productname&gt;PostgreSQL&lt;/productname&gt;'s standard stopword lists are also
    provided by the Snowball project.)
    For example, there is a built-in definition equivalent to
</span>
<span class="application">Snowball</span>辞書テンプレートは、有名な「英語用のポーターの語幹アルゴリズム」を発明したMartin Porterのプロジェクトに基づいています。
Snowballは今では多くの言語用の語幹アルゴリズムを提供しています(詳細は<a class="ulink" href="http://snowballstem.org/" target="_top">Snowballのサイト</a>を参照してください)。
各々のアルゴリズムにより、その言語において単語の共通部分を取りだし、基本部もしくは語幹の綴りに縮退させることができます。
Snowball辞書には、どの語幹処理を使うかを識別する<code class="literal">言語</code>パラメータが必須で、加えて、オプションで無視すべき単語のリストを保持する<code class="literal">ストップワード</code>ファイルを指定することもできます。
(<span class="productname">PostgreSQL</span>の標準的なストップワードファイルもまたSnowball projectから提供されています。)
たとえば、以下と同じ組み込みの定義があります。

</p><pre class="programlisting">
CREATE TEXT SEARCH DICTIONARY english_stem (
    TEMPLATE = snowball,
    Language = english,
    StopWords = english
);
</pre><p>

<span class="original">
    The stopword file format is the same as already explained.
</span>
ストップワードファイルの形式はすでに説明されているものと同じです。
   </p><p>
<span class="original">
    A &lt;application&gt;Snowball&lt;/application&gt; dictionary recognizes everything, whether
    or not it is able to simplify the word, so it should be placed
    at the end of the dictionary list. It is useless to have it
    before any other dictionary because a token will never pass through it to
    the next dictionary.
</span>
<span class="application">Snowball</span>辞書は、単純化できるかどうかに関係なく、すべての単語を認識するので、辞書リストの最後に置く必要があります。他の辞書の前に置くのは意味がありません。<span class="application">Snowball</span>辞書は決してトークンを次の辞書に渡さないからです。
   </p></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="textsearch-parsers.html">前へ</a> </td><td width="20%" align="center"><a accesskey="u" href="textsearch.html">上へ</a></td><td width="40%" align="right"> <a accesskey="n" href="textsearch-configuration.html">次へ</a></td></tr><tr><td width="40%" align="left" valign="top">12.5. パーサ </td><td width="20%" align="center"><a accesskey="h" href="index.html">ホーム</a></td><td width="40%" align="right" valign="top"> 12.7. 設定例</td></tr></table></div></body></html>