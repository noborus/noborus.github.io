[{"content":"psql This is the recommended setting for PSQL_PAGER. Header 1 is specified(-H1),\"|\" is used to separate columns(-d “|”), and column mode(-C) is set. If it fits on the screen, exit the pager(-F).\nPSQL_PAGER 'ov -F -C -d \"|\" -H1' The following sets the header style of config.yaml.\nStyleHeader: Background: \"#23274f\" Bold: true StyleColumnHighlight: Foreground: \"lightcyan\" Reverse: true StyleAlternate: Background: \"#2a2a2a\" watch(PostgreSQL 15) A pager is available for WATCH from PostgreSQL version 15. This is the recommended value for PSQL_WATCH_PAGER. Continues to display the last section separated by blank lines.\nPSQL_WATCH_PAGER 'ov --follow-section --section-delimiter \"^$\"' expanded output (\\x) Even when displaying in the extended output (\\x), if the record delimiter is treated as a section delimiter, the display when moved will be easier to see.\nPAGER 'ov -F --section-delimiter \"^-\"' You can also display expanded output (\\x) with \\watch.\nunaligned (\\a) Even in unaligned display, it is displayed comfortably by using column highlighting.\nThe PAGER specification does not change with the following.\nPSQL_PAGER'ov -F -C -d \"|\" -H1'. ","description":"","tags":["ov"],"title":"psql","uri":"/ov/psql/index.html"},{"content":" Guess the width of the width-specified format (April 9, 2023) Another way to aggregate json(jq + SQL) (May 3, 2022) ","description":"","tags":null,"title":"Blog","uri":"/blog/index.html"},{"content":" What I made trdsql Star Fork A tool that can execute SQL on CSV, LTSV, JSON, TBLN files\ntrdsql Blog Created a command line tool called trdsql(Qiita) trdsql is a tool to import CSV, LTSV, JSON into DB (PostgreSQL, MySQL)(Zenn) trdsql Category ov Star Fork Feature-rich terminal Pager\nA highly functional pager that works as a substitute for less and more.\nov pages Introduction to ov(Zenn) Terminal Pager New Era(Qiita) ov Category ovcs Star Fork A client/server version of Terminal Pager ov.\nBy combining terminal pager with client/server and tmux, it became the strongest SQL client tbln Star Fork Libraries and tools that handle file formats (tbln) that are compatible with database tables\ntbln.dev psutilsql Star Fork\nA tool that executes SQL to display system information\nmdtsql Star Fork\nA tool to execute SQL against a markdown table\nmdtsql Category mdviewer Star Fork\nView markdown in pager\npgsp Star Fork\nCLI tool to monitor and display pg_stat_progress of PostgreSQL\npgsp Category go-textra Star Fork\nみんなの自動翻訳@textra’s Library for client API.\njpug-doc-tool Star Fork\nJapanese manual translation tool for PostgreSQL\njpug-doc Category guesswidth Star Fork Library tool to infer column widths in CLI output\nGuess the width of the width format Guess the width of the width-specified format Participating projects jpug-doc A repository for translating PostgreSQL manuals.\n(Qiita) About the PostgreSQL Japanese manual PostgreSQL Japan User Group (Annex) Site with the latest version of the translated manual github Translations PostgreSQL manual translations test version Updated irregularly. There is an experimental change that has not been decided on.\nCSS sample\nlast-updated: 2019-08-06 15:01:23 JST\nTest PDF\n","description":"","tags":null,"title":"Top","uri":"/index.html"},{"content":"Install For Linux/Windows/macOS, Download. It is made in Go and has no other dependent libraries, so it can be deployed and executed immediately.\nDocker If Docker is available, you can also run it with Docker. You can also use docker pull from Docker Hub, so please pull as follows.\ndocker pull noborus/trdsql Mount and use the input file location. Since the result is output to the standard output, it can be received by redirection as it is.\nWhen executing for test.csv in the current directory, it will be as follows.\ndocker run --rm -it -v $(pwd):$(pwd) --workdir $(pwd) noborus/trdsql \"SELECT * FROM test.csv\" \u003e test_new.csv Homebrew You can install it with:\nbrew tap noborus/trdsql brew install trdsql go get If you have a go build environment, you can build it yourself.\ngo get -u -d github.com/noborus/trdsql cd trdsql make 自分の環境用にビルドするのは難しくないと思いますが、クロスコンパイルする場合は、依存しているgo-sqlite3が cgo を使用しているので、注意が必要になります。\nI don’t think it would be difficult to build for your own environment, but if you want to cross-compile, you should check the dependent go-sqlite3 uses cgo so you have to be careful.\nExecution Execute from the terminal.\ntrdsql [OPTIONS] [SQL command] The SQL command specifies a database table, but you can simply specify a file instead of a table.\n","description":"How to install trdsql","tags":["trdsql","install","docker"],"title":"trdsql install","uri":"/trdsql/01_install/index.html"},{"content":"Git calls pager when needed. Git output will be easier to use if each is separated by section-delimiter\nIt is recommended to set the following in gitconfig.\n[pager] diff = ov -F --section-delimiter \"^diff\" log = ov -F --section-delimiter \"^commit\" git log The git log is separated by commit. You will be able to move by commit as shown below.\n[pager] log = ov -F --section-delimiter \"^commit\" git diff git diff is separated by diff or file. You will be able to move in diff units as shown below.\n[pager] diff = ov -F --section-delimiter \"^diff\" ","description":"","tags":["ov"],"title":"git","uri":"/ov/git/index.html"},{"content":"This is the document of trdsql, a tool that can execute SQL on CSV, LTSV, JSON, TBLN files.\nIt was originally written as trdsql Advent Calendar 2019. I am adding it afterwards.\noverview trdsql is a CLI tool that executes SQL on text in table format. A tabular format is data that consists of rows and columns, such as:\n1 column 2 columns 1 row a1 a2 2 lines b1 b2 Since the results can be output in various formats, it can also be used for format conversion of tabular data.\ntable of contents trdsql install (January 1, 1) ","description":"","tags":null,"title":"trdsql","uri":"/trdsql/index.html"},{"content":" Download\nPlease refer to the github site for installation and settings.\nFeatures ov provides a more convenient function by separating text, not only the pager function to display at the terminal size.\nSpecify a fixed line to be displayed as a header. Table-formatted text can be interpreted as a column by the delimiter. Text can be interpreted as a section by splitting the line with a delimiter. Supports files larger than memory. Use case psql (May 19, 2022) git (May 19, 2022) mysql (May 24, 2022) pgcli (May 24, 2022) mycli (May 24, 2022) ps (May 31, 2023) man (May 24, 2022) top (January 30, 2023) procs (May 24, 2022) bat (May 30, 2022) Watch files with ov (May 22, 2022) view csv (May 24, 2022) View markdown (May 24, 2022) multiple files (June 26, 2022) Multicolor highlights multiple words (December 30, 2022) execute command (May 27, 2022) How to use follow mode (May 27, 2022) How to use section (May 26, 2022) Memory management (June 2, 2023) ","description":"","tags":"ov","title":"ov - Feature-rich pager","uri":"/ov/index.html"},{"content":"ov can be used as a pager for mysql or MySQL Shell.\nUse the –pager option with the mysql client.\nmysql --pager='ov -w=f -H3 -F -C -d \"|\"' You can also write in ~/.my.cnf.\n[client] pager=ov -w=f -H3 -F -C -d \"|\" The header line for mysql is 3, but it’s surrounded by a separator line. You can increase the display area by setting the skip line to 1 and the header to 1.\nov -w=f --skip-lines 1 -H1 -F -C -d \"|\"' For mysqlsh, use the --pager option or set it while mysqlsh is running. For example, in js mode, it can be made persistent by the following command.\nshell.options.setPersist(\"pager\",\"ov -H1 --skip-lines 1 -C -w=false -d'|' -F\") SQL mode and Python mode.\n\\option --persist pager \"ov -w=f -H1 --skip-lines 1 -F -C -d '|'\" ","description":"","tags":["ov"],"title":"mysql","uri":"/ov/mysql/index.html"},{"content":"Noboru Saito’s Page.\nnoborus Links GitHub: https://github.com/noborus Twitter: https://twitter.com/noborus Qiita: https://qiita.com/noborus Zenn: https://zenn.dev/noborus ","description":"Noboru Saito","tags":null,"title":"About","uri":"/about/index.html"},{"content":"ov can be set as a pager for pgcli.\n~/.config/pgcli/config\npager = 'ov -C -d \"|\" --skip-lines 1 -H1' ","description":"","tags":["ov"],"title":"pgcli","uri":"/ov/pgcli/index.html"},{"content":"ov can be set as a pager for mycli.\nmycli reads the client section of ~/.my.cnf in mysql. Please refer to https://www.mycli.net/config.\n[client] pager=\"ov -C --skip-lines 1 --header 1 -d'|'\" ","description":"","tags":["ov"],"title":"mycli","uri":"/ov/mycli/index.html"},{"content":"The ps output is properly columned. --column-width can divide columns better than spaces.\nps aux | ov --column-width --column-rainbow -H1 ","description":"","tags":["ov"],"title":"ps","uri":"/ov/ps/index.html"},{"content":"ov can also be used as a man pager.\nMANPAGER=ov In the man page, you can set the color by the StyleOverStrike and StyleOverLine styles.\nStyleOverStrike: Foreground: \"aqua\" Bold: true StyleOverLine: Foreground: \"red\" Underline: true ","description":"","tags":["ov"],"title":"man","uri":"/ov/man/index.html"},{"content":"top works fine when started in batch mode (it doesn’t work as-is when started normally because it steals keystrokes).\nIt is convenient because you can browse the history of top.\ntop -b -c -w512|ov --column-delimiter \"/\\s+/\" --section-delimiter \"^top\" --column-mode --column-rainbow --follow-section -w=false ","description":"","tags":["ov"],"title":"top","uri":"/ov/top/index.html"},{"content":"procs supports pager.\nYou can specify the pager in the configuration file.\nIt is convenient to set header(-H) to 1 or 2.\n[pager] command = \"ov -H=1 -w=false -d=│\" ","description":"","tags":["ov"],"title":"procs","uri":"/ov/procs/index.html"},{"content":"bat supports pager.\nYou can use it by setting the environment variable PAGER or BAT_PAGER.\nexport BAT_PAGER=\"ov -F -H3\" bat should not be wrapped (--wrap=never). If it wraps with bat, it cannot be switched to unwrap. It is better to operate with ov.\nbat --wrap=never README.md ","description":"","tags":["ov"],"title":"bat","uri":"/ov/bat/index.html"},{"content":"ov supports watch mode, which reads files at regular intervals. The file is added every specified time.\nov --watch 1 /proc/meminfo At that time, add formfeed (\\f) instead of EOF. watch mode automatically sets follow-section “\\f”.\n","description":"","tags":["ov"],"title":"Watch files with ov","uri":"/ov/watch/index.html"},{"content":"ov can also be used as a csv viewer.\nov -H1 -C -d',' -c --column-rainbow MOCK_DATA.csv ","description":"","tags":["ov"],"title":"view csv","uri":"/ov/csv/index.html"},{"content":"ov can also be used as a markdown viewer. Specifying the markdown header as a section delimiter makes it easier to move to the next section.\nov --section-delimiter \"^#\" README.md ","description":"","tags":["ov"],"title":"View markdown","uri":"/ov/markdown/index.html"},{"content":"ov can specify multiple files.\n] key to view the next document [ key to view previous document (With default key bindings).\nov *.go ","description":"","tags":["ov"],"title":"multiple files","uri":"/ov/multifile/index.html"},{"content":"ov can highlight multiple words in multiple colors.\nov --multi-color \"ERROR.*,WARN,INFO,DEBUG,not,^.{24}\" access.log input mode Enter regular expressions separated by spaces. Enclose in quotation marks if it contains spaces.\n. multicolor input mode(default key bindings). ERROR.* WARN \"error is\" customize The colors(styles) displayed are customizable. See github size for settings.\nStyleMultiColorHighlight: - Foreground: \"red\" - Foreground: \"aqua\" - Foreground: \"yellow\" - Foreground: \"fuchsia\" - Foreground: \"lime\" - Foreground: \"blue\" - Foreground: \"grey\" ","description":"","tags":["ov"],"title":"Multicolor highlights multiple words","uri":"/ov/multicolor/index.html"},{"content":"Exec mode executes commands from ov. In Exec mode, stdout and stderr can be displayed as separate documents.\nBy using it at the same time as --follow-all, you can display the one that was output last.\nFor example, while displaying the standard output of make and the error output separately, you can switch the screen if there is an error.\nov --follow-all --exec -- make ","description":"","tags":["ov"],"title":"execute command","uri":"/ov/exec/index.html"},{"content":"Output appended data and move it to the bottom line (like tail -f).\nov can perform operations such as search input without stopping follow-mode (also incremental search!).\ndocker run chentex/random-logger:latest 100 400 |ov --follow-mode ","description":"","tags":["ov"],"title":"How to use follow mode","uri":"/ov/tail/index.html"},{"content":"ov can use a unit called section. Sections are blocks separated by section delimiters. The section delimiter line is displayed in the style of StyleSectionLine (background color green).\nThe section delimiter is optionally specified as a regular expression string at startup.\nov --section-delimiter \"^$\" If you want to set the section delimiter after startup, enter it in input mode with the section_delimiter key binding (alt + d).\nSection delimiter: ^$ If section delimiters are not required (blank lines, etc.), --section-start 1 can be used to display from the next line.\n--follow-section uses the section instead of the follow-mode line.\nSuitable for use with \\watch of psql.\n","description":"","tags":["ov"],"title":"How to use section","uri":"/ov/section/index.html"},{"content":"","description":"","tags":null,"title":"Tag :: ov","uri":"/tags/ov/index.html"},{"content":"","description":"","tags":null,"title":"Tags","uri":"/tags/index.html"},{"content":"Memory management Regular file ov is managed by dividing it into Chunks for each ChunkSize (10,000) lines. For example, a file with 73210 lines is divided into 7 chunks. Chunk\nThe first Chunk (Chunk0) is always loaded into memory. Chunk3 and Chunk4 must also be loaded into memory, as they may span two Chunks when displayed. Chunk1 and Chunk2 have been used before and are loaded into memory, but can be freed if they exceed their limits. For regular files, it is possible to save memory and speed by loading and freeing memory while seeking.\nNon-regular file Files that cannot be seek (pipes and compressed files) are also managed in chunk units, but once released, they cannot be loaded into memory, so load them into memory as much as possible. If there is a memory limit, read up to the memory limit and then pause reading.\nThen, for example, when you go to line 41230, Chunk1, Chunk2, and Chunk3 are freed and read ahead from where they are now.\nmemory limit The default memory limit for regular files is 100 (1 million lines). I don’t think you need to change much, but you can specify it with --memory-limit-file.\nov --memory-limit-file 10 large.log The default memory limit for non-regular files is -1 ( unlimited).\nIt is recommended to limit this according to memory. It is recommended to set MemoryLimit: 10000(or 1000) in ov.yaml.\nMemoryLimit: 10000 You can also use options like --memory-limit 1000.\ncommand | ov --memory-limit 1000 Even with the memory limit option specified, large files can still use a lot of memory. Setting GOMEMLIMIT to run GC frequently will also suppress temporary memory increase.\nexport GOMEMLIMIT=400MiB ov --memory-limit-file 10 large.log ","description":"","tags":null,"title":"Memory management","uri":"/ov/memory/index.html"},{"content":"","description":"","tags":null,"title":"Categories","uri":"/categories/index.html"},{"content":"","description":"","tags":null,"title":"Category :: ov","uri":"/categories/ov/index.html"},{"content":"For a long time now, Unix-like commands and CLI have been outputting width-aligned output. ls, ps, df, etc…\nSuch output can be produced by a printf format specification.\nIf this format specification is known, it can be read by scanf, but it is not easy to recognize and read columns from “just the output”.\nIf multiple spaces are considered as delimiters, it is possible to divide the output into columns, but headers and values may cause unnecessary division. We have created a library/tool to guess the column width so that this can be read by humans.\nguesswidth Made by Go.\nIt is difficult to read perfectly, but I think it gives better results than space-separated regular expressions.\nThe main thing that can be read is if there is a header row and the width of the header column represents the width of the values in the rows that follow.\nThis is the case for ps and df. In ls, there is no header row, so the column delimiters are ambiguous.\nIn ps, “PID”, “TTY”, “TIME”, and “CMD” represent the lower values, and can be divided into four parts:\nIn this example, multiple spaces can be split, but if the header or value contains spaces, it cannot be split correctly. guesswidth supports such formats.\nTo use guesswidth, simply pass in the pipe |. By default, | is inserted as a delimiter.\nps |guesswidth PID| TTY | TIME|CMD 1145448| pts/2 | 00:00:00|zsh 1158532| pts/2 | 00:00:00|ps You can also separate them as CSV with “,” separators; in CSV, extra spaces are stripped.\nps |guesswidth csv PID,TTY,TIME,CMD 1145448,pts/2,00:00:00,zsh 1158532,pts/2,00:00:00,ps Support for ps, df, docker ps and many other outputs. The ls has no header, so it is split based on the contents of the first line. (The first line is a total display and must be removed from the criteria.)\nls -l|guesswidth --header 2 合計 7900|||||||| -rw-r--r--| 1| noborus| noborus| 1078| Mar| 14| 05:48|LICENSE -rw-r--r--| 1| noborus| noborus| 526| Mar| 16| 05:23|Makefile -rw-r--r--| 1| noborus| noborus| 1751| Mar| 21| 16:49|README.md The modern ls alternative, exa, can add header lines, so it’s more GUESSWIDTH oriented.\n$ exa -lh|guesswidth Permissions| Size| User | Date Modified|Name drwxr-xr-x | -| noborus| 14 Mar 16:30 |cmd drwxr-xr-x | -| noborus| 22 Mar 09:02 |dist drwxr-xr-x | -| noborus| 19 Mar 12:58 |docs .rw-r--r-- | 3.0k| noborus| 21 Mar 16:39 |example_test.go .rw-r--r-- | 285| noborus| 4 Apr 14:22 |go.mod .rw-r--r-- | 1.2k| noborus| 4 Apr 14:22 |go.sum How do you do that? Guess where the split is? The division method is not difficult, but it is a bit annoying, so I will explain it.\nFirst, a reference line (header line) is determined. Without this base line, some values will be incorrectly split there (as in the ls example) because some formats have a space in the same position.\nFrom that reference line, we create candidates for the delimiter position. Simply convert to 1 (candidate) if it is a space, otherwise convert to 0 (not a delimiter position).\nFor simplicity, take ps as an example.\nPID TTY TIME CMD 11110001000111111111100001000 Next, the values are candidates for spaces as well, but exclude positions that are not candidates in the header and count up.\nValue 1st line\n1145448 pts/2 00:00:00 zsh 11110002000112222111100002000 Value 2nd line\n1158532 pts/2 00:00:00 ps 11110003000113333111100003000 The first and last spaces are omitted due to the nature of the search for delimiters. The largest number in the sequence of 0 (not a delimiter) numbers is the most likely candidate for a delimiter position.If we consider that position as a delimiter, we can guess the delimiter position.\nIf there is a sequence of even larger numbers in the same point, it is not possible to make a judgment, but due to the characteristics of printf, the numbers do not extend to the left but to the right, so the rightmost number is guessed as the delimiter position.\nIf we leave the numbers only at the delimiter position, we get the following.\n11110003000113333111100003000 ↓ 3 1133331111 3 ↓ 3 3 3 The accuracy is increased by reading as many lines of values as possible, not just the header lines, before determining the value.\nSplitting process If the position of the division can be guessed, that is not the end of the process. As mentioned above, although the format outputs the data with a specified width, it is often the case that the data does not fit into the specified width and extends beyond the specified width.\nFor example, if you use the option ps, you can display more information, but there are many items that will be overflowed.\n$ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 169004 11464 ? Ss Mar27 1:04 /sbin/init sp root 2 0.0 0.0 0 0 ? S Mar27 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? I\u003c Mar27 0:00 [rcu_gp] and you think the vertical position is nicely displayed,\nnoborus 619043 0.0 0.0 38992 28968 pts/4 Ss+ Apr04 0:02 zsh noborus 1061523 2.2 1.8 34556112 591016 ? SLl Apr06 61:54 /opt/google/chrome/chrome and VSZ and RSS are overhanging memory-intensive processes like chrome processes.\nSo if the delimiter position is not a space, many will shift to the right and look for a space to compensate for the delimiter position (in fact, they will even try to shift to the left to see if it fits, in case they guessed the delimiter position wrong and shifted to the right).\nOther considerations Although the header line is the standard, spaces are sometimes used in header line headings.\nFor example, in df the last Mounted on is a single column.\nFilesystem 1K-blocks Used Available Use% Mounted on Therefore, if there is a space only in the header line position and no space in the value below it, the delimiter position is prevented by setting the threshold to 2 or more, because if the value is an array of numbers, it will not be counted up and will remain at 1.\nlibrary The guesswidth is an independent version originally created for use in another tool.\nI also incorporated it into my trdsql, so you can use -iwidth to output in various formats as follows.\nps aux|trdsql -iwidth -ojson \"SELECT * FROM - WHERE \\\"COMMAND\\\" = 'ps aux'\" [ { \"USER\": \"noborus\", \"PID\": \"1166430\", \"%CPU\": \"0.0\", \"%MEM\": \"0.0\", \"VSZ\": \"13716\", \"RSS\": \"3520\", \"TTY\": \"pts/2\", \"STAT\": \"R+\", \"START\": \"17:56\", \"TIME\": \"0:00\", \"COMMAND\": \"ps aux\" } ] Also, this is actually the real deal, but I have also incorporated it into my pager ov (still working on it before release), and by combining the options, you can display the following.\nps aux| ov ","description":"","tags":["guesswidth"],"title":"Guess the width of the width-specified format","uri":"/blog/guesswidth/index.html"},{"content":"","description":"","tags":null,"title":"Tag :: guesswidth","uri":"/tags/guesswidth/index.html"},{"content":"","description":"","tags":null,"title":"Category :: guesswidth","uri":"/categories/guesswidth/index.html"},{"content":"Aggregate json with trdsql I agree that the aggregation of jq described in the Introducing zq is not easy.\nI’ve seen A Practical Example of zq, zq was not easy for me.\nSQL is not easy for everyone, but it is a language that many people can use. I am one of them.\nOf course, it is difficult to process all JSON with SQL. But what about using them in combination?\nRecent versions of trdsql allow the use of jq syntax, including gojq.\nIn addition, I’ve improved the handling of null in JSON in the latest version, making it easier to aggregate JSON.\nLet’s try with the e jq and zq examples.\njq jq '[.docs[] | {title,author_name: .author_name[0], publish_year: .publish_year[0]} | select(.author_name!=null and .publish_year!=null)] | group_by(.author_name)| [.[] |{author_name: .[0].author_name, count: . | length}] | sort_by(.count) | reverse | limit(3;.[])' openlibrary.json { \"author_name\": \"S. Stepniak\", \"count\": 38 } { \"author_name\": \"Władysław Stępniak\", \"count\": 7 } { \"author_name\": \"Władysław Stępniak\", \"count\": 4 } zq zq -j \"over docs | {title, author_name: author_name[0], publish_year: publish_year[0]}| has(author_name) and has(publish_year)| count() by author_name | sort -r count | head 3\" openlibrary.json {\"author_name\":\"S. Stepniak\",\"count\":38} {\"author_name\":\"Władysław Stępniak\",\"count\":11} {\"author_name\":\"Andrzej Stępniak\",\"count\":4} trdsql trdsql treats JSON(jq processed JSON) as a table and executes SQL.\ntrdsql -driver sqlite3 -ojsonl \"SELECT json(author_name)-\u003e\u003e0 AS author_name, count(*) AS count FROM openlibrary.json::.docs WHERE author_name IS NOT NULL AND publish_year IS NOT NULL GROUP BY json(author_name)-\u003e\u003e0 ORDER BY count DESC LIMIT 3\" {\"author_name\":\"S. Stepniak\",\"count\":38} {\"author_name\":\"Władysław Stępniak\",\"count\":7} {\"author_name\":\"Władysław Stępniak\",\"count\":4} The “.docs” after the “::” in “openlibrary.json::.docs” is the jq syntax. Only this part is jq syntax, and the others are SQL.\ntrdsql just includes the gojq library, which eliminates the need for the jq command. This is the same as passing jq as a filter.\njq .docs openlibrary.json| trdsql -driver sqlite3 -ijson -ojsonl \"SELECT json(author_name)-\u003e\u003e0 AS author_name, count(*) AS count FROM - WHERE author_name IS NOT NULL AND publish_year IS NOT NULL GROUP BY json(author_name)-\u003e\u003e0 ORDER BY count DESC LIMIT 3\" sqlite3 does not yet have a standard unicode normalization function. However, PostgreSQL has a normalize function.\ntrdsql -driver postgres -dsn \"dbname=trdsql\" -ojsonl \"SELECT json(normalize(author_name))-\u003e\u003e0 AS author_name, count(*) AS count FROM openlibrary.json::.docs WHERE author_name IS NOT NULL AND publish_year IS NOT NULL GROUP BY json(normalize(author_name))-\u003e\u003e0 ORDER BY count DESC LIMIT 3\" {\"author_name\":\"S. Stepniak\",\"count\":38} {\"author_name\":\"Władysław Stępniak\",\"count\":11} {\"author_name\":\"Andrzej Stępniak\",\"count\":4} I don’t think it’s right to use SQL for everything, but I’d like to argue that there are enough problems with people who are good at SQL.\nLink trdsql(github) gojq(github) [zed](https://github.com/brimdata/zed(github)(zq) jq(github) ","description":"","tags":["trdsql","jq","SQL","zq"],"title":"Another way to aggregate json(jq + SQL)","uri":"/blog/jqsql/index.html"},{"content":"","description":"","tags":null,"title":"Tag :: jq","uri":"/tags/jq/index.html"},{"content":"","description":"","tags":null,"title":"Tag :: SQL","uri":"/tags/sql/index.html"},{"content":"","description":"","tags":null,"title":"Tag :: trdsql","uri":"/tags/trdsql/index.html"},{"content":"","description":"","tags":null,"title":"Tag :: zq","uri":"/tags/zq/index.html"},{"content":"","description":"","tags":null,"title":"Tag :: docker","uri":"/tags/docker/index.html"},{"content":"","description":"","tags":null,"title":"Tag :: install","uri":"/tags/install/index.html"},{"content":"","description":"","tags":null,"title":"Category :: trdsql","uri":"/categories/trdsql/index.html"}]