<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Trdsql on Noboru Saito&#39;s page</title>
    <link>https://noborus.github.io/categories/trdsql/index.html</link>
    <description>Recent content in Trdsql on Noboru Saito&#39;s page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 27 Jan 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://noborus.github.io/categories/trdsql/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>trdsql install</title>
      <link>https://noborus.github.io/trdsql/01_install/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/01_install/index.html</guid>
      <description>Install For Linux/Windows/macOS, Download. It is made in Go and has no other dependent libraries, so it can be deployed and executed immediately.
Docker If Docker is available, you can also run it with Docker. You can also use docker pull from Docker Hub, so please pull as follows.
docker pull noborus/trdsql Mount and use the input file location. Since the result is output to the standard output, it can be received by redirection as it is.</description>
    </item>
    <item>
      <title>trdsql File format conversion</title>
      <link>https://noborus.github.io/trdsql/02_convert/index.html</link>
      <pubDate>Sat, 10 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/02_convert/index.html</guid>
      <description>TRDSQL describes files such as CSV as a tool for processing SQL, but can also be used as a tool for simply converting file formats.
In that case, SQL is enough to remember the following fixed phrases. Output all rows and columns in the file.
SELECT * FROM fileNameAfter that, if you specify the input format (-i &amp;hellip;) and the output format (-o &amp;hellip;) as the option, you can convert the file format.</description>
    </item>
    <item>
      <title>trdsql Easy SQL </title>
      <link>https://noborus.github.io/trdsql/03_sql/index.html</link>
      <pubDate>Mon, 12 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/03_sql/index.html</guid>
      <description>By using trdsql and simple SQL, you can do something that can be done by combining other UNIX tools.
File analysis If you want to run a simple SQL from SELECT * FROM, you need to know the column name in advance. If you execute the file name to the -a option to the -a option, it will analyze the file and output information. (If the extension of the CSV file is like .</description>
    </item>
    <item>
      <title>trdsql simple SQL 2</title>
      <link>https://noborus.github.io/trdsql/04_sql2/index.html</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/04_sql2/index.html</guid>
      <description>Search condition Last time, we sorted columns, extracted, and sorted rows, so this time we will extract rows. To extract rows, add WHERE and write the search condition.
We will use the same example file as last time.
trdsql -ih &amp;#34;SELECT id, \`name\` FROM header.csv WHERE id=1&amp;#34; 1,OrangeThis is the main feature of SQL. Just write the search condition and you can output the corresponding rows.
AND, OR You can write complex conditions by using AND, OR, and () parentheses.</description>
    </item>
    <item>
      <title>trdsql Aggregation</title>
      <link>https://noborus.github.io/trdsql/05_aggregate/index.html</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/05_aggregate/index.html</guid>
      <description>COUNT(*) First is COUNT(*). You can count the total number of cases.
When using aggregate functions, the original row and column data is not output, and the aggregated result is output from there.
The following example does not look like a CSV because the result is one line, but it is output as a one-line, one-column CSV with a header.
Although it simply counts the number of cases, care must be taken not to include the number in the interpretation of the header.</description>
    </item>
    <item>
      <title>trdsql aggregation calculation</title>
      <link>https://noborus.github.io/trdsql/06_calculation/index.html</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/06_calculation/index.html</guid>
      <description>Aggregation calculation Of course, you can aggregate calculations as well as COUNT() for aggregation. SQL has a set of aggregation functions that perform calculations on numbers.
Here we explain with an example of a CSV file like the following.
name,price apple,100 orange,50 melon,500 apple,90 apple,90 orange,40 orange,40SUM Calculate the sum. Add all the price columns.
trdsql -ih &amp;#34;SELECT SUM(price) FROM sample.csv&amp;#34; 910As I wrote before, trdsql treats columns as text types, so you need to CAST them to numeric types before calculating them.</description>
    </item>
    <item>
      <title>trdsql GROUP aggregation</title>
      <link>https://noborus.github.io/trdsql/07_group/index.html</link>
      <pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/07_group/index.html</guid>
      <description>GROUP BY When aggregating, you may want to calculate the total of the entire table, but you may also want to output the total of each group.
For example, if you have a CSV file like the following.
name,price apple,100 orange,50 melon,500 apple,90 apple,90 orange,40 orange,40If you want to calculate the total of each name, you can do the following.
trdsql -ih &amp;#34;SELECT name,SUM(CAST(price AS INT)) as sum FROM sample.csv WHERE name=&amp;#39;apple&amp;#39;&amp;#34; apple,280trdsql -ih &amp;#34;SELECT name,SUM(CAST(price AS INT)) as sum FROM sample.</description>
    </item>
    <item>
      <title>trdsql Log aggregation</title>
      <link>https://noborus.github.io/trdsql/08_log/index.html</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/08_log/index.html</guid>
      <description>Log aggregation Apache and nginx Log are also becoming established in the way of outputting in LTSV format.
An example of analyzing such Log with trdsql.
The output side customizes the apache LogFormat setting to the following custom format.
LogFormat &amp;#34;host:%h\tident:%l\tuser:%u\ttime:%t\treq:%r\tstatus:%&amp;gt;s\tsize:%b\treferer:\%{Referer}i\tua:%{User-Agent}i&amp;#34; combined_ltsvThe items host, ident, user, time, req, status, size, referer, ua are output.
The actual Log looks like this.
host:176.99.192.42	ident:-	user:-	time:[21/Oct/2019:21:33:53 +0900]	req:GET /category/software HTTP/1.1	status:200	size:138	referer:-	ua:Mozilla/5.</description>
    </item>
    <item>
      <title>trdsql wildcard, compressed file</title>
      <link>https://noborus.github.io/trdsql/09_wildcard/index.html</link>
      <pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/09_wildcard/index.html</guid>
      <description>Wildcard Up to this point, we have targeted one file, but log files, etc. may be rotated and become multiple files.
If the target file is composed of the same columns, you can use wildcards to treat multiple files as one table.
ls test*.csv test1.csv test2.csv test3.csvtrdsql -icsv &amp;#34;SELECT COUNT(*) FROM test*.csv&amp;#34; 15Compressed files Old log files might be compressed. If they are compressed with [gzip, bzip2, zstd, lz4, xz], they will be automatically decompressed and processed.</description>
    </item>
    <item>
      <title>trdsql 標準入力</title>
      <link>https://noborus.github.io/trdsql/10_stdin/index.html</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/10_stdin/index.html</guid>
      <description>標準入力 trdsqlは他のUNIXツールのように標準入力からデータを受け取ることができます。ただSQLの文法上テーブル名を指定する必要があります。標準入力を使用するときは、「-」か「stdin」を使用します。
cat test.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; apple,100 orange,50 potato,30 trdsqlは標準入力から受け取りますが、標準入力をすべて受け取り終わってからSQLの実行が開始されます。 そのため終わらないコマンドからの出力を受け取ることはできません。
CSV、LTSV、JSONを出力するコマンドでは、ファイル名の代わりに標準入力を使えばそのまま利用できます。 例えば、文字コードがUTF-8でないファイルをUTF-8に変更してそのまま使用したり、
nkf -w sjis.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; 大きなファイルを処理する前に先頭の数行のみを処理して試してみたりできます。
head -100 big.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; それ以外にも、例えばUNIX系のコマンドでは、スペースを区切りとして解釈すればテーブルデータとして扱える出力をするコマンドが数多くあります。
例えば psコマンドでは、
ps PID TTY TIME CMD 1157 pts/3 00:00:00 ps 22590 pts/3 00:00:03 zshのようにヘッダーがあり、それぞれの列を出力しています（trdsqlでは連続したスペースの区切り文字は一つとして解釈するように動作します）。
そのため、以下のように実行すると Ascii Table形式で出力できます。
ps|trdsql -ih -id &amp;#34; &amp;#34; -oat &amp;#34;SELECT \`PID\`, \`TTY\`, \`TIME\`, \`CMD\` FROM -&amp;#34; +-------+-------+----------+--------+ | PID | TTY | TIME | CMD | +-------+-------+----------+--------+ | 1363 | pts/3 | 00:00:00 | ps | | 1364 | pts/3 | 00:00:00 | trdsql | | 22590 | pts/3 | 00:00:03 | zsh | +-------+-------+----------+--------+標準入力の解析 また、trdsqlの-a解析オプションは標準入力も使用することが出来ます。</description>
    </item>
    <item>
      <title>trdsql 処理の概要</title>
      <link>https://noborus.github.io/trdsql/11_summary/index.html</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/11_summary/index.html</guid>
      <description>ここでtrdsqlの内部処理の概要を簡単に説明します。
trdsqlの内部処理は、以下のようになっています。
オプションやSQLコマンドの解釈 SQLコマンド内のファイル名をデータベースにインポート SQLの実行 指定された出力フォーマットで実行結果を出力 SQLの実行は実際のRDBMSを使用して実行されます（デフォルトではSQLite3のメモリデータベース)。
trdsqlはインポートとエクスポートの形式を整えているだけで、データベースに丸投げしているツールと言えます。
そのため、他の1行づつ処理するようなストリーミングができるツールとは違い、一旦全部のデータをインポートしてから実行されるため、非常に大きなデータではSQLの実行開始までに時間がかかります。
しかしながら、SQLライクではなく本当のSQLが使用できます。
これらの特徴を踏まえて使用すると良いでしょう。</description>
    </item>
    <item>
      <title>trdsql PostgreSQLエンジンの使用</title>
      <link>https://noborus.github.io/trdsql/12_postgres/index.html</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/12_postgres/index.html</guid>
      <description>trdsqlは組込みのSQLite3を利用してSQLを実行していますが、データベースの処理を別のデータベースに変更出来ます。
ここではPostgreSQLを使用する方法を説明します。
PostgreSQLに接続 SQLite3と違いPostgreSQLは動作しているPostgreSQLサーバーが必要です。接続できテーブルが作成できる権限があるデータベースを作成しておきます。
オプションの -driver に postgres を指定し、-dsn にサーバーへの接続情報を指定します。
dsnの項目には以下が指定できます。デフォルトの場合は省略可能です。
項目名 説明 dbname データベース名（デフォルト:ログインユーザー名） user ユーザー名（デフォルト:ログインユーザー名） password パスワード（デフォルト:なし） host ホスト名又はIPアドレス（デフォルト:localhost） port ポート番号(デフォルト: 5432) sslmode SSLモード（デフォルト: require） fallback_application_name （提供されない場合の）アプリケーション名（デフォルト:なし） connect_timeout 接続の最大待機時間 sslcert 証明書ファイルの場所 sslkey 秘密鍵ファイルの場所 sslrootcert ルート証明書ファイルの場所 項目=値をスペース区切りで指定します。
DSN指定 例えば、ローカルホストのportが5433でデータベース名がtrdsql_testに接続するには以下のようにします。
trdsql -driver postgres -dsn &amp;#34;host=localhost port=5433 dbname=trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; UNIXドメインソケット UNIXドメインソケットへ接続もできます。
パッケージ等でPostgreSQLをインストールすると以下のような場所にUNIXドメインソケットファイルが作成されています。
/var/run/postgresql/.s.PGSQL.5432上記の場合、hostに/var/run/postgresql/を指定します。「/」から始まるとUnixドメインソケットとみなされます。portは.s.PGSQL.の後にある「5432」を指定します。
trdsql -driver postgres -dsn &amp;#34;host=/var/run/postgresql/ port=5432 dbname=trdsql_test&amp;#34; &amp;#34;SELECT VERSION()&amp;#34; &amp;#34;PostgreSQL 10.10 (Ubuntu 10.10-0ubuntu0.18.04.1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 7.</description>
    </item>
    <item>
      <title>trdsql MySQLエンジンの使用</title>
      <link>https://noborus.github.io/trdsql/13_mysql/index.html</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/13_mysql/index.html</guid>
      <description>前回はPostgreSQL接続の話でしたが、今度はMySQLに接続して使用する方法を説明します。
MySQLに接続 MySQLに接続するには動作しているMySQLサーバーが必要です。接続できテーブルが作成できる権限があるデータベースを作成しておきます。
オプションの -driver に mysql を指定し、-dsn にサーバーへの接続情報を指定します。
MySQLのdsnは以下のような形式です。
ユーザー名:パスワード@プロトコル(ホスト名:ポート番号)/データベース名?param=valueparam=valueのパラメーターは多くの種類がありますので、go-sql-driverを参照して下さい。
UNIXドメインソケット ローカルホストのデフォルトのUNIXドメインソケットを使用する場合は、ユーザー名、パスワード、データベース名を指定すれば接続できます。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; UNIXドメインソケットのパスを指定するには、プロトコルにunixを指定して、unix(パス)で指定します。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@unix(/var/run/mysqld/mysqld.sock)/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; TCP接続 TCPはプロトコルにtcpを指定して、tcp(ホスト名:ポート番号)を指定します。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@tcp(localhost:3306)/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; 実テーブルの出力 接続できれば、これまでと同じようにSQLが実行できますが、実際に実行されるのはMySQL上なので、MySQLが実行できるSQLを書く必要があります。
前回のPostgreSQLと同様にMySQLのテーブルに対してSQLを実行し、オプションで指定したフォーマットで出力することが出来ます。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@/trdsql_test&amp;#34; -oat -ih &amp;#34;SELECT * FROM actor LIMIT 10&amp;#34; +----------+------------+--------------+---------------------+ | actor_id | first_name | last_name | last_update | +----------+------------+--------------+---------------------+ | 1 | PENELOPE | GUINESS | 2006-02-15 04:34:33 | | 2 | NICK | WAHLBERG | 2006-02-15 04:34:33 | | 3 | ED | CHASE | 2006-02-15 04:34:33 | | 4 | JENNIFER | DAVIS | 2006-02-15 04:34:33 | | 5 | JOHNNY | LOLLOBRIGIDA | 2006-02-15 04:34:33 | | 6 | BETTE | NICHOLSON | 2006-02-15 04:34:33 | | 7 | GRACE | MOSTEL | 2006-02-15 04:34:33 | | 8 | MATTHEW | JOHANSSON | 2006-02-15 04:34:33 | | 9 | JOE | SWANK | 2006-02-15 04:34:33 | | 10 | CHRISTIAN | GABLE | 2006-02-15 04:34:33 | +----------+------------+--------------+---------------------+</description>
    </item>
    <item>
      <title>trdsql SQLite3エンジンの使用</title>
      <link>https://noborus.github.io/trdsql/14_sqlite3/index.html</link>
      <pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/14_sqlite3/index.html</guid>
      <description>SQLite3への接続方法を説明します。
SQLite3に接続 そもそもtrdsqlのデフォルトはSQLite3のメモリデータベースに接続していますが、メモリデータベース以外にも接続できます。
オプションの -driver に sqlite3 を指定し、-dsn にサーバーへの接続情報を指定します。
dsnはsqlite3のデータファイル名を指定すれば、そのファイルをデータベースとして使用します。 （ファイル名の指定の仕方はfile: や file:// 等も可能です）。
あらかじめファイルが無い場合もエラーにはなりません。
trdsql -driver sqlite3 -dsn &amp;#34;test.sqlite&amp;#34; -oat &amp;#34;SELECT * FROM test&amp;#34; +----+--------+-------+ | id | name | price | +----+--------+-------+ | 1 | Orange | 50 | | 2 | Melon | 500 | | 3 | Apple | 100 | +----+--------+-------+さらに「?」で続けて、オプションを渡すこともできます。 メモリデータベースでオプションを渡すときには 「:memory:?」の後にオプションを続けて下さい。
例えば、LIKEで大文字小文字を区別するように変更するには以下のようにします。
デフォルトではLIKEは大文字小文字が区別されない。
trdsql -driver sqlite3 -dsn &amp;#34;:memory:&amp;#34; -ih &amp;#34;SELECT * FROM header.csv WHERE name LIKE &amp;#39;%a%&amp;#39;&amp;#34; 1,Orange 3,Apple_cslike=trueにすると大文字小文字が区別されます。</description>
    </item>
    <item>
      <title>trdsql DBインポート</title>
      <link>https://noborus.github.io/trdsql/15_import/index.html</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/15_import/index.html</guid>
      <description>trdsqlにはデータベースにインポートするオプションはありません。 しかしながら、SELECT以外のSQLの実行も可能なので、SQLによるインポートが可能です。
以下は、メモリデータベースにインポートしても終了すると消えてしまうので、メモリデータベース以外のデータベースに接続して実行します。
CREATE TABLE AS テーブルを作成してインポートするには CREATE TABLE ASを使用します。
PostgreSQL で CREATE TABLE AS まず、PostgreSQLへデータをインポートしてみます。 これまで、SELECTで実行してきた内容に CREATE TABLE テーブル名 AS を前につければ、テーブルが作成されデータがインポートされます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih \ &amp;#34;CREATE TABLE test AS SELECT * FROM header.csv&amp;#34;成功した場合、何も表示されずに終了します。失敗した場合、エラーが表示されます。
SELECTの結果がインポートされるため、SELECT側で列名の変更、列の型指定、インポートするデータの条件指定をすれば良いことになります。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih \ &amp;#34;CREATE TABLE fruits AS SELECT id::int AS num, name::VARCHAR(20) FROM header.csv&amp;#34;trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih -oh\ &amp;#34;SELECT * FROM fruits&amp;#34; num,name 1,Orange 2,Melon 3,Appleもし、テーブルの作成のみを先にして、INSERTを後でおこないたい場合はWITH NO DATAを付けます。</description>
    </item>
    <item>
      <title>trdsql JOIN</title>
      <link>https://noborus.github.io/trdsql/16_join/index.html</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/16_join/index.html</guid>
      <description>これまで一つのファイルにSQLを実行してきましたが、複数のファイルをJOINするSQLも実行できます。
以下の2つのCSVファイルがあったとして、
abc.csv
1,AAA 2,BBB 3,CCCprice.csv
1,100 2,500 3,50以下のように連結するのが、JOINです。
1,AAA,100 2,BBB,500 3,CCC,50trdsqlではテーブルの代わりにファイル名を使用すれば、そのままSQLのJOINが書けます。
trdsql &amp;#34;SELECT a.c1, a.c2, p.c2&amp;#34; \ &amp;#34;FROM abc.csv AS a&amp;#34; \ &amp;#34;LEFT JOIN price.csv AS p&amp;#34; \ &amp;#34;USING (c1)&amp;#34;同じ件数で対応する同じ列がある1対1のJOINのため、INNER JOINと同じ結果になります。 LEFT JOINの場合は、先に指定したabc.csvの行はすべて表示され、price.csvは対応する行がある場合のみ表示されます。 今回はヘッダーがないCSVなので、列名はc1,c2&amp;hellip;の共通になるため、一番左側(c1)が共通の列としてUSINGを使用してます。これは ON a.c1 = p.c1 と同じ意味になります。
複数のCSVをJOINするときには、ヘッダーの有無を統一しておく必要があります。
しかしながら、自動判別可能な拡張子になっていれば、CSVとLTSV等の混在は可能です。
unit.ltsv
id:1	unit:個 id:2	unit:箱先程のCSVのJOINの結果に更にLTSVをJOINします。
trdsql -oat \ &amp;#34;SELECT a.c1, a.c2, p.c2, unit&amp;#34; \ &amp;#34; FROM abc.csv AS a&amp;#34; \ &amp;#34;LEFT JOIN price.csv AS p&amp;#34; \ &amp;#34;USING (c1)&amp;#34; \ &amp;#34;LEFT JOIN unit.</description>
    </item>
    <item>
      <title>trdsql ファイルとテーブルのJOIN</title>
      <link>https://noborus.github.io/trdsql/17_file_table/index.html</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/17_file_table/index.html</guid>
      <description>既にテーブルが存在するデータベースに接続することにより、ファイルとテーブルをJOINすることもできます。
例えば、データベース内にfruitsというテーブルがあった場合に、前回のabc.csvとJOINできます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; \ &amp;#34;SELECT a.c1, a.c2, f.name FROM abc.csv AS a &amp;#34;\ &amp;#34;LEFT JOIN fruits AS f ON (CAST(a.c1 AS int) = f.id)&amp;#34; 1,AAA,Orange 2,BBB,Melon 3,CCC,Apple例えば、データベース上にusersテーブルがあり、抽出したいリストがCSVファイルであった場合に、リストをWHERE user IN (...)で並べる等を検討するところですが、trdsqlではダイレクトにJOINして抽出できます。
list.csv
tarou jirou noborususersテーブル
id,name 1,taizou 2,momo 3,taroutrdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; \ &amp;#34;SELECT u.id, u.name FROM users AS u &amp;#34;\ &amp;#34;INNER JOIN list.csv AS l ON (u.name = l.c1)&amp;#34; 3,tarou逆にCSVファイルにデータベースのテーブルから情報を足すといったことも考えられます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; \ &amp;#34;SELECT u.</description>
    </item>
    <item>
      <title>trdsql 列の編集</title>
      <link>https://noborus.github.io/trdsql/18_edit_columns/index.html</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/18_edit_columns/index.html</guid>
      <description>これまで列の並べ替えはしてきましたが、列の内容はそのままでした。 SQLでは、文字列の書き換えが得意分野とは言えませんが、SQLの関数を使うことにより、それなりできる機能は揃っています。
列の連結 「||」を使って、列名をつなげば、２つ以上の列を連結して一つの列になります。
trdsql -ih -oh \ &amp;#34;SELECT id,name||id AS name_id FROM header.csv&amp;#34; id,name_id 1,Orange1 2,Melon2 3,Apple3列と列だけでなく、文字列をそのまま連結も可能です。SQLの文字列は「&amp;rsquo;」シングルクオートで括ります。
trdsql -ih -oh \ &amp;#34;SELECT id,name||&amp;#39;_&amp;#39;||id AS name_id FROM header.csv&amp;#34; id,name_id 1,Orange_1 2,Melon_2 3,Apple_3PostgreSQL、MySQL またPostgreSQLとMySQLでは、複数の列をつなげたいときには concat(列名or文字列,列名or文字列,&amp;hellip;) が使用できます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih -oh \ &amp;#34;SELECT concat(id,name,&amp;#39;個&amp;#39;) FROM header.csv&amp;#34; concat 1Orange個 2Melon個 3Apple個接続文字を付けてつなげたい場合は、concat_ws(接続文字,列名or文字列,列名or文字列,&amp;hellip;)が使用できます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih -oh \ &amp;#34;SELECT concat_ws(&amp;#39; &amp;#39;,id,name,&amp;#39;個&amp;#39;) FROM header.csv&amp;#34; concat_ws 1 Orange 個 2 Melon 個 3 Apple 個SQLite3 SQLite3では、concat,concat_wsはありませんが、printfが使用できますので、より柔軟に文字列を生成できます。</description>
    </item>
    <item>
      <title>trdsql Window関数</title>
      <link>https://noborus.github.io/trdsql/19_window/index.html</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/19_window/index.html</guid>
      <description>これまでグループ集計による集計を紹介していますが、グループ集計は元の行とはまったく別にグループ毎の行を出力していました。 つまり、元のファイルとは別に集計の結果を出力していた訳です。
そうではなくて、元のファイルの情報にプラスして集計結果を出して欲しい場合があります。 例えば、点数の列では、点数の平均との差を出力したり、柔軟な計算が出来るようになります。これまでの方法では、一旦集計してからJOINするしかありませんでしたが、SQLのWindow関数を使うとそういった集計も出すことが出来ます。
古いバージョンではSQLite3では、Window関数を使用できませんでしたが、現在のtrdsqlに含まれているSQLite3では、Window関数を使用できます。
PostgreSQLやMySQLでもWindow関数が使用できますが、MySQLは8.0からなので、注意が必要です。
合計の表示 合計の計算は集計計算で出しましたが、最後の結果のみを出力していました。 Window関数では、行毎に結果を表示できます。
例えば、以下のような点数のCSVについて結果を表示してみます。
id,class,name,score 1,A,bob,174 2,A,alice,248 3,A,carol,163 4,B,dave,289 5,B,eve,157 6,B,flank,272Window関数は集約関数の関数にOVER ()句を付けることにより範囲や、順序を指定することにより計算をおこないます。 OVER ()句があることで、他の列とは独立して対象の行以外を計算できます。
OVER()句を空で指定すると全行が対象となります。
trdsql -ih -omd \ &amp;#34;SELECT id,name,score, SUM(CAST(score AS int)) OVER () FROM score.csv&amp;#34; | id | name | score | sum | |----|-------|-------|------| | 1 | bob | 174 | 1303 | | 2 | alice | 248 | 1303 | | 3 | carol | 163 | 1303 | | 4 | dave | 289 | 1303 | | 5 | eve | 157 | 1303 | | 6 | flank | 272 | 1303 |SUM()で合計が求められるので、AVG()で平均も求められます。</description>
    </item>
    <item>
      <title>trdsql 日付・時刻処理</title>
      <link>https://noborus.github.io/trdsql/20_date/index.html</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/20_date/index.html</guid>
      <description>ファイル内に入っている日付、時刻をそのまま扱う場合は良いですが、変換等の処理をしたい場合があります。
その場合は、一旦日付や時刻と解釈させてから扱う方が扱いやすくなります。
SQLite3の日付、時刻処理 デフォルトのSQLite3の日付、時刻処理では、以下のフォーマットであれば、日付、時刻として解釈することができます。 もしSQLite3のエンジンで処理したい場合は、このフォーマットにしておくと良いでしょう。
YYYY-MM-DD YYYY-MM-DD HH:MM YYYY-MM-DD HH:MM:SS YYYY-MM-DD HH:MM:SS.SSS YYYY-MM-DDTHH:MM YYYY-MM-DDTHH:MM:SS YYYY-MM-DDTHH:MM:SS.SSS HH:MM HH:MM:SS HH:MM:SS.SSS now DDDDDDDDDD 以下のようなログファイルのtimeを処理したい場合、
time:2015-09-06T05:58:05+09:00	method:POST	... time:2015-09-06T05:58:41+09:00	method:POST	... time:2015-09-06T06:00:42+09:00	method:GET	...datetime(time)で日時として、認識させれば、strftime()で再フォーマットがしやすくなります。
trdsql -iltsv &amp;#34;SELECT strftime(&amp;#39;%Y年%m月%d日%H時%M分%S秒&amp;#39;,datetime(time)) FROM log.ltsv&amp;#34; 2015年09月05日20時58分05秒 2015年09月05日20時58分41秒 2015年09月05日21時00分42秒上記以外のフォーマットの場合は、SQLite3では文字列をまず書き換える必要があります。
PostgreSQLの日付、時刻処理 PostgreSQLの日付、時刻処理は、より豊富なフォーマットを処理できます。
多くの場合は、dateやtimestampにCASTするだけで、多くの有名なフォーマットは解釈されます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; &amp;#34;SELECT to_char(CAST(time AS timestamp),&amp;#39;YYYY年MM月dd日HH24時MI分ss秒&amp;#39;) FROM log.ltsv&amp;#34; 2015年09月06日05時58分05秒 2015年09月06日05時58分41秒 2015年09月06日06時00分42秒日付、時刻型に変換されるので、そこから表示するフォーマットに変換するにはto_char()を使用します。指定の仕方はマニュアルを参照して下さい。
さらに独特なフォーマットの場合は、 to_dateやto_timestampにより自分で定義したフォーマットで解釈させることが出来ます。
例えば上記で出力したフォーマットの場合、to_charと同じフォーマット指定でto_timestampを実行すれば逆にタイムスタンプとして扱われます。
trdsql -ih -oh -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; &amp;#34;SELECT to_timestamp(\&amp;#34;日時\&amp;#34;,&amp;#39;YYYY年MM月dd日HH24時MI分ss秒&amp;#39;) FROM d.csv&amp;#34; 2015-09-05T20:58:05+09:00 2015-09-05T20:58:41+09:00 2015-09-05T21:00:42+09:00MySQLの日付、時刻処理 MySQLでも多くのフォーマットをdate()やtimestamp()により変換させることができます。</description>
    </item>
    <item>
      <title>trdsql JSON解析</title>
      <link>https://noborus.github.io/trdsql/21_json_parse/index.html</link>
      <pubDate>Sat, 21 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/21_json_parse/index.html</guid>
      <description>これまでtrdsqlでは、JSONの入力が可能と書きましたが、例として書いたのは基本的にフラットな構造のJSONでした。 ただ、２階層以上の階層構造が含まれるJSONはエラーになる訳ではなく、そのまま文字列として扱われます。
以下のようなJSONがあるとします。
sample.json
[ { &amp;#34;color&amp;#34;: &amp;#34;white&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;value&amp;#34;, &amp;#34;code&amp;#34;: { &amp;#34;rgba&amp;#34;: [0, 0, 0, 1], &amp;#34;hex&amp;#34;: &amp;#34;#FFF&amp;#34; } }, { &amp;#34;color&amp;#34;: &amp;#34;red&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;hue&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;primary&amp;#34;, &amp;#34;code&amp;#34;: { &amp;#34;rgba&amp;#34;: [255, 0, 0, 1], &amp;#34;hex&amp;#34;: &amp;#34;#FF0&amp;#34; } }, { &amp;#34;color&amp;#34;: &amp;#34;blue&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;hue&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;primary&amp;#34;, &amp;#34;code&amp;#34;: { &amp;#34;rgba&amp;#34;: [0, 0, 255, 1], &amp;#34;hex&amp;#34;: &amp;#34;#00F&amp;#34; } } ]これをそのままtrdsqlを実行すると以下のようになります(見やすいように-oatを付けています。CSV出力にすると「&amp;quot;」が含まれる文字列のためエスケープされて出力されます。)
trdsql -oat &amp;#34;SELECT color,category,code FROM sample.json&amp;#34; +-------+----------+-----------------------------------+ | color | category | code | +-------+----------+-----------------------------------+ | white | value | {&amp;#34;hex&amp;#34;:&amp;#34;#FFF&amp;#34;,&amp;#34;rgba&amp;#34;:[0,0,0,1]} | | red | hue | {&amp;#34;hex&amp;#34;:&amp;#34;#FF0&amp;#34;,&amp;#34;rgba&amp;#34;:[255,0,0,1]} | | blue | hue | {&amp;#34;hex&amp;#34;:&amp;#34;#00F&amp;#34;,&amp;#34;rgba&amp;#34;:[0,0,255,1]} | +-------+----------+-----------------------------------+このcodeは文字列の扱いですが、各データベースは既にJSONを扱える関数を備えているため、データベース側の関数を使って変更できます。</description>
    </item>
    <item>
      <title>trdsql JSON出力</title>
      <link>https://noborus.github.io/trdsql/22_json_output/index.html</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/22_json_output/index.html</guid>
      <description>CSVやLTSVなどのフラットな形式のデータは、JSONにしたいときには（-ojsonによる）JSON出力をすれば良いですが、JSONは本来より深い階層も表現できるフォーマットです。
そのようなJSONは、データベースのJSON関数を使用することにより作成できます。
以下のCSVからJSON関数でJSON出力をしてみます。
id,name 1,Orange 2,Melon 3,AppleJSON関数で出力する場合は、「”」等がエスケープされない-orawを使用して出力すると、有効なJSONとして出力できます。
SQLite3、MySQL SQLite3、MySQLでは、json_array()やjson_object()を使用することによりJSONを生成できます。 ここでは「名前:値」の形式で出力するためjson_objectを使用します。2つペアの引数で、指定していきます。
trdsql -ih -oraw &amp;#34;SELECT json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name) FROM header.csv&amp;#34; {&amp;#34;id&amp;#34;:&amp;#34;1&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;Orange&amp;#34;} {&amp;#34;id&amp;#34;:&amp;#34;2&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;Melon&amp;#34;} {&amp;#34;id&amp;#34;:&amp;#34;3&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;Apple&amp;#34;}階層を深くするには、json_object()を内部でさらに使います。 SQLite3にはjson_pretty()関数が無いので、jqで見やすくしています。
trdsql -ih -oraw &amp;#34;SELECT json_object(&amp;#39;fruits&amp;#39;, json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name)) FROM header.csv&amp;#34;|jq . { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Orange&amp;#34; } } { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;2&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Melon&amp;#34; } } { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;3&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Apple&amp;#34; } }上記の結果は1行1JSONで出力されています。これをさらに配列にして、一つのJSONにするには、SQLite3では json_group_array()、MySQLではjson_arrayagg()でグループ化して出力できます。
SQLite3 trdsql -ih -oraw &amp;#34;SELECT json_group_array(json_object(&amp;#39;fruits&amp;#39;, json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name))) FROM header.csv&amp;#34;|jq . [ { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Orange&amp;#34; } }, { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;2&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Melon&amp;#34; } }, { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;3&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Apple&amp;#34; } } ]MySQL trdsql -driver mysql -dsn &amp;#34;noborus:noborus@/trdsql_test&amp;#34; -ih -oraw &amp;#34;SELECT json_pretty(json_arrayagg(json_object(&amp;#39;fruits&amp;#39;, json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name)))) &amp;#34;\ &amp;#34;FROM header.</description>
    </item>
    <item>
      <title>trdsql 差分、比較</title>
      <link>https://noborus.github.io/trdsql/23_except/index.html</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/23_except/index.html</guid>
      <description>CSV同士やCSVとテーブルなどで、値の比較をしたい場合があります。
同じ形式で一部が違うCSVファイルであれば、diffを取る方法もありますが、trdsqlのSQLを使用して比較すると形式が違う場合の比較にも使用できます。
差分の出力 SQLで比較して、差分を出すには、EXCEPTを使用します。EXCEPTは Aのテーブルから Bのテーブルを引いた残りのAの内容を出力します。
Bの方に多くの行があっても関係なく、AにあってBにない行を出力します。
以下のCSVファイルで比較してみます。new.csvで、3の更新と4の追加があるCSVファイルです。
old.csv
1,AAA 2,BBB 3,CCCnew.csv
1,AAA 2,BBB 3,CCB 4,DDD単純に全列を比較すると1と2の行が同じであるため、消されて残った3と4が出力されます。 この場合old.csv側にnew.csvにない行があっても出力されません。diffの比較とは違いますね。
trdsql &amp;#34;SELECT * FROM new.csv EXCEPT SELECT * FROM old.csv &amp;#34; 3,CCB 4,DDDテーブルとファイルの差分出力 既存のデータベースに接続すれば、テーブルとの比較もできます。
例えば、trdsql DBインポートでインポートしたテーブルと更新されたCSVとの比較をしたいときには、以下のようにすると良いでしょう。
CSVファイル側をキャストして型を合わせています。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih -oh \ &amp;#34;SELECT id::int,name FROM fruits.csv &amp;#34; \ &amp;#34;EXCEPT &amp;#34; \ &amp;#34;SELECT id,name FROM fruits &amp;#34; id,name 4,Grapeデータベース側のテーブルが更新されて新しい場合は、逆にテーブル EXCEPT CSVファイルとすれば、良いでしょう。
共通の行の出力 また、EXCEPTとは逆に共通の行を出力させたいときには、INTERSECT を使用します。
&amp;#34;SELECT id::int,name FROM fruits.csv &amp;#34; \ &amp;#34;INTERSECT &amp;#34; \ &amp;#34;SELECT id,name FROM fruits&amp;#34; id,name 1,Orange 2,Melon 3,Apple</description>
    </item>
    <item>
      <title>trdsql グラフ</title>
      <link>https://noborus.github.io/trdsql/24_graph/index.html</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/24_graph/index.html</guid>
      <description>trdsqlは、グラフ作成機能は持っていないためグラフを作成したいときには別のツールを使用して作成することになります。
ExcelやLibreOfficeで描画するのが定番でしょうが、ここではmarianogappa/chartでグラフを描画する方法を紹介します。
marianogappa/chartは、Goで作られていて、や多くのプラットフォームで動作して、標準入力から受け取ったデータをブラウザに描画します。
複雑なグラフには向いていませんが、簡単なグラフを少ないオプションを指定するだけで描画できます。
chartに与えるデータは表示したいグラフによりますが、1列又は2列のデータです。
例えばchartのデフォルトのpieでは、以下のような文字列が並んでいるようなデータを集計して円グラフにしてくれます。
aaa bbb ccc aaa aaa aaacat aaa.csv|chart（ブラウザが開いて表示されます）
これを使用して例えば、ログ集計で使用したログのリクエストをグラフにすると以下のようになります。
trdsql &amp;#34;SELECT req FROM log.ltsv&amp;#34;|chart また、他のグラフでは、1列目がx項目名で、2列目が値として与えます。デフォルトはタブ区切りのデータを受け取るので、タブ区切りで出力します。
ログ集計のリクエストが多い順をTOP 20に変えて出力すると以下のようになります。
trdsql -od &amp;#34;\t&amp;#34; \ &amp;#34;SELECT req, count(req) as count &amp;#34; \ &amp;#34;FROM log.ltsv &amp;#34; \ &amp;#34;GROUP BY req &amp;#34; \ &amp;#34;ORDER BY count DESC LIMIT 20&amp;#34; |chart bar marianogappa/chartは、Chart.jsを使用してグラフを描画しています。Chart.js自体が簡単なJavaScriptを用意すれば描画してくれるので、もう少し複雑なグラフを描きたい場合は直接利用するのが良いでしょう。</description>
    </item>
    <item>
      <title>trdsql ライブラリ使用</title>
      <link>https://noborus.github.io/trdsql/25_library/index.html</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/25_library/index.html</guid>
      <description>trdsqlは初期の頃は、main packageで構成されていましたが、現在はtrdsql packageをmainから呼び出す構成になっていて、trdsql packageをライブラリとして使用できます。
trdsqlのパッケージは、以下の構成になっていて、それぞれ呼び出し可能です。
簡単なサンプルを示します。
package main import ( &amp;#34;log&amp;#34; &amp;#34;github.com/noborus/trdsql&amp;#34; ) func main() { trd := trdsql.NewTRDSQL( trdsql.NewImporter(trdsql.InDelimiter(&amp;#34;:&amp;#34;)), trdsql.NewExporter(trdsql.NewWriter()), ) err := trd.Exec(&amp;#34;SELECT c1 FROM /etc/passwd&amp;#34;) if err != nil { log.Fatal(err) } }上記のプログラムは/etc/passwdに対してSQL文を実行しています。 Importer(データベースにインポートするインターフェイス）とExporter(データベースから結果を出力するインターフェイス）を与えてTRDSQLをNewし、Execで実行するのが、おおまかな流れです。
func NewTRDSQL(im Importer, ex Exporter) *TRDSQLこのImporter,Exporterはインターフェイスに沿っていれば、置き換えられます（例えば、SQL内のファイルをインポートするのではなく、独自にインポートするにはImporterのインターフェイスに沿った関数を作成します）。
Importer デフォルトのImporterは、trdsql.NewImporter()を呼び出せば作成できます。 デフォルトのImporterはtrdsql.Import()でReadOptsのオプションを取ります。ここでフォーマットやその他オプションを渡します。
SQL文にある「/etc/passwd」をデータベースにインポートして使用するのは、デフォルトの動作のため、区切り文字のみ「:」に変更しています。
trdsql.Import()はSQL文を受け取り、必要なファイルをデータベースにインポートします。そのときにファイルの形式に合わせたtrdsql.Readerインターフェイス（各CSV,LTSV,JSON,TBLNのReader)からテーブルへインポートされます。
また、インポートするデータベースによってバルクインサートかCOPYによるインポートを選択してインポートしています。
Exporter デフォルトのExporterは、trdsql.NewExporter()を呼び出せば作成できます。 SQLでは出力は1つなので、出力する関数（trdsql.NewWriter()）を渡しています。 trdsql.NewWriter()はWriteOptsによりフォーマットと動作のオプションを設定して、実際のWriter関数（CSV、LTSV、JSON、TBLN、AT、VF&amp;hellip;)によりSQLを実行した結果を書き出します。
Exec ImporterとExporterの準備が済んでいれば、ExecでSQLを実際に実行します。
データベース接続 トランザクションの開始 Importerでインポートの実行 Exporterで指定したSQLの実行をして出力 トランザクションの終了 データベース切断 参考資料 trdsqlには、参考してファイルからのインポートだけでなく、スライスからインポートする関数が入っています。 それを利用したサンプルが _example/slice/ にあります。
また、trdsql packageを利用してshirou/gopsutilの結果をSQLで取得できるようにしたものが、 noborus/psutilsql です。</description>
    </item>
    <item>
      <title>trdsql SQLファイル指定</title>
      <link>https://noborus.github.io/trdsql/26_file_sql/index.html</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/26_file_sql/index.html</guid>
      <description>SQLファイル名指定オプション「-q」 trdsql &amp;ldquo;SQLコマンド&amp;quot;の形式だと、長いSQLを書くのが難しいですし、シェルに対してエスケープしなければならない文字があって見た目もわかりにくい場合があります。
trdsqlではファイルにSQLを書いておき、そのファイルのSQLを実行させるオプションがあります。
以下のように記述したSQLをtest.sqlで保存しておきます。
test.sql
SELECT id, `name` FROM testsql.csv（コマンドの引数で渡していたときは「\`」のように「`」をエスケープする必要がありましたが、ファイルのSQLを実行する場合は必要ありません）。
testsql.csv は対象となるCSVファイルです。
id,name 1,tarou 2,jirou&amp;ldquo;SQLコマンド&amp;rdquo; の代わりに 「-q ファイル名.sql」で実行します。それ以外のオプションは代わりません。
trdsql -ih -oat -q test.sql+----+-------+ | id | name | +----+-------+ | 1 | tarou | | 2 | jirou | +----+-------+</description>
    </item>
    <item>
      <title>trdsql config</title>
      <link>https://noborus.github.io/trdsql/27_config/index.html</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/27_config/index.html</guid>
      <description>trdsqlは設定ファイルが無くても動作しますが、設定ファイルによりデフォルトのデータベースのエンジンを変更できます。
configファイルの場所 -configオプションで、直接ファイルの場所を指定できます。
-configオプションを使用しないデフォルトの場所は以下です。
Linux等のWindows以外 ${HOME}/.config/trdsql/config.jsonWindows %APPDATA%trdsql\config.json です。多くは以下の位置になります。
C:\Users\{&amp;#34;User&amp;#34;}\AppData\Roaming\trdsql\config.jsonconfigファイルの内容 以下がサンプルです。
{ &amp;#34;db&amp;#34;: &amp;#34;pdb&amp;#34;, &amp;#34;database&amp;#34;: { &amp;#34;sdb&amp;#34;: { &amp;#34;driver&amp;#34;: &amp;#34;sqlite3&amp;#34;, &amp;#34;dsn&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;pdb&amp;#34;: { &amp;#34;driver&amp;#34;: &amp;#34;postgres&amp;#34;, &amp;#34;dsn&amp;#34;: &amp;#34;user=test dbname=test&amp;#34; }, &amp;#34;mdb&amp;#34;: { &amp;#34;driver&amp;#34;: &amp;#34;mysql&amp;#34;, &amp;#34;dsn&amp;#34;: &amp;#34;user:password@/dbname&amp;#34; } } }&amp;ldquo;database&amp;rdquo; に &amp;ldquo;名前&amp;rdquo;: {&amp;ldquo;driver&amp;rdquo;: ドライバ名(sqlite3 or postgres or mysql), &amp;ldquo;dsn&amp;rdquo;: &amp;ldquo;ドライバに沿ったDSN&amp;rdquo;} でデータベースを定義しておき、最初の &amp;ldquo;db&amp;quot;に定義した&amp;quot;名前&amp;quot;を書くとデフォルトのエンジンが変更されます。
上記では、&amp;ldquo;pdb&amp;quot;がデフォルトになり、&amp;ldquo;postgres&amp;quot;エンジンが使用されます。
デフォルトの変更だけでなく、ここで定義しておくと trdsqlのオプション -db mdb を指定することにより、簡単にmysqlドライバのエンジンに切り替えられます。
確認方法 configファイルが無くても動作するため、実際にエンジンが変更されているかわかりにくいことがあります。
trdsqlを-debugオプション付きで起動すると詳細が表示されますので、そこで確認して下さい。
設定ファイルが見つからなかった場合 trdsql -debug -db pdb &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 2019/12/27 11:22:13 configOpen: open /home/noborus/.</description>
    </item>
    <item>
      <title>trdsql CROSS JOIN</title>
      <link>https://noborus.github.io/trdsql/28_cross_join/index.html</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/28_cross_join/index.html</guid>
      <description>CROSS JOINは、総当りを簡単に作り出せる方法です。
a.csv
aa ab acb.csv
ba bb bcの２つのCSVをCROSS JOINすると 3×3で全ての組み合わせを出力できます。
trdsql &amp;#34;SELECT * FROM a.csv CROSS JOIN b.csv&amp;#34; aa,ba aa,bb aa,bc ab,ba ab,bb ab,bc ac,ba ac,bb ac,bcまた一つのファイルに対して自己結合をすることもできます。 例えば、ホーム＆アウェーの総当り表を作成してみます。
cleague.csv
team 巨人 DeNA 阪神 広島 中日 ヤクルト単純にCROSS JOINするには以下のようになります（JOIN条件は無いので書けません）。
trdsql -ih \ &amp;#34;SELECT h.team,a.team &amp;#34;\ &amp;#34; FROM cleague.csv AS h &amp;#34;\ &amp;#34; CROSS JOIN cleague.csv AS a&amp;#34;自分のチームとは対戦出来ないので、同じチームのときをWHERE h.team != a.teamにより除外します。
trdsql -ih -omd \ &amp;#34;SELECT h.team AS home,a.team AS aware &amp;#34; \ &amp;#34; FROM cleague.</description>
    </item>
    <item>
      <title>trdsql generate_series</title>
      <link>https://noborus.github.io/trdsql/29_generate_series/index.html</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/29_generate_series/index.html</guid>
      <description>generate_series PostgreSQLにはgenerate_series()という便利な関数があります。 これはUnixのseqコマンドと同じような働きをする関数です。またgenerate_series()は、タイムスタンプ型にも使用できる拡張があります。
使い方は簡単で「開始値」、「終了値」、「刻み値（省略可能）」を指定して実行します。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; &amp;#34;SELECT * FROM generate_series(1,10)&amp;#34; 1 2 3 4 5 6 7 8 9 10generate_series()はテーブルを返す関数で、テーブルの代わりに使用できます。 （SELECT generate_series(1,10)と書くこともできます）。
もちろん、trdsqlでは、外部からの入力を簡単に取り入れられるので、seqコマンドで代用することもできます。
seq 1 10|trdsql &amp;#34;SELECT * FROM -&amp;#34; 1 2 3 4 5 6 7 8 9 10seqコマンドは、引数の順序が「開始値」、「刻み値（省略可能）」「終了値」になります。 2つの値を渡すときには同じですが、刻み値を指定する場合は、順序が異なるので注意が必要です。
タイムスタンプ generate_series()では、タイムスタンプを扱えるので、2020年のカレンダーを日本語で出すと少々トリッキーですが、以下のようになります。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; \ &amp;#34;SET LC_TIME=&amp;#39;ja_JP.UTF-8&amp;#39;; &amp;#34; \ &amp;#34;SELECT to_char(day,&amp;#39;YYYY年TMMonthDD日 (TMDay)&amp;#39;) &amp;#34; \ &amp;#34; FROM generate_series(&amp;#39;2020-01-1&amp;#39;::timestamp,&amp;#39;2020-12-31&amp;#39;,&amp;#39;1 day&amp;#39;) as day&amp;#34; 2020年1月01日 (水曜日) 2020年1月02日 (木曜日) 2020年1月03日 (金曜日) 2020年1月04日 (土曜日) .</description>
    </item>
    <item>
      <title>trdsql convert log</title>
      <link>https://noborus.github.io/trdsql/30_convert_log/index.html</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/trdsql/30_convert_log/index.html</guid>
      <description>既存のログをLTSVに変換する 既存のログをLTSVに変換にしてみます。
mingrammer/flog を使用するとフェイクのログが簡単に出力できるので、 これで出力されるログをLTSV形式に変換する方法を紹介します。
Apache common log 以下のコマンドにより apache_common形式のログをaccess.common.logとして保存します。
flog -f apache_common -t log -o access.common.log 内容は、以下のようになります。
92.129.44.198 - metz3917 [30/Dec/2019:17:02:27 +0900] &amp;#34;DELETE /infomediaries/e-markets HTTP/2.0&amp;#34; 500 24843 246.54.243.199 - - [30/Dec/2019:17:02:27 +0900] &amp;#34;POST /24%2f7 HTTP/1.1&amp;#34; 302 8879 9.172.27.159 - - [30/Dec/2019:17:02:27 +0900] &amp;#34;DELETE /convergence/best-of-breed HTTP/1.1&amp;#34; 203 3252 49.129.77.219 - kozey2248 [30/Dec/2019:17:02:27 +0900] &amp;#34;PUT /embrace HTTP/1.1&amp;#34; 301 2812 216.42.120.216 - - [30/Dec/2019:17:02:27 +0900] &amp;#34;HEAD /infomediaries HTTP/2.0&amp;#34; 204 12516これを trdsqlの -id &amp;quot; &amp;quot; によりスペース区切りで解析すると c4とc5でタイムが分かれてしまいますが、それ以外は問題無さそうです。</description>
    </item>
    <item>
      <title>trdsql 合計を行に追加する</title>
      <link>https://noborus.github.io/trdsql/31_rollup/index.html</link>
      <pubDate>Sat, 04 Jan 2020 13:38:00 +0900</pubDate>
      <guid>https://noborus.github.io/trdsql/31_rollup/index.html</guid>
      <description>Window関数により元のファイルの内容に列を追加して、集計結果を出せました。 ただ、人が確認する場合は、集計の結果行が最後に出るほうが確認しやすくなります。
通常のSQLでも元の内容と集計結果を別々に出してUNIONを使うことで、一つの結果として出すことが出来ますが、一回で済むならばそれに越したことはありません。
SQLite3ではサポートされていませんが、PostgreSQLとMySQLならばサポートされている文があります。
ROLLUP Window関数でも使用した以下のCSVファイルを使用します。
id,class,name,score 1,A,bob,174 2,A,alice,248 3,A,carol,163 4,B,dave,289 5,B,eve,157 6,B,flank,272通常のGROUP BYで全体の合計又は、class毎の合計が出せました。 ただし、class毎の合計と全体の合計を出すにはWindow関数を使用して別の列に出していました。
GROUP BYに ROLLUPを指定することで、両方を出力できます。
PostgreSQL PostgreSQLでは、GROUP BY 列名の代わりにGROUP BY ROLLUP(列名)を使用することで、通常のGROUP BYに加えて、全体の集計結果を出力します。
trdsql -driver &amp;#34;postgres&amp;#34; -dsn &amp;#34;dbname=trdsql_test&amp;#34; -oat -ih \ &amp;#34;SELECT class, SUM(score::int) AS score FROM score.csv GROUP BY ROLLUP(class) ORDER BY class&amp;#34; +-------+------+ | class | sum | +-------+------+ | A | 585 | | B | 718 | | | 1303 | +-------+------+MySQL MySQLでは、GROUP BY 列名の後に WITH ROLLUPを付けると、通常のGROUP BYに加えて、全体の集計結果を出力します。</description>
    </item>
    <item>
      <title>trdsql CASE式</title>
      <link>https://noborus.github.io/trdsql/32_case/index.html</link>
      <pubDate>Tue, 07 Jan 2020 10:18:00 +0900</pubDate>
      <guid>https://noborus.github.io/trdsql/32_case/index.html</guid>
      <description>CASE式は、プログラム言語のif文やswitch文のような条件に分岐した処理をおこないます。単純な1を&amp;rsquo;A&amp;rsquo;に変換するような場合は、一時的なテーブルとJOINさせたり文字列の書き換えで可能ですが、 範囲を指定してグループ化したい場合はCASE式を使うと便利です。
CASE式には以下の2つのパターンどちらも使用できます。
CASEは CASE 式（列) WHEN 値 THEN 結果とCASEの後に式を書いて、WHENが値だけのパターンと CASE WHEN 式 THEN 結果 とCASEの式を省略してWHENに式を書くパターン 必要であれば、ELSE 結果で当てはまらない場合を書き、ENDで式の終わりを示します。
case.csv のようなCSVを使用して、scoreが80以上の場合は&amp;rsquo;A&amp;rsquo;、30以上の場合は、&amp;lsquo;B&amp;rsquo;、30より下の場合は、&amp;lsquo;F&amp;rsquo;と表示させてみます。
id,name,score 1,bob,89 2,alice,75 3,dave,23trdsql -ih -oat \ &amp;#34;SELECT id,name,score, &amp;#34; \ &amp;#34; CASE WHEN CAST(score AS int) &amp;gt;= 80 THEN &amp;#39;A&amp;#39; &amp;#34; \ &amp;#34; WHEN CAST(score AS int) &amp;gt;= 30 THEN &amp;#39;B&amp;#39; &amp;#34; \ &amp;#34; ELSE &amp;#39;F&amp;#39; &amp;#34; \ &amp;#34; END AS evaluation &amp;#34; \ &amp;#34; FROM case.csv&amp;#34; +----+-------+-------+------------+ | id | name | score | evaluation | +----+-------+-------+------------+ | 1 | bob | 89 | A | | 2 | alice | 75 | B | | 3 | dave | 23 | F | +----+-------+-------+------------+CASE式は書いた先から評価されます。</description>
    </item>
    <item>
      <title>trdsql 圧縮ファイル</title>
      <link>https://noborus.github.io/trdsql/33_compression/index.html</link>
      <pubDate>Mon, 02 Mar 2020 17:52:00 +0900</pubDate>
      <guid>https://noborus.github.io/trdsql/33_compression/index.html</guid>
      <description>圧縮ファイルに実行 0.7.4までは gzip(.gz)の圧縮形式のみの対応でしたが、最新のmaster(0.7.5以降の予定)では、gzip(gz)、bzip2(bz2)、zstd(zst)、lz4、xzの圧縮形式に対応しました。
従来は.gzの拡張子をみて判断していましたが、今回から圧縮形式のファイルの先頭のマジックナンバー（signatureの値）を見て判断するようになりました。そのため、拡張子が何であっても上記の圧縮形式はそのまま読み取ることが出来ます。
圧縮率にもよりますが、デフォルトレベルのzstdでの圧縮されたファイルをtrdsqlで処理すると、手元のマシンでの処理時間はほぼ変わらないか、少しzstdで圧縮されているファイルのほうが早いくらいです。
例えば以下のような145MBのファイルに対してzstdで圧縮すると44MBになりました。
145M worldcitiespop.csv 44M worldcitiespop.csv.zst timeを付けての結果は以下のようになりました。
/usr/bin/time -p trdsql -ih &amp;#34;SELECT count(*) FROM worldcitiespop.csv&amp;#34; real 11.47 user 11.76 sys 0.70 zstd圧縮
/usr/bin/time -p trdsql -ih &amp;#34;SELECT count(*) FROM worldcitiespop.csv.zst&amp;#34; real 9.76 user 11.00 sys 0.37 LTSVファイルでは、同じ内容のCSVファイルよりもファイルサイズが大きくなりますが、圧縮効率は良いので圧縮したときのファイルサイズの差は小さくなります。
330M worldcitiespop.ltsv 54M worldcitiespop.ltsv.zst 145MBをLTSVにすると330MBのファイルになっていたのが、圧縮するとCSV:44MB、LTSV:54MBになります。
処理時間は以下のようになりました。
/usr/bin/time -p trdsql &amp;#34;SELECT count(*) FROM worldcitiespop.ltsv real 16.72 user 17.41 sys 1.05 /usr/bin/time -p trdsql &amp;#34;SELECT count(*) FROM worldcitiespop.ltsv.zst&amp;#34; 3173958 real 13.93 user 16.</description>
    </item>
    <item>
      <title>trdsql output</title>
      <link>https://noborus.github.io/trdsql/34_output/index.html</link>
      <pubDate>Mon, 02 Mar 2020 18:45:00 +0900</pubDate>
      <guid>https://noborus.github.io/trdsql/34_output/index.html</guid>
      <description>今までは標準出力にのみ出力していましたが、-out ファイル名により、出力ファイルを指定できるようにしました。
-out ファイル名では出力ファイル名からファイル形式、圧縮形式を推測するモードをデフォルトで有効にしてあります。
出力ファイル名の拡張子が[.csv,.ltsv,json,jsonl,tbln,md,at,vf,raw]等の出力ファイル形式の拡張子だった場合は自動でその出力形式で出力します。
以下はLTSV形式で出力します。
trdsql -out test.ltsv &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 出力フォーマットを指定した場合は、出力フォーマットが優先されます。以下はjsonl形式で出力されます。
trdsql -ojsonl -out test.txt &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 圧縮形式も推測するので、test.csv.gzのようにした場合はCSV形式のgzip圧縮で出力されます。基本的ファイルの拡張子はファイル形式.圧縮形式の順です。
以下はLTSV形式でzstd圧縮で出力されます。
trdsql -out test.ltsv.zst &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 圧縮フォーマットも-oz 圧縮形式で指定した場合はそちらが優先されます。
例えば、.zstの拡張子を付けたいが圧縮してほしくない（理由はわかりませんが&amp;hellip;)の場合は、-out-without-guessを付けて実行して下さい。</description>
    </item>
    <item>
      <title>trdsql jq構文</title>
      <link>https://noborus.github.io/trdsql/35_jq/index.html</link>
      <pubDate>Sat, 09 Jul 2022 07:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/trdsql/35_jq/index.html</guid>
      <description>これまでtdsqlが対象とするJSONはフラットなJSONでした。そのためSQLの対象となるのはトップレベルのオブジェクトでした。
[ {&amp;#34;age&amp;#34;: &amp;#34;26&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Tanaka&amp;#34;}, {&amp;#34;age&amp;#34;: &amp;#34;32&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Suzuki&amp;#34;} ]JSONは階層を深くすることができるので、さらに下の階層をSQLの対象としたい場合がありました。 SQLの関数を使用して、アクセスすることも出来ますが、少し面倒でした。
{ &amp;#34;list&amp;#34;: [ {&amp;#34;age&amp;#34;: &amp;#34;26&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Tanaka&amp;#34;}, {&amp;#34;age&amp;#34;: &amp;#34;32&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Suzuki&amp;#34;} ] }tdsqlではJSONに対し、まずjqの構文を使用して処理し、その結果に対してSQLを実行できます。 jqの構文はファイル名の後に&amp;quot;::&amp;ldquo;を付け、その後に書きます。 jqの構文なので、主に&amp;rdquo;.&amp;ldquo;ドットではじまり、中の値にアクセスします。
（jsonを対象とすると配列全体を１つの列と解釈してしまう）。
trdsql &amp;#34;SELECT * FROM example0-s.json &amp;#34;[{&amp;#34;&amp;#34;age&amp;#34;&amp;#34;:&amp;#34;&amp;#34;26&amp;#34;&amp;#34;,&amp;#34;&amp;#34;name&amp;#34;&amp;#34;:&amp;#34;&amp;#34;Tanaka&amp;#34;&amp;#34;},{&amp;#34;&amp;#34;age&amp;#34;&amp;#34;:&amp;#34;&amp;#34;32&amp;#34;&amp;#34;,&amp;#34;&amp;#34;name&amp;#34;&amp;#34;:&amp;#34;&amp;#34;Suzuki&amp;#34;&amp;#34;}]&amp;#34; （listをテーブルとして解釈して、中のオブジェクトを列にする）。
trdsql &amp;#34;SELECT * FROM example0-s.json::.list 26,Tanaka 32,Suzuki 深い階層にアクセスしたいときは、jqの構文では .list.menu.itemのようにドットで繋いでいけば簡単にアクセスすることができます。 階層途中に配列があってもjqの構文（[]等が含まれる場合は「&amp;quot;」で括る等してください）が書ければアクセスすることができます。
trdsql &amp;#34;SELECT * FROM example0-s.json::\&amp;#34;.list[1].name\&amp;#34;&amp;#34; 複雑な集計をjqで書くのは難しいため、対象をテーブル化することでSQLで集計するといったことができます。 また、CSVや他の形式に変換するのもtrdsqlでは簡単です。</description>
    </item>
    <item>
      <title>trdsql v0.13.0</title>
      <link>https://noborus.github.io/blog/trdsql_0130/index.html</link>
      <pubDate>Sun, 12 Nov 2023 09:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_0130/index.html</guid>
      <description>trdsql v0.13.0をリリースしました。 リリースのページから各バイナリがダウンロードできます。
テーブル名の指定 -tオプションでテーブル名を指定できるようになりました。一番短い構文は以下のようになります。
trdsql -t test.csv 単純にフォーマット変換したいときに便利です。
trdsql -ojson -t test.csv これはSELECT * FROM test.csvと同じです。
macOSのM1バイナリを修正 macOSのM1(Arm64)バイナリを修正しました。Linuxからのクロスビルドで作成していたため、macOSでのビルドが動作しませんでした。 macOS環境のクロスビルドにしたため、macOSでのビルドが動作するようになりました。
zigビルドのサポート ビルド環境の見直しによって、zigでのビルドが可能になりました。全体を置き換えようかと思いましたが、結局置き換えはしませんでした。 今回linux-old版のみzigでビルドしています。</description>
    </item>
    <item>
      <title>trdsql v0.12.1</title>
      <link>https://noborus.github.io/blog/trdsql_0121/index.html</link>
      <pubDate>Wed, 18 Oct 2023 12:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_0121/index.html</guid>
      <description>trdsql v0.12.1をリリースしました。 リリースのページから各バイナリがダウンロードできます。
CGOを使わないビルドに対応 CGOを使わないビルドに対応しました。trdsqlはgo-sqlite3がデフォルトで使用しているため、ビルドにCGOが必要でした。sqliteを使用することでCGOを使わないビルドを実現しています。
CGOを使わないビルドは以下のようにビルドします。
CGO_ENABLED=0 make CGOを使わないビルドにした場合はdriver名はsqliteに変更になります。また、sqliteがデフォルトになります。
CGOを使わないビルドの場合は以下がエラーになります。
trdsql -driver sqlite3 &amp;#34;SELECT 1;&amp;#34; trdsqlのreleaseページにあるバイナリはCGOを使用するようにビルドされています。これは速度面でCGOを使用したほうが有利だからです。
trdsqlのパッケージ利用ソフト trdsqlのパッケージを利用したソフトである、psutilsql、mdtsqlはCGOを使わないビルドにして、バイナリをリリースしています。
クロスビルドが簡単になったため、各OSのバイナリも用意しています。</description>
    </item>
    <item>
      <title>trdsql v0.12.0</title>
      <link>https://noborus.github.io/blog/trdsql_0120/index.html</link>
      <pubDate>Sat, 30 Sep 2023 08:45:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_0120/index.html</guid>
      <description>trdsql v0.12.0をリリースしました。 リリースのページから各バイナリがダウンロードできます。
YAMLサポート YAML形式のファイルを読み込み、出力できるようになりました。
読み込みはYAML, またはYMLの拡張子であれば自動判別させるか、-iyamlを指定します。
- id: 1 name: Orange - id: 2 name: Melon - id: 3 name: Apple$ trdsql -oh &amp;#34;SELECT id,name FROM test.yaml&amp;#34; id,name 1,Orange 2,Melon 3,Apple 出力は-oyamlを指定します。
trdsql -oyaml &amp;#34;SELECT * FROM KEN_ALL.CSV LIMIT 1&amp;#34; - c1: 577 c2: 48 c3: 196608 c4: ホッカイドウ c5: サッポロシチュウオウク c6: イカニケイサイガナイバアイ c7: 北海道 c8: 札幌市中央区 c9: 以下に掲載がない場合 c10: 0 c11: 0 c12: 0 c13: 0 c14: 0 c15: 0YAMLの読み込みは内部的にはJSONに変換してから読み込んでいます。そのため階層構造のあるYAMLの値はJSONになります。</description>
    </item>
    <item>
      <title>trdsql For fixed width</title>
      <link>https://noborus.github.io/trdsql/36_guesswidth/index.html</link>
      <pubDate>Tue, 13 Jun 2023 07:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/trdsql/36_guesswidth/index.html</guid>
      <description>trdsql can receive data from Standard input, but the output such as PS interpreted a format that is not originally a space separation, so the column.The interpretation was not accurate.
trdsql 0.11.1 uses the -iwidth option to handle a row of a fixed length as a table. With this option, you can interpret output like ps more accurately.
ps | trdsql -omd -iwidth &amp;#34;SELECT * FROM - &amp;#34; | PID | TTY | TIME | CMD | |--------|-------|----------|--------| | 237958 | pts/2 | 00:00:02 | zsh | | 369132 | pts/2 | 00:00:00 | ps | | 369133 | pts/2 | 00:00:00 | trdsql |You can interpret it when there is a row name header and the header is output according to the width of the value later.</description>
    </item>
    <item>
      <title>trdsql v0.11.1</title>
      <link>https://noborus.github.io/blog/trdsql_0111/index.html</link>
      <pubDate>Sun, 19 Mar 2023 07:17:08 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_0111/index.html</guid>
      <description>trdsql v0.11.1をリリースしました。 リリースのページから各バイナリがダウンロードできます。
guesswidthを使用して、幅が固定長の列をテーブルとして扱えるようにしました。
これまではpsの出力等をスペース（複数の連続スペースがあっても1つとみなす）区切りで、CSVとして解釈するといったことをしてきましたが、スペースの規則が決まっているわけではなく不正確でした。
完璧ではありませんが、幅を推測することでより良く解釈することが可能です。
ps|trdsql -iwidth &amp;#34;SELECT * FROM -&amp;#34; 1067693,pts/0,00:00:08,zsh 1123441,pts/0,00:00:00,ps 1123442,pts/0,00:00:00,trdsql 例えば、psの出力をjsonにしたり、docker psの出力をアスキーテーブルで表示できたりします。</description>
    </item>
    <item>
      <title>trdsql jq構文</title>
      <link>https://noborus.github.io/blog/35_jq/index.html</link>
      <pubDate>Sat, 09 Jul 2022 07:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/35_jq/index.html</guid>
      <description>これまでtdsqlが対象とするJSONはフラットなJSONでした。そのためSQLの対象となるのはトップレベルのオブジェクトでした。
[ {&amp;#34;age&amp;#34;: &amp;#34;26&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Tanaka&amp;#34;}, {&amp;#34;age&amp;#34;: &amp;#34;32&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Suzuki&amp;#34;} ]JSONは階層を深くすることができるので、さらに下の階層をSQLの対象としたい場合がありました。 SQLの関数を使用して、アクセスすることも出来ますが、少し面倒でした。
{ &amp;#34;list&amp;#34;: [ {&amp;#34;age&amp;#34;: &amp;#34;26&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Tanaka&amp;#34;}, {&amp;#34;age&amp;#34;: &amp;#34;32&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Suzuki&amp;#34;} ] }tdsqlではJSONに対し、まずjqの構文を使用して処理し、その結果に対してSQLを実行できます。 jqの構文はファイル名の後に&amp;quot;::&amp;ldquo;を付け、その後に書きます。 jqの構文なので、主に&amp;rdquo;.&amp;ldquo;ドットではじまり、中の値にアクセスします。
（jsonを対象とすると配列全体を１つの列と解釈してしまう）。
trdsql &amp;#34;SELECT * FROM example0-s.json &amp;#34;[{&amp;#34;&amp;#34;age&amp;#34;&amp;#34;:&amp;#34;&amp;#34;26&amp;#34;&amp;#34;,&amp;#34;&amp;#34;name&amp;#34;&amp;#34;:&amp;#34;&amp;#34;Tanaka&amp;#34;&amp;#34;},{&amp;#34;&amp;#34;age&amp;#34;&amp;#34;:&amp;#34;&amp;#34;32&amp;#34;&amp;#34;,&amp;#34;&amp;#34;name&amp;#34;&amp;#34;:&amp;#34;&amp;#34;Suzuki&amp;#34;&amp;#34;}]&amp;#34; （listをテーブルとして解釈して、中のオブジェクトを列にする）。
trdsql &amp;#34;SELECT * FROM example0-s.json::.list 26,Tanaka 32,Suzuki 深い階層にアクセスしたいときは、jqの構文では .list.menu.itemのようにドットで繋いでいけば簡単にアクセスすることができます。 階層途中に配列があってもjqの構文（[]等が含まれる場合は「&amp;quot;」で括る等してください）が書ければアクセスすることができます。
trdsql &amp;#34;SELECT * FROM example0-s.json::\&amp;#34;.list[1].name\&amp;#34;&amp;#34; 複雑な集計をjqで書くのは難しいため、対象をテーブル化することでSQLで集計するといったことができます。 また、CSVや他の形式に変換するのもtrdsqlでは簡単です。</description>
    </item>
    <item>
      <title>Another way to aggregate json(jq &#43; SQL)</title>
      <link>https://noborus.github.io/blog/jqsql/index.html</link>
      <pubDate>Tue, 03 May 2022 12:58:24 +0900</pubDate>
      <guid>https://noborus.github.io/blog/jqsql/index.html</guid>
      <description>Aggregate json with trdsql I agree that the aggregation of jq described in the Introducing zq is not easy.
I&amp;rsquo;ve seen A Practical Example of zq, zq was not easy for me.
SQL is not easy for everyone, but it is a language that many people can use. I am one of them.
Of course, it is difficult to process all JSON with SQL. But what about using them in combination?</description>
    </item>
    <item>
      <title>trdsql v0.10.0</title>
      <link>https://noborus.github.io/blog/trdsql_0100/index.html</link>
      <pubDate>Tue, 03 May 2022 09:29:54 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_0100/index.html</guid>
      <description>trdsql v0.10.0をリリースしました。 リリースのページから各バイナリがダウンロードできます。
NULLの扱い変更 今回はNULLの扱いを変更しました。
JSONにはnullがありましたが、CSV等のテキストフォーマットには無いため、 すべて空文字として扱っていましたが、JSONのnullをSQLのNULLとして扱うようにしました。
JSONの文字列とみなせる箇所がnullの場合は、それほど問題ではありませんでしたが、 配列（&amp;quot;[]&amp;quot;）のようなJSONが入る箇所がnullの場合に空文字（&amp;quot;&amp;quot;）にしてしまうと、 SQLのJSON関数に渡しづらい問題があったためSQLのNULLにするようにしました。
これによりJSONの集計問題が解きやすくなっていると思います。
Introducing zqで示されている問題にSQLで解くときにスッキリ書けるようになっています。
上記の&amp;quot;A Practical Example&amp;quot;は、以下のSQLで解けます。
SELECT json(author_name)-&amp;gt;&amp;gt;0 AS author_name, count(*) AS count FROM openlibrary.json::.docs WHERE author_name IS NOT NULL AND publish_year IS NOT NULL GROUP BY json(author_name)-&amp;gt;&amp;gt;0 ORDER BY count DESC LIMIT 3;{&amp;#34;author_name&amp;#34;:&amp;#34;S. Stepniak&amp;#34;,&amp;#34;count&amp;#34;:38} {&amp;#34;author_name&amp;#34;:&amp;#34;Władysław Stępniak&amp;#34;,&amp;#34;count&amp;#34;:7} {&amp;#34;author_name&amp;#34;:&amp;#34;Władysław Stępniak&amp;#34;,&amp;#34;count&amp;#34;:4}Unicodeの正規化はPostgreSQLエンジンを使用する場合はnormalize()関数があるため、間に入れれば可能です。SQLite3エンジンを使用する場合は、 別のコマンドで正規化してからパイプで使用する必要があります。
jq .docs openlibrary.json| uconv norm | trdsql -driver sqlite3 -ijson -ojsonl &amp;#34;SELECT json(author_name)-&amp;gt;&amp;gt;0 AS author_name, count(*) AS count FROM - WHERE author_name IS NOT NULL AND publish_year IS NOT NULL GROUP BY json(author_name)-&amp;gt;&amp;gt;0 ORDER BY count DESC LIMIT 3&amp;#34; NULLオプション追加 また、-inullと-onullオプションを追加しました。-inullはSQLのNULLに変換する文字列を指定し、 -onullはSQLのNULLを指定された文字列に変換します。</description>
    </item>
    <item>
      <title>trdsql v0.9.1</title>
      <link>https://noborus.github.io/blog/trdsql_091/index.html</link>
      <pubDate>Fri, 07 Jan 2022 00:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_091/index.html</guid>
      <description>trdsql v0.9.1をリリースしました。 リリースのページから各バイナリがダウンロードできます。
読み込み行数を指定できるオプションを追加しました -ilr num で行数を指定します。SQLでは結果を制限するLIMITがありますが、これは入力の行数を制限します。 大きなファイルでは、読み込むのに時間がかかるためSQLを試行するときや、全部の結果が必要ないとき等に使用できます。
JSON出力時にオブジェクトの順番を固定しました JSON出力ではSQLでSELECT a,b FROM csvとしてもaとbの順番が不定で出力されていました。
SELECT a,b FROM ab.csv[ { &amp;#34;b&amp;#34;: &amp;#34;2&amp;#34;, &amp;#34;a&amp;#34;: &amp;#34;1&amp;#34; }, { &amp;#34;b&amp;#34;: &amp;#34;4&amp;#34;, &amp;#34;a&amp;#34;: &amp;#34;3&amp;#34; }, { &amp;#34;b&amp;#34;: &amp;#34;6&amp;#34;, &amp;#34;a&amp;#34;: &amp;#34;5&amp;#34; } ]SQLの出力結果をgoのmapにしてからJSONを出力するので、オブジェクト順は不定になっていました。 これをorderedmapを使用して、結果を指定順になるようにしました。
GOの対象バージョンを変更 goの対象バージョンを1.16以上にしました。リリースのバイナリは1.17でビルドするようになっています。</description>
    </item>
    <item>
      <title>trdsql&#43;PostgreSQL 14でJSONを処理する</title>
      <link>https://noborus.github.io/blog/trdsql_jq/index.html</link>
      <pubDate>Sat, 18 Dec 2021 15:40:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_jq/index.html</guid>
      <description>trdsql はCSVやLTSVと共にJSONに対してもSQLを実行できるツールですが、SQLを使用するため得意な対象はフラットなJSONです。 ただし、v0.9.0からjqの構文が使え、SQL内でもSQLの関数が使えるため、内容によっては簡単に書くことができる場合があります。
デフォルトのsqlite3にもJSON関数がありますが、ここではよりJSON関数が充実しているPostgreSQL 14を使用します。
基本的な使用法 SQLを実行する対象として複数の列のリストの形になっているものが対象です。 以下のように{``}で囲まれた複数の名前: 値が,で並べられたJSONが基本的な形です。 改行で区切られた（実際には）複数のJSONが並べられたLDJSONやJSONLと呼ばれるものは一番SQLで実行しやすい形です。
{ &amp;#34;name&amp;#34;: &amp;#34;Tanaka&amp;#34;, &amp;#34;age&amp;#34;: 26 } { &amp;#34;name&amp;#34;: &amp;#34;Suzuki&amp;#34;, &amp;#34;age&amp;#34;: 32 }一つのJSONの場合は上記を配列化します。
[ { &amp;#34;age&amp;#34;: &amp;#34;26&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Tanaka&amp;#34; }, { &amp;#34;age&amp;#34;: &amp;#34;32&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Suzuki&amp;#34; } ]どちらもそのままSELECT name, age FROM example0.jsonのようにtrdsqlのSQLとして実行できます。
JSONはオブジェクトや配列で入れ子に出来るため、ルートが対象とならない場合があります。以下の場合は、そのまま実行すると menu 列が一つに中身がすべて入っていることになります。
{ &amp;#34;menu&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;value&amp;#34;: &amp;#34;File&amp;#34;, &amp;#34;popup&amp;#34;: { &amp;#34;menuitem&amp;#34;: [ { &amp;#34;value&amp;#34;: &amp;#34;New&amp;#34;, &amp;#34;onclick&amp;#34;: &amp;#34;CreateDoc()&amp;#34; }, { &amp;#34;value&amp;#34;: &amp;#34;Open&amp;#34;, &amp;#34;onclick&amp;#34;: &amp;#34;OpenDoc()&amp;#34; }, { &amp;#34;value&amp;#34;: &amp;#34;Save&amp;#34;, &amp;#34;onclick&amp;#34;: &amp;#34;SaveDoc()&amp;#34; } ] } } }SQLのJSON関数を使用することで内部のオブジェクトにアクセスできますが、ほとんどがJSON関数の記述になってしまうのでSQLで実行するメリットが感じられません。</description>
    </item>
    <item>
      <title>trdsql v0.9.0</title>
      <link>https://noborus.github.io/blog/trdsql_090/index.html</link>
      <pubDate>Mon, 24 May 2021 16:47:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_090/index.html</guid>
      <description>trdsql v0.9.0をリリースしました。 リリースのページから各バイナリがダウンロードできます。
JSONに対してjq式でフィルタを掛けられるようになりました。 JSONに対してtrdsqlでは最初のオブジェクトや配列をテーブルとみなして処理します。 JSONは階層構造に出来るため、その中のオブジェクトをテーブルとしたい場合にはSQLのJSON関数を使うか、jqを使用してフィルタリングしてパイプで受け取る等の処置が必要でした。
これが面倒だったため、JSONファイルに対してjq式を書けるようにしました。
この実装にはgojqを利用しています。
例えば以下のようなJSONファイルがあった場合に、通常のtrdsqlでは menuカラムしかありませんでした。
{ &amp;#34;menu&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;file&amp;#34;, &amp;#34;value&amp;#34;: &amp;#34;File&amp;#34;, &amp;#34;popup&amp;#34;: { &amp;#34;menuitem&amp;#34;: [ { &amp;#34;value&amp;#34;: &amp;#34;New&amp;#34;, &amp;#34;onclick&amp;#34;: &amp;#34;CreateDoc()&amp;#34; }, { &amp;#34;value&amp;#34;: &amp;#34;Open&amp;#34;, &amp;#34;onclick&amp;#34;: &amp;#34;OpenDoc()&amp;#34; }, { &amp;#34;value&amp;#34;: &amp;#34;Save&amp;#34;, &amp;#34;onclick&amp;#34;: &amp;#34;SaveDoc()&amp;#34; } ] } } }ファイル名に追加してjq式を書くことで以下のようにmenuitemに対してSQLを書けるようになります。
trdsql -oat &amp;#34;SELECT * FROM menu.json::.menu.popup.menuitem&amp;#34; +-------+-------------+ | value | onclick | +-------+-------------+ | New | CreateDoc() | | Open | OpenDoc() | | Save | SaveDoc() | +-------+-------------+これによりjqコマンドは必要なくなり、複数のファイル又は一つのJSONファイルの中の複数のテーブルを使用できるようになります。</description>
    </item>
    <item>
      <title>trdsql v0.8.0</title>
      <link>https://noborus.github.io/blog/trdsql_080/index.html</link>
      <pubDate>Wed, 27 Jan 2021 11:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_080/index.html</guid>
      <description>trdsql v0.8.0をリリースしました。 リリースのページから各バイナリがダウンロードできます。
Contextを追加しました。 コマンドでは、killシグナルによって終了するので、変更はないですが、内部的にContextによるキャンセルを出来るようにしました。パッケージ使用する場合にプロセスの終了をせずにキャンセルする処理が書きやすく成ります。
JSON出力でJSONオブジェクトだった場合にjson.RawMessageで返すようになりました。 JSONは入れ子で配列、オブジェクトを入れられますが、これまでのtrdsqlではフラットな文字列として扱うため、JSONの入れ子構造を作ることが出来ませんでした。 json.RawMessageとして返すことで、SQLのJSON関数でJSON化した列をJSONとして扱えるようになりました。
JSON出力時にオブジェクトの順序が保持されるようになりました。 JSONのオブジェクト{&amp;quot;a&amp;quot;: &amp;quot;x&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;y&amp;quot;}が並んだときには順序は無いことになっています。そのため、{&amp;quot;a&amp;quot;: &amp;quot;x&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;y&amp;quot;}と{&amp;quot;b&amp;quot;, &amp;quot;y&amp;quot;,&amp;quot;a&amp;quot;: &amp;quot;x&amp;quot;,}は同じものです。 そのため、trdsqlでJSONやJSONL出力するときに &amp;quot;SELECT a,b FROM test.json&amp;quot;のようなSQLでもJSONに変換された時点でaとbの順序は不定でした。 しかしながら、不便な場合があるのでこの順序を守るようにしました。
~(tilde) を $HOMEに展開するようにしました。 ~/test.csv　などの ~(tilde) の指定は通常shellがおこなうため、&amp;quot;SELECT * FROM ~/test.csv&amp;quot;のようにした場合は~(tilde)が展開されませんでした。trdsqlではファイル名だった場合に自前で置き換えするようにしたので展開されることになります。</description>
    </item>
    <item>
      <title>trdsql 0.7.5</title>
      <link>https://noborus.github.io/blog/trdsql_075/index.html</link>
      <pubDate>Sat, 07 Mar 2020 10:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_075/index.html</guid>
      <description>trdsql 0.7.5をリリースしました。 リリースのページから各バイナリがダウンロードできます。
圧縮ファイルへの対応を強化 trdsql 圧縮ファイルに書いたように圧縮ファイルのサポートを増やしました。
また、圧縮しての出力をできるようにしました。
ファイルへの出力 trdsql outputに書いたように出力ファイルを指定して出力できるようになりました。
出力ファイル名から出力フォーマットと圧縮フォーマットを推測するのがデフォルトの動作になっています。
オプションが増加したため、-helpメッセージの出力を見直しました。 以下のようになります。
trdsql - Execute SQL queries on CSV, LTSV, JSON and TBLN. Usage: trdsql [OPTIONS] [SQL(SELECT...)] Options: -A string analyze the file but only suggest SQL. -a string analyze the file and suggest SQL. -config string configuration file location. -db string specify db name of the setting. -dblist display db information. -debug debug print. -driver string database driver. [ mysql | postgres | sqlite3 ] -dsn string database driver specific data source name.</description>
    </item>
    <item>
      <title>trdsql output</title>
      <link>https://noborus.github.io/blog/34_output/index.html</link>
      <pubDate>Mon, 02 Mar 2020 18:45:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/34_output/index.html</guid>
      <description>今までは標準出力にのみ出力していましたが、-out ファイル名により、出力ファイルを指定できるようにしました。
-out ファイル名では出力ファイル名からファイル形式、圧縮形式を推測するモードをデフォルトで有効にしてあります。
出力ファイル名の拡張子が[.csv,.ltsv,json,jsonl,tbln,md,at,vf,raw]等の出力ファイル形式の拡張子だった場合は自動でその出力形式で出力します。
以下はLTSV形式で出力します。
trdsql -out test.ltsv &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 出力フォーマットを指定した場合は、出力フォーマットが優先されます。以下はjsonl形式で出力されます。
trdsql -ojsonl -out test.txt &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 圧縮形式も推測するので、test.csv.gzのようにした場合はCSV形式のgzip圧縮で出力されます。基本的ファイルの拡張子はファイル形式.圧縮形式の順です。
以下はLTSV形式でzstd圧縮で出力されます。
trdsql -out test.ltsv.zst &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 圧縮フォーマットも-oz 圧縮形式で指定した場合はそちらが優先されます。
例えば、.zstの拡張子を付けたいが圧縮してほしくない（理由はわかりませんが&amp;hellip;)の場合は、-out-without-guessを付けて実行して下さい。</description>
    </item>
    <item>
      <title>trdsql 圧縮ファイル</title>
      <link>https://noborus.github.io/blog/33_compression/index.html</link>
      <pubDate>Mon, 02 Mar 2020 17:52:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/33_compression/index.html</guid>
      <description>圧縮ファイルに実行 0.7.4までは gzip(.gz)の圧縮形式のみの対応でしたが、最新のmaster(0.7.5以降の予定)では、gzip(gz)、bzip2(bz2)、zstd(zst)、lz4、xzの圧縮形式に対応しました。
従来は.gzの拡張子をみて判断していましたが、今回から圧縮形式のファイルの先頭のマジックナンバー（signatureの値）を見て判断するようになりました。そのため、拡張子が何であっても上記の圧縮形式はそのまま読み取ることが出来ます。
圧縮率にもよりますが、デフォルトレベルのzstdでの圧縮されたファイルをtrdsqlで処理すると、手元のマシンでの処理時間はほぼ変わらないか、少しzstdで圧縮されているファイルのほうが早いくらいです。
例えば以下のような145MBのファイルに対してzstdで圧縮すると44MBになりました。
145M worldcitiespop.csv 44M worldcitiespop.csv.zst timeを付けての結果は以下のようになりました。
/usr/bin/time -p trdsql -ih &amp;#34;SELECT count(*) FROM worldcitiespop.csv&amp;#34; real 11.47 user 11.76 sys 0.70 zstd圧縮
/usr/bin/time -p trdsql -ih &amp;#34;SELECT count(*) FROM worldcitiespop.csv.zst&amp;#34; real 9.76 user 11.00 sys 0.37 LTSVファイルでは、同じ内容のCSVファイルよりもファイルサイズが大きくなりますが、圧縮効率は良いので圧縮したときのファイルサイズの差は小さくなります。
330M worldcitiespop.ltsv 54M worldcitiespop.ltsv.zst 145MBをLTSVにすると330MBのファイルになっていたのが、圧縮するとCSV:44MB、LTSV:54MBになります。
処理時間は以下のようになりました。
/usr/bin/time -p trdsql &amp;#34;SELECT count(*) FROM worldcitiespop.ltsv real 16.72 user 17.41 sys 1.05 /usr/bin/time -p trdsql &amp;#34;SELECT count(*) FROM worldcitiespop.ltsv.zst&amp;#34; 3173958 real 13.93 user 16.</description>
    </item>
    <item>
      <title>trdsql 0.7.4</title>
      <link>https://noborus.github.io/blog/trdsql_074/index.html</link>
      <pubDate>Wed, 05 Feb 2020 10:00:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/trdsql_074/index.html</guid>
      <description>trdsql 0.7.4をリリースしました。 リリースのページから各バイナリがダウンロードできます。
全ての項目を二重引用符（”）で囲うオプション(-oaq)を追加 今回は、CSV出力に全ての項目を二重引用符（”）で囲うオプション(-oaq)を追加しました。
goのencoding/csvはRFC 4180に沿って実装されていますが、必要な項目を二重引用符（”）で囲うようになっていますが、全ての項目を囲う方法は用意されていません。要望はありましたが、却下されています。
trdsqlにも要望が以前より来ていましたが、encoding/csvが対応していないので、対応出来ないとして、カスタマイズする方法を提示していました。 今回別の方からも要望が来たので、実装しました。
encoding/csvでは対応出来ないので、別の方法で実装する必要がありますが、定番と言えるモジュールは無く実装自体は難しくないので、自前で実装することにしました。と言ってもencoding/csvのコードから少し変更しているだけです。
その際に、関連する箇所を見直して、全体の出力が速くなるように改善しました。多くの出力をする場合でないと違いは出ませんが、手元では317万行(145MB)あるファイルを &amp;quot;SELECT * FROM 〜&amp;quot;で出力してみたら、全体で10%ほど高速化していました。
またその他に、二重引用符（”）以外の引用符が使用できる(-oq)と改行文字をCRLFに変更する(-ocrlf)を追加しました。 CRLFはRFC 4180にあり、encoding/csvでも対応していたのですが、入れそびれていたので今回入れました。 引用符は変更してしまうとtrdsqlで読めないCSVになってしまうので注意が必要です。普通は使わないと思うのでかなり特殊用途だと思います。
GitHub Actions でのバイナリ作成に変更 これまで travis-ciでリリース時にビルドしてアップロードしていましたが、GitHub Actionsに変更しました。 途中まではtravis-ciと同様に各環境でビルドしてアップロードしていましたが、crazy-max/xgo(https://github.com/karalabe/xgoのfork版ですが、こちらでないとまだ問題がありました)で、クロスビルドが出来たので、こちらでビルドしてアップロードしています。
crazy-max/ghaction-xgoを使用した場合は、ビルドからアップロードまで簡単に出来るようになっていますが、zipでアーカイブしてアップロードしたかったため、Makefileでビルドまでおこないアップロードをおこなっています。
対応環境数が大幅に増えたため、ワイルドカードでファイルが指定できるAButler/upload-release-assetsを使用してアップロードしています。
armやmipsは環境が無いので自分では動かして試して見ることが出来ません。問題がありましたらお知らせ下さい。</description>
    </item>
    <item>
      <title>trdsql CASE式</title>
      <link>https://noborus.github.io/blog/32_case/index.html</link>
      <pubDate>Tue, 07 Jan 2020 10:18:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/32_case/index.html</guid>
      <description>CASE式は、プログラム言語のif文やswitch文のような条件に分岐した処理をおこないます。単純な1を&amp;rsquo;A&amp;rsquo;に変換するような場合は、一時的なテーブルとJOINさせたり文字列の書き換えで可能ですが、 範囲を指定してグループ化したい場合はCASE式を使うと便利です。
CASE式には以下の2つのパターンどちらも使用できます。
CASEは CASE 式（列) WHEN 値 THEN 結果とCASEの後に式を書いて、WHENが値だけのパターンと CASE WHEN 式 THEN 結果 とCASEの式を省略してWHENに式を書くパターン 必要であれば、ELSE 結果で当てはまらない場合を書き、ENDで式の終わりを示します。
case.csv のようなCSVを使用して、scoreが80以上の場合は&amp;rsquo;A&amp;rsquo;、30以上の場合は、&amp;lsquo;B&amp;rsquo;、30より下の場合は、&amp;lsquo;F&amp;rsquo;と表示させてみます。
id,name,score 1,bob,89 2,alice,75 3,dave,23trdsql -ih -oat \ &amp;#34;SELECT id,name,score, &amp;#34; \ &amp;#34; CASE WHEN CAST(score AS int) &amp;gt;= 80 THEN &amp;#39;A&amp;#39; &amp;#34; \ &amp;#34; WHEN CAST(score AS int) &amp;gt;= 30 THEN &amp;#39;B&amp;#39; &amp;#34; \ &amp;#34; ELSE &amp;#39;F&amp;#39; &amp;#34; \ &amp;#34; END AS evaluation &amp;#34; \ &amp;#34; FROM case.csv&amp;#34; +----+-------+-------+------------+ | id | name | score | evaluation | +----+-------+-------+------------+ | 1 | bob | 89 | A | | 2 | alice | 75 | B | | 3 | dave | 23 | F | +----+-------+-------+------------+CASE式は書いた先から評価されます。</description>
    </item>
    <item>
      <title>trdsql 合計を行に追加する</title>
      <link>https://noborus.github.io/blog/31_rollup/index.html</link>
      <pubDate>Sat, 04 Jan 2020 13:38:00 +0900</pubDate>
      <guid>https://noborus.github.io/blog/31_rollup/index.html</guid>
      <description>Window関数により元のファイルの内容に列を追加して、集計結果を出せました。 ただ、人が確認する場合は、集計の結果行が最後に出るほうが確認しやすくなります。
通常のSQLでも元の内容と集計結果を別々に出してUNIONを使うことで、一つの結果として出すことが出来ますが、一回で済むならばそれに越したことはありません。
SQLite3ではサポートされていませんが、PostgreSQLとMySQLならばサポートされている文があります。
ROLLUP Window関数でも使用した以下のCSVファイルを使用します。
id,class,name,score 1,A,bob,174 2,A,alice,248 3,A,carol,163 4,B,dave,289 5,B,eve,157 6,B,flank,272通常のGROUP BYで全体の合計又は、class毎の合計が出せました。 ただし、class毎の合計と全体の合計を出すにはWindow関数を使用して別の列に出していました。
GROUP BYに ROLLUPを指定することで、両方を出力できます。
PostgreSQL PostgreSQLでは、GROUP BY 列名の代わりにGROUP BY ROLLUP(列名)を使用することで、通常のGROUP BYに加えて、全体の集計結果を出力します。
trdsql -driver &amp;#34;postgres&amp;#34; -dsn &amp;#34;dbname=trdsql_test&amp;#34; -oat -ih \ &amp;#34;SELECT class, SUM(score::int) AS score FROM score.csv GROUP BY ROLLUP(class) ORDER BY class&amp;#34; +-------+------+ | class | sum | +-------+------+ | A | 585 | | B | 718 | | | 1303 | +-------+------+MySQL MySQLでは、GROUP BY 列名の後に WITH ROLLUPを付けると、通常のGROUP BYに加えて、全体の集計結果を出力します。</description>
    </item>
    <item>
      <title>trdsql convert log</title>
      <link>https://noborus.github.io/blog/30_convert_log/index.html</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/30_convert_log/index.html</guid>
      <description>既存のログをLTSVに変換する 既存のログをLTSVに変換にしてみます。
mingrammer/flog を使用するとフェイクのログが簡単に出力できるので、 これで出力されるログをLTSV形式に変換する方法を紹介します。
Apache common log 以下のコマンドにより apache_common形式のログをaccess.common.logとして保存します。
flog -f apache_common -t log -o access.common.log 内容は、以下のようになります。
92.129.44.198 - metz3917 [30/Dec/2019:17:02:27 +0900] &amp;#34;DELETE /infomediaries/e-markets HTTP/2.0&amp;#34; 500 24843 246.54.243.199 - - [30/Dec/2019:17:02:27 +0900] &amp;#34;POST /24%2f7 HTTP/1.1&amp;#34; 302 8879 9.172.27.159 - - [30/Dec/2019:17:02:27 +0900] &amp;#34;DELETE /convergence/best-of-breed HTTP/1.1&amp;#34; 203 3252 49.129.77.219 - kozey2248 [30/Dec/2019:17:02:27 +0900] &amp;#34;PUT /embrace HTTP/1.1&amp;#34; 301 2812 216.42.120.216 - - [30/Dec/2019:17:02:27 +0900] &amp;#34;HEAD /infomediaries HTTP/2.0&amp;#34; 204 12516これを trdsqlの -id &amp;quot; &amp;quot; によりスペース区切りで解析すると c4とc5でタイムが分かれてしまいますが、それ以外は問題無さそうです。</description>
    </item>
    <item>
      <title>trdsql generate_series</title>
      <link>https://noborus.github.io/blog/29_generate_series/index.html</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/29_generate_series/index.html</guid>
      <description>generate_series PostgreSQLにはgenerate_series()という便利な関数があります。 これはUnixのseqコマンドと同じような働きをする関数です。またgenerate_series()は、タイムスタンプ型にも使用できる拡張があります。
使い方は簡単で「開始値」、「終了値」、「刻み値（省略可能）」を指定して実行します。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; &amp;#34;SELECT * FROM generate_series(1,10)&amp;#34; 1 2 3 4 5 6 7 8 9 10generate_series()はテーブルを返す関数で、テーブルの代わりに使用できます。 （SELECT generate_series(1,10)と書くこともできます）。
もちろん、trdsqlでは、外部からの入力を簡単に取り入れられるので、seqコマンドで代用することもできます。
seq 1 10|trdsql &amp;#34;SELECT * FROM -&amp;#34; 1 2 3 4 5 6 7 8 9 10seqコマンドは、引数の順序が「開始値」、「刻み値（省略可能）」「終了値」になります。 2つの値を渡すときには同じですが、刻み値を指定する場合は、順序が異なるので注意が必要です。
タイムスタンプ generate_series()では、タイムスタンプを扱えるので、2020年のカレンダーを日本語で出すと少々トリッキーですが、以下のようになります。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; \ &amp;#34;SET LC_TIME=&amp;#39;ja_JP.UTF-8&amp;#39;; &amp;#34; \ &amp;#34;SELECT to_char(day,&amp;#39;YYYY年TMMonthDD日 (TMDay)&amp;#39;) &amp;#34; \ &amp;#34; FROM generate_series(&amp;#39;2020-01-1&amp;#39;::timestamp,&amp;#39;2020-12-31&amp;#39;,&amp;#39;1 day&amp;#39;) as day&amp;#34; 2020年1月01日 (水曜日) 2020年1月02日 (木曜日) 2020年1月03日 (金曜日) 2020年1月04日 (土曜日) .</description>
    </item>
    <item>
      <title>trdsql CROSS JOIN</title>
      <link>https://noborus.github.io/blog/28_cross_join/index.html</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/28_cross_join/index.html</guid>
      <description>CROSS JOINは、総当りを簡単に作り出せる方法です。
a.csv
aa ab acb.csv
ba bb bcの２つのCSVをCROSS JOINすると 3×3で全ての組み合わせを出力できます。
trdsql &amp;#34;SELECT * FROM a.csv CROSS JOIN b.csv&amp;#34; aa,ba aa,bb aa,bc ab,ba ab,bb ab,bc ac,ba ac,bb ac,bcまた一つのファイルに対して自己結合をすることもできます。 例えば、ホーム＆アウェーの総当り表を作成してみます。
cleague.csv
team 巨人 DeNA 阪神 広島 中日 ヤクルト単純にCROSS JOINするには以下のようになります（JOIN条件は無いので書けません）。
trdsql -ih \ &amp;#34;SELECT h.team,a.team &amp;#34;\ &amp;#34; FROM cleague.csv AS h &amp;#34;\ &amp;#34; CROSS JOIN cleague.csv AS a&amp;#34;自分のチームとは対戦出来ないので、同じチームのときをWHERE h.team != a.teamにより除外します。
trdsql -ih -omd \ &amp;#34;SELECT h.team AS home,a.team AS aware &amp;#34; \ &amp;#34; FROM cleague.</description>
    </item>
    <item>
      <title>trdsql config</title>
      <link>https://noborus.github.io/blog/27_config/index.html</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/27_config/index.html</guid>
      <description>trdsqlは設定ファイルが無くても動作しますが、設定ファイルによりデフォルトのデータベースのエンジンを変更できます。
configファイルの場所 -configオプションで、直接ファイルの場所を指定できます。
-configオプションを使用しないデフォルトの場所は以下です。
Linux等のWindows以外 ${HOME}/.config/trdsql/config.jsonWindows %APPDATA%trdsql\config.json です。多くは以下の位置になります。
C:\Users\{&amp;#34;User&amp;#34;}\AppData\Roaming\trdsql\config.jsonconfigファイルの内容 以下がサンプルです。
{ &amp;#34;db&amp;#34;: &amp;#34;pdb&amp;#34;, &amp;#34;database&amp;#34;: { &amp;#34;sdb&amp;#34;: { &amp;#34;driver&amp;#34;: &amp;#34;sqlite3&amp;#34;, &amp;#34;dsn&amp;#34;: &amp;#34;&amp;#34; }, &amp;#34;pdb&amp;#34;: { &amp;#34;driver&amp;#34;: &amp;#34;postgres&amp;#34;, &amp;#34;dsn&amp;#34;: &amp;#34;user=test dbname=test&amp;#34; }, &amp;#34;mdb&amp;#34;: { &amp;#34;driver&amp;#34;: &amp;#34;mysql&amp;#34;, &amp;#34;dsn&amp;#34;: &amp;#34;user:password@/dbname&amp;#34; } } }&amp;ldquo;database&amp;rdquo; に &amp;ldquo;名前&amp;rdquo;: {&amp;ldquo;driver&amp;rdquo;: ドライバ名(sqlite3 or postgres or mysql), &amp;ldquo;dsn&amp;rdquo;: &amp;ldquo;ドライバに沿ったDSN&amp;rdquo;} でデータベースを定義しておき、最初の &amp;ldquo;db&amp;quot;に定義した&amp;quot;名前&amp;quot;を書くとデフォルトのエンジンが変更されます。
上記では、&amp;ldquo;pdb&amp;quot;がデフォルトになり、&amp;ldquo;postgres&amp;quot;エンジンが使用されます。
デフォルトの変更だけでなく、ここで定義しておくと trdsqlのオプション -db mdb を指定することにより、簡単にmysqlドライバのエンジンに切り替えられます。
確認方法 configファイルが無くても動作するため、実際にエンジンが変更されているかわかりにくいことがあります。
trdsqlを-debugオプション付きで起動すると詳細が表示されますので、そこで確認して下さい。
設定ファイルが見つからなかった場合 trdsql -debug -db pdb &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 2019/12/27 11:22:13 configOpen: open /home/noborus/.</description>
    </item>
    <item>
      <title>trdsql SQLファイル指定</title>
      <link>https://noborus.github.io/blog/26_file_sql/index.html</link>
      <pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/26_file_sql/index.html</guid>
      <description>SQLファイル名指定オプション「-q」 trdsql &amp;ldquo;SQLコマンド&amp;quot;の形式だと、長いSQLを書くのが難しいですし、シェルに対してエスケープしなければならない文字があって見た目もわかりにくい場合があります。
trdsqlではファイルにSQLを書いておき、そのファイルのSQLを実行させるオプションがあります。
以下のように記述したSQLをtest.sqlで保存しておきます。
test.sql
SELECT id, `name` FROM testsql.csv（コマンドの引数で渡していたときは「\`」のように「`」をエスケープする必要がありましたが、ファイルのSQLを実行する場合は必要ありません）。
testsql.csv は対象となるCSVファイルです。
id,name 1,tarou 2,jirou&amp;ldquo;SQLコマンド&amp;rdquo; の代わりに 「-q ファイル名.sql」で実行します。それ以外のオプションは代わりません。
trdsql -ih -oat -q test.sql+----+-------+ | id | name | +----+-------+ | 1 | tarou | | 2 | jirou | +----+-------+</description>
    </item>
    <item>
      <title>trdsql ライブラリ使用</title>
      <link>https://noborus.github.io/blog/25_library/index.html</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/25_library/index.html</guid>
      <description>trdsqlは初期の頃は、main packageで構成されていましたが、現在はtrdsql packageをmainから呼び出す構成になっていて、trdsql packageをライブラリとして使用できます。
trdsqlのパッケージは、以下の構成になっていて、それぞれ呼び出し可能です。
簡単なサンプルを示します。
package main import ( &amp;#34;log&amp;#34; &amp;#34;github.com/noborus/trdsql&amp;#34; ) func main() { trd := trdsql.NewTRDSQL( trdsql.NewImporter(trdsql.InDelimiter(&amp;#34;:&amp;#34;)), trdsql.NewExporter(trdsql.NewWriter()), ) err := trd.Exec(&amp;#34;SELECT c1 FROM /etc/passwd&amp;#34;) if err != nil { log.Fatal(err) } }上記のプログラムは/etc/passwdに対してSQL文を実行しています。 Importer(データベースにインポートするインターフェイス）とExporter(データベースから結果を出力するインターフェイス）を与えてTRDSQLをNewし、Execで実行するのが、おおまかな流れです。
func NewTRDSQL(im Importer, ex Exporter) *TRDSQLこのImporter,Exporterはインターフェイスに沿っていれば、置き換えられます（例えば、SQL内のファイルをインポートするのではなく、独自にインポートするにはImporterのインターフェイスに沿った関数を作成します）。
Importer デフォルトのImporterは、trdsql.NewImporter()を呼び出せば作成できます。 デフォルトのImporterはtrdsql.Import()でReadOptsのオプションを取ります。ここでフォーマットやその他オプションを渡します。
SQL文にある「/etc/passwd」をデータベースにインポートして使用するのは、デフォルトの動作のため、区切り文字のみ「:」に変更しています。
trdsql.Import()はSQL文を受け取り、必要なファイルをデータベースにインポートします。そのときにファイルの形式に合わせたtrdsql.Readerインターフェイス（各CSV,LTSV,JSON,TBLNのReader)からテーブルへインポートされます。
また、インポートするデータベースによってバルクインサートかCOPYによるインポートを選択してインポートしています。
Exporter デフォルトのExporterは、trdsql.NewExporter()を呼び出せば作成できます。 SQLでは出力は1つなので、出力する関数（trdsql.NewWriter()）を渡しています。 trdsql.NewWriter()はWriteOptsによりフォーマットと動作のオプションを設定して、実際のWriter関数（CSV、LTSV、JSON、TBLN、AT、VF&amp;hellip;)によりSQLを実行した結果を書き出します。
Exec ImporterとExporterの準備が済んでいれば、ExecでSQLを実際に実行します。
データベース接続 トランザクションの開始 Importerでインポートの実行 Exporterで指定したSQLの実行をして出力 トランザクションの終了 データベース切断 参考資料 trdsqlには、参考してファイルからのインポートだけでなく、スライスからインポートする関数が入っています。 それを利用したサンプルが _example/slice/ にあります。
また、trdsql packageを利用してshirou/gopsutilの結果をSQLで取得できるようにしたものが、 noborus/psutilsql です。</description>
    </item>
    <item>
      <title>trdsql グラフ</title>
      <link>https://noborus.github.io/blog/24_graph/index.html</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/24_graph/index.html</guid>
      <description>trdsqlは、グラフ作成機能は持っていないためグラフを作成したいときには別のツールを使用して作成することになります。
ExcelやLibreOfficeで描画するのが定番でしょうが、ここではmarianogappa/chartでグラフを描画する方法を紹介します。
marianogappa/chartは、Goで作られていて、や多くのプラットフォームで動作して、標準入力から受け取ったデータをブラウザに描画します。
複雑なグラフには向いていませんが、簡単なグラフを少ないオプションを指定するだけで描画できます。
chartに与えるデータは表示したいグラフによりますが、1列又は2列のデータです。
例えばchartのデフォルトのpieでは、以下のような文字列が並んでいるようなデータを集計して円グラフにしてくれます。
aaa bbb ccc aaa aaa aaacat aaa.csv|chart（ブラウザが開いて表示されます）
これを使用して例えば、ログ集計で使用したログのリクエストをグラフにすると以下のようになります。
trdsql &amp;#34;SELECT req FROM log.ltsv&amp;#34;|chart また、他のグラフでは、1列目がx項目名で、2列目が値として与えます。デフォルトはタブ区切りのデータを受け取るので、タブ区切りで出力します。
ログ集計のリクエストが多い順をTOP 20に変えて出力すると以下のようになります。
trdsql -od &amp;#34;\t&amp;#34; \ &amp;#34;SELECT req, count(req) as count &amp;#34; \ &amp;#34;FROM log.ltsv &amp;#34; \ &amp;#34;GROUP BY req &amp;#34; \ &amp;#34;ORDER BY count DESC LIMIT 20&amp;#34; |chart bar marianogappa/chartは、Chart.jsを使用してグラフを描画しています。Chart.js自体が簡単なJavaScriptを用意すれば描画してくれるので、もう少し複雑なグラフを描きたい場合は直接利用するのが良いでしょう。</description>
    </item>
    <item>
      <title>trdsql 差分、比較</title>
      <link>https://noborus.github.io/blog/23_except/index.html</link>
      <pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/23_except/index.html</guid>
      <description>CSV同士やCSVとテーブルなどで、値の比較をしたい場合があります。
同じ形式で一部が違うCSVファイルであれば、diffを取る方法もありますが、trdsqlのSQLを使用して比較すると形式が違う場合の比較にも使用できます。
差分の出力 SQLで比較して、差分を出すには、EXCEPTを使用します。EXCEPTは Aのテーブルから Bのテーブルを引いた残りのAの内容を出力します。
Bの方に多くの行があっても関係なく、AにあってBにない行を出力します。
以下のCSVファイルで比較してみます。new.csvで、3の更新と4の追加があるCSVファイルです。
old.csv
1,AAA 2,BBB 3,CCCnew.csv
1,AAA 2,BBB 3,CCB 4,DDD単純に全列を比較すると1と2の行が同じであるため、消されて残った3と4が出力されます。 この場合old.csv側にnew.csvにない行があっても出力されません。diffの比較とは違いますね。
trdsql &amp;#34;SELECT * FROM new.csv EXCEPT SELECT * FROM old.csv &amp;#34; 3,CCB 4,DDDテーブルとファイルの差分出力 既存のデータベースに接続すれば、テーブルとの比較もできます。
例えば、trdsql DBインポートでインポートしたテーブルと更新されたCSVとの比較をしたいときには、以下のようにすると良いでしょう。
CSVファイル側をキャストして型を合わせています。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih -oh \ &amp;#34;SELECT id::int,name FROM fruits.csv &amp;#34; \ &amp;#34;EXCEPT &amp;#34; \ &amp;#34;SELECT id,name FROM fruits &amp;#34; id,name 4,Grapeデータベース側のテーブルが更新されて新しい場合は、逆にテーブル EXCEPT CSVファイルとすれば、良いでしょう。
共通の行の出力 また、EXCEPTとは逆に共通の行を出力させたいときには、INTERSECT を使用します。
&amp;#34;SELECT id::int,name FROM fruits.csv &amp;#34; \ &amp;#34;INTERSECT &amp;#34; \ &amp;#34;SELECT id,name FROM fruits&amp;#34; id,name 1,Orange 2,Melon 3,Apple</description>
    </item>
    <item>
      <title>trdsql JSON出力</title>
      <link>https://noborus.github.io/blog/22_json_output/index.html</link>
      <pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/22_json_output/index.html</guid>
      <description>CSVやLTSVなどのフラットな形式のデータは、JSONにしたいときには（-ojsonによる）JSON出力をすれば良いですが、JSONは本来より深い階層も表現できるフォーマットです。
そのようなJSONは、データベースのJSON関数を使用することにより作成できます。
以下のCSVからJSON関数でJSON出力をしてみます。
id,name 1,Orange 2,Melon 3,AppleJSON関数で出力する場合は、「”」等がエスケープされない-orawを使用して出力すると、有効なJSONとして出力できます。
SQLite3、MySQL SQLite3、MySQLでは、json_array()やjson_object()を使用することによりJSONを生成できます。 ここでは「名前:値」の形式で出力するためjson_objectを使用します。2つペアの引数で、指定していきます。
trdsql -ih -oraw &amp;#34;SELECT json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name) FROM header.csv&amp;#34; {&amp;#34;id&amp;#34;:&amp;#34;1&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;Orange&amp;#34;} {&amp;#34;id&amp;#34;:&amp;#34;2&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;Melon&amp;#34;} {&amp;#34;id&amp;#34;:&amp;#34;3&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;Apple&amp;#34;}階層を深くするには、json_object()を内部でさらに使います。 SQLite3にはjson_pretty()関数が無いので、jqで見やすくしています。
trdsql -ih -oraw &amp;#34;SELECT json_object(&amp;#39;fruits&amp;#39;, json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name)) FROM header.csv&amp;#34;|jq . { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Orange&amp;#34; } } { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;2&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Melon&amp;#34; } } { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;3&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Apple&amp;#34; } }上記の結果は1行1JSONで出力されています。これをさらに配列にして、一つのJSONにするには、SQLite3では json_group_array()、MySQLではjson_arrayagg()でグループ化して出力できます。
SQLite3 trdsql -ih -oraw &amp;#34;SELECT json_group_array(json_object(&amp;#39;fruits&amp;#39;, json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name))) FROM header.csv&amp;#34;|jq . [ { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Orange&amp;#34; } }, { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;2&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Melon&amp;#34; } }, { &amp;#34;fruits&amp;#34;: { &amp;#34;id&amp;#34;: &amp;#34;3&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;Apple&amp;#34; } } ]MySQL trdsql -driver mysql -dsn &amp;#34;noborus:noborus@/trdsql_test&amp;#34; -ih -oraw &amp;#34;SELECT json_pretty(json_arrayagg(json_object(&amp;#39;fruits&amp;#39;, json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name)))) &amp;#34;\ &amp;#34;FROM header.</description>
    </item>
    <item>
      <title>trdsql JSON解析</title>
      <link>https://noborus.github.io/blog/21_json_parse/index.html</link>
      <pubDate>Sat, 21 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/21_json_parse/index.html</guid>
      <description>これまでtrdsqlでは、JSONの入力が可能と書きましたが、例として書いたのは基本的にフラットな構造のJSONでした。 ただ、２階層以上の階層構造が含まれるJSONはエラーになる訳ではなく、そのまま文字列として扱われます。
以下のようなJSONがあるとします。
sample.json
[ { &amp;#34;color&amp;#34;: &amp;#34;white&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;value&amp;#34;, &amp;#34;code&amp;#34;: { &amp;#34;rgba&amp;#34;: [0, 0, 0, 1], &amp;#34;hex&amp;#34;: &amp;#34;#FFF&amp;#34; } }, { &amp;#34;color&amp;#34;: &amp;#34;red&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;hue&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;primary&amp;#34;, &amp;#34;code&amp;#34;: { &amp;#34;rgba&amp;#34;: [255, 0, 0, 1], &amp;#34;hex&amp;#34;: &amp;#34;#FF0&amp;#34; } }, { &amp;#34;color&amp;#34;: &amp;#34;blue&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;hue&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;primary&amp;#34;, &amp;#34;code&amp;#34;: { &amp;#34;rgba&amp;#34;: [0, 0, 255, 1], &amp;#34;hex&amp;#34;: &amp;#34;#00F&amp;#34; } } ]これをそのままtrdsqlを実行すると以下のようになります(見やすいように-oatを付けています。CSV出力にすると「&amp;quot;」が含まれる文字列のためエスケープされて出力されます。)
trdsql -oat &amp;#34;SELECT color,category,code FROM sample.json&amp;#34; +-------+----------+-----------------------------------+ | color | category | code | +-------+----------+-----------------------------------+ | white | value | {&amp;#34;hex&amp;#34;:&amp;#34;#FFF&amp;#34;,&amp;#34;rgba&amp;#34;:[0,0,0,1]} | | red | hue | {&amp;#34;hex&amp;#34;:&amp;#34;#FF0&amp;#34;,&amp;#34;rgba&amp;#34;:[255,0,0,1]} | | blue | hue | {&amp;#34;hex&amp;#34;:&amp;#34;#00F&amp;#34;,&amp;#34;rgba&amp;#34;:[0,0,255,1]} | +-------+----------+-----------------------------------+このcodeは文字列の扱いですが、各データベースは既にJSONを扱える関数を備えているため、データベース側の関数を使って変更できます。</description>
    </item>
    <item>
      <title>trdsql 日付・時刻処理</title>
      <link>https://noborus.github.io/blog/20_date/index.html</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/20_date/index.html</guid>
      <description>ファイル内に入っている日付、時刻をそのまま扱う場合は良いですが、変換等の処理をしたい場合があります。
その場合は、一旦日付や時刻と解釈させてから扱う方が扱いやすくなります。
SQLite3の日付、時刻処理 デフォルトのSQLite3の日付、時刻処理では、以下のフォーマットであれば、日付、時刻として解釈することができます。 もしSQLite3のエンジンで処理したい場合は、このフォーマットにしておくと良いでしょう。
YYYY-MM-DD YYYY-MM-DD HH:MM YYYY-MM-DD HH:MM:SS YYYY-MM-DD HH:MM:SS.SSS YYYY-MM-DDTHH:MM YYYY-MM-DDTHH:MM:SS YYYY-MM-DDTHH:MM:SS.SSS HH:MM HH:MM:SS HH:MM:SS.SSS now DDDDDDDDDD 以下のようなログファイルのtimeを処理したい場合、
time:2015-09-06T05:58:05+09:00	method:POST	... time:2015-09-06T05:58:41+09:00	method:POST	... time:2015-09-06T06:00:42+09:00	method:GET	...datetime(time)で日時として、認識させれば、strftime()で再フォーマットがしやすくなります。
trdsql -iltsv &amp;#34;SELECT strftime(&amp;#39;%Y年%m月%d日%H時%M分%S秒&amp;#39;,datetime(time)) FROM log.ltsv&amp;#34; 2015年09月05日20時58分05秒 2015年09月05日20時58分41秒 2015年09月05日21時00分42秒上記以外のフォーマットの場合は、SQLite3では文字列をまず書き換える必要があります。
PostgreSQLの日付、時刻処理 PostgreSQLの日付、時刻処理は、より豊富なフォーマットを処理できます。
多くの場合は、dateやtimestampにCASTするだけで、多くの有名なフォーマットは解釈されます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; &amp;#34;SELECT to_char(CAST(time AS timestamp),&amp;#39;YYYY年MM月dd日HH24時MI分ss秒&amp;#39;) FROM log.ltsv&amp;#34; 2015年09月06日05時58分05秒 2015年09月06日05時58分41秒 2015年09月06日06時00分42秒日付、時刻型に変換されるので、そこから表示するフォーマットに変換するにはto_char()を使用します。指定の仕方はマニュアルを参照して下さい。
さらに独特なフォーマットの場合は、 to_dateやto_timestampにより自分で定義したフォーマットで解釈させることが出来ます。
例えば上記で出力したフォーマットの場合、to_charと同じフォーマット指定でto_timestampを実行すれば逆にタイムスタンプとして扱われます。
trdsql -ih -oh -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; &amp;#34;SELECT to_timestamp(\&amp;#34;日時\&amp;#34;,&amp;#39;YYYY年MM月dd日HH24時MI分ss秒&amp;#39;) FROM d.csv&amp;#34; 2015-09-05T20:58:05+09:00 2015-09-05T20:58:41+09:00 2015-09-05T21:00:42+09:00MySQLの日付、時刻処理 MySQLでも多くのフォーマットをdate()やtimestamp()により変換させることができます。</description>
    </item>
    <item>
      <title>trdsql Window関数</title>
      <link>https://noborus.github.io/blog/19_window/index.html</link>
      <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/19_window/index.html</guid>
      <description>これまでグループ集計による集計を紹介していますが、グループ集計は元の行とはまったく別にグループ毎の行を出力していました。 つまり、元のファイルとは別に集計の結果を出力していた訳です。
そうではなくて、元のファイルの情報にプラスして集計結果を出して欲しい場合があります。 例えば、点数の列では、点数の平均との差を出力したり、柔軟な計算が出来るようになります。これまでの方法では、一旦集計してからJOINするしかありませんでしたが、SQLのWindow関数を使うとそういった集計も出すことが出来ます。
古いバージョンではSQLite3では、Window関数を使用できませんでしたが、現在のtrdsqlに含まれているSQLite3では、Window関数を使用できます。
PostgreSQLやMySQLでもWindow関数が使用できますが、MySQLは8.0からなので、注意が必要です。
合計の表示 合計の計算は集計計算で出しましたが、最後の結果のみを出力していました。 Window関数では、行毎に結果を表示できます。
例えば、以下のような点数のCSVについて結果を表示してみます。
id,class,name,score 1,A,bob,174 2,A,alice,248 3,A,carol,163 4,B,dave,289 5,B,eve,157 6,B,flank,272Window関数は集約関数の関数にOVER ()句を付けることにより範囲や、順序を指定することにより計算をおこないます。 OVER ()句があることで、他の列とは独立して対象の行以外を計算できます。
OVER()句を空で指定すると全行が対象となります。
trdsql -ih -omd \ &amp;#34;SELECT id,name,score, SUM(CAST(score AS int)) OVER () FROM score.csv&amp;#34; | id | name | score | sum | |----|-------|-------|------| | 1 | bob | 174 | 1303 | | 2 | alice | 248 | 1303 | | 3 | carol | 163 | 1303 | | 4 | dave | 289 | 1303 | | 5 | eve | 157 | 1303 | | 6 | flank | 272 | 1303 |SUM()で合計が求められるので、AVG()で平均も求められます。</description>
    </item>
    <item>
      <title>trdsql 列の編集</title>
      <link>https://noborus.github.io/blog/18_edit_columns/index.html</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/18_edit_columns/index.html</guid>
      <description>これまで列の並べ替えはしてきましたが、列の内容はそのままでした。 SQLでは、文字列の書き換えが得意分野とは言えませんが、SQLの関数を使うことにより、それなりできる機能は揃っています。
列の連結 「||」を使って、列名をつなげば、２つ以上の列を連結して一つの列になります。
trdsql -ih -oh \ &amp;#34;SELECT id,name||id AS name_id FROM header.csv&amp;#34; id,name_id 1,Orange1 2,Melon2 3,Apple3列と列だけでなく、文字列をそのまま連結も可能です。SQLの文字列は「&amp;rsquo;」シングルクオートで括ります。
trdsql -ih -oh \ &amp;#34;SELECT id,name||&amp;#39;_&amp;#39;||id AS name_id FROM header.csv&amp;#34; id,name_id 1,Orange_1 2,Melon_2 3,Apple_3PostgreSQL、MySQL またPostgreSQLとMySQLでは、複数の列をつなげたいときには concat(列名or文字列,列名or文字列,&amp;hellip;) が使用できます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih -oh \ &amp;#34;SELECT concat(id,name,&amp;#39;個&amp;#39;) FROM header.csv&amp;#34; concat 1Orange個 2Melon個 3Apple個接続文字を付けてつなげたい場合は、concat_ws(接続文字,列名or文字列,列名or文字列,&amp;hellip;)が使用できます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih -oh \ &amp;#34;SELECT concat_ws(&amp;#39; &amp;#39;,id,name,&amp;#39;個&amp;#39;) FROM header.csv&amp;#34; concat_ws 1 Orange 個 2 Melon 個 3 Apple 個SQLite3 SQLite3では、concat,concat_wsはありませんが、printfが使用できますので、より柔軟に文字列を生成できます。</description>
    </item>
    <item>
      <title>trdsql ファイルとテーブルのJOIN</title>
      <link>https://noborus.github.io/blog/17_file_table/index.html</link>
      <pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/17_file_table/index.html</guid>
      <description>既にテーブルが存在するデータベースに接続することにより、ファイルとテーブルをJOINすることもできます。
例えば、データベース内にfruitsというテーブルがあった場合に、前回のabc.csvとJOINできます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; \ &amp;#34;SELECT a.c1, a.c2, f.name FROM abc.csv AS a &amp;#34;\ &amp;#34;LEFT JOIN fruits AS f ON (CAST(a.c1 AS int) = f.id)&amp;#34; 1,AAA,Orange 2,BBB,Melon 3,CCC,Apple例えば、データベース上にusersテーブルがあり、抽出したいリストがCSVファイルであった場合に、リストをWHERE user IN (...)で並べる等を検討するところですが、trdsqlではダイレクトにJOINして抽出できます。
list.csv
tarou jirou noborususersテーブル
id,name 1,taizou 2,momo 3,taroutrdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; \ &amp;#34;SELECT u.id, u.name FROM users AS u &amp;#34;\ &amp;#34;INNER JOIN list.csv AS l ON (u.name = l.c1)&amp;#34; 3,tarou逆にCSVファイルにデータベースのテーブルから情報を足すといったことも考えられます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; \ &amp;#34;SELECT u.</description>
    </item>
    <item>
      <title>trdsql JOIN</title>
      <link>https://noborus.github.io/blog/16_join/index.html</link>
      <pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/16_join/index.html</guid>
      <description>これまで一つのファイルにSQLを実行してきましたが、複数のファイルをJOINするSQLも実行できます。
以下の2つのCSVファイルがあったとして、
abc.csv
1,AAA 2,BBB 3,CCCprice.csv
1,100 2,500 3,50以下のように連結するのが、JOINです。
1,AAA,100 2,BBB,500 3,CCC,50trdsqlではテーブルの代わりにファイル名を使用すれば、そのままSQLのJOINが書けます。
trdsql &amp;#34;SELECT a.c1, a.c2, p.c2&amp;#34; \ &amp;#34;FROM abc.csv AS a&amp;#34; \ &amp;#34;LEFT JOIN price.csv AS p&amp;#34; \ &amp;#34;USING (c1)&amp;#34;同じ件数で対応する同じ列がある1対1のJOINのため、INNER JOINと同じ結果になります。 LEFT JOINの場合は、先に指定したabc.csvの行はすべて表示され、price.csvは対応する行がある場合のみ表示されます。 今回はヘッダーがないCSVなので、列名はc1,c2&amp;hellip;の共通になるため、一番左側(c1)が共通の列としてUSINGを使用してます。これは ON a.c1 = p.c1 と同じ意味になります。
複数のCSVをJOINするときには、ヘッダーの有無を統一しておく必要があります。
しかしながら、自動判別可能な拡張子になっていれば、CSVとLTSV等の混在は可能です。
unit.ltsv
id:1	unit:個 id:2	unit:箱先程のCSVのJOINの結果に更にLTSVをJOINします。
trdsql -oat \ &amp;#34;SELECT a.c1, a.c2, p.c2, unit&amp;#34; \ &amp;#34; FROM abc.csv AS a&amp;#34; \ &amp;#34;LEFT JOIN price.csv AS p&amp;#34; \ &amp;#34;USING (c1)&amp;#34; \ &amp;#34;LEFT JOIN unit.</description>
    </item>
    <item>
      <title>trdsql DBインポート</title>
      <link>https://noborus.github.io/blog/15_import/index.html</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/15_import/index.html</guid>
      <description>trdsqlにはデータベースにインポートするオプションはありません。 しかしながら、SELECT以外のSQLの実行も可能なので、SQLによるインポートが可能です。
以下は、メモリデータベースにインポートしても終了すると消えてしまうので、メモリデータベース以外のデータベースに接続して実行します。
CREATE TABLE AS テーブルを作成してインポートするには CREATE TABLE ASを使用します。
PostgreSQL で CREATE TABLE AS まず、PostgreSQLへデータをインポートしてみます。 これまで、SELECTで実行してきた内容に CREATE TABLE テーブル名 AS を前につければ、テーブルが作成されデータがインポートされます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih \ &amp;#34;CREATE TABLE test AS SELECT * FROM header.csv&amp;#34;成功した場合、何も表示されずに終了します。失敗した場合、エラーが表示されます。
SELECTの結果がインポートされるため、SELECT側で列名の変更、列の型指定、インポートするデータの条件指定をすれば良いことになります。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih \ &amp;#34;CREATE TABLE fruits AS SELECT id::int AS num, name::VARCHAR(20) FROM header.csv&amp;#34;trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; -ih -oh\ &amp;#34;SELECT * FROM fruits&amp;#34; num,name 1,Orange 2,Melon 3,Appleもし、テーブルの作成のみを先にして、INSERTを後でおこないたい場合はWITH NO DATAを付けます。</description>
    </item>
    <item>
      <title>trdsql SQLite3エンジンの使用</title>
      <link>https://noborus.github.io/blog/14_sqlite3/index.html</link>
      <pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/14_sqlite3/index.html</guid>
      <description>SQLite3への接続方法を説明します。
SQLite3に接続 そもそもtrdsqlのデフォルトはSQLite3のメモリデータベースに接続していますが、メモリデータベース以外にも接続できます。
オプションの -driver に sqlite3 を指定し、-dsn にサーバーへの接続情報を指定します。
dsnはsqlite3のデータファイル名を指定すれば、そのファイルをデータベースとして使用します。 （ファイル名の指定の仕方はfile: や file:// 等も可能です）。
あらかじめファイルが無い場合もエラーにはなりません。
trdsql -driver sqlite3 -dsn &amp;#34;test.sqlite&amp;#34; -oat &amp;#34;SELECT * FROM test&amp;#34; +----+--------+-------+ | id | name | price | +----+--------+-------+ | 1 | Orange | 50 | | 2 | Melon | 500 | | 3 | Apple | 100 | +----+--------+-------+さらに「?」で続けて、オプションを渡すこともできます。 メモリデータベースでオプションを渡すときには 「:memory:?」の後にオプションを続けて下さい。
例えば、LIKEで大文字小文字を区別するように変更するには以下のようにします。
デフォルトではLIKEは大文字小文字が区別されない。
trdsql -driver sqlite3 -dsn &amp;#34;:memory:&amp;#34; -ih &amp;#34;SELECT * FROM header.csv WHERE name LIKE &amp;#39;%a%&amp;#39;&amp;#34; 1,Orange 3,Apple_cslike=trueにすると大文字小文字が区別されます。</description>
    </item>
    <item>
      <title>trdsql MySQLエンジンの使用</title>
      <link>https://noborus.github.io/blog/13_mysql/index.html</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/13_mysql/index.html</guid>
      <description>前回はPostgreSQL接続の話でしたが、今度はMySQLに接続して使用する方法を説明します。
MySQLに接続 MySQLに接続するには動作しているMySQLサーバーが必要です。接続できテーブルが作成できる権限があるデータベースを作成しておきます。
オプションの -driver に mysql を指定し、-dsn にサーバーへの接続情報を指定します。
MySQLのdsnは以下のような形式です。
ユーザー名:パスワード@プロトコル(ホスト名:ポート番号)/データベース名?param=valueparam=valueのパラメーターは多くの種類がありますので、go-sql-driverを参照して下さい。
UNIXドメインソケット ローカルホストのデフォルトのUNIXドメインソケットを使用する場合は、ユーザー名、パスワード、データベース名を指定すれば接続できます。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; UNIXドメインソケットのパスを指定するには、プロトコルにunixを指定して、unix(パス)で指定します。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@unix(/var/run/mysqld/mysqld.sock)/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; TCP接続 TCPはプロトコルにtcpを指定して、tcp(ホスト名:ポート番号)を指定します。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@tcp(localhost:3306)/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; 実テーブルの出力 接続できれば、これまでと同じようにSQLが実行できますが、実際に実行されるのはMySQL上なので、MySQLが実行できるSQLを書く必要があります。
前回のPostgreSQLと同様にMySQLのテーブルに対してSQLを実行し、オプションで指定したフォーマットで出力することが出来ます。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@/trdsql_test&amp;#34; -oat -ih &amp;#34;SELECT * FROM actor LIMIT 10&amp;#34; +----------+------------+--------------+---------------------+ | actor_id | first_name | last_name | last_update | +----------+------------+--------------+---------------------+ | 1 | PENELOPE | GUINESS | 2006-02-15 04:34:33 | | 2 | NICK | WAHLBERG | 2006-02-15 04:34:33 | | 3 | ED | CHASE | 2006-02-15 04:34:33 | | 4 | JENNIFER | DAVIS | 2006-02-15 04:34:33 | | 5 | JOHNNY | LOLLOBRIGIDA | 2006-02-15 04:34:33 | | 6 | BETTE | NICHOLSON | 2006-02-15 04:34:33 | | 7 | GRACE | MOSTEL | 2006-02-15 04:34:33 | | 8 | MATTHEW | JOHANSSON | 2006-02-15 04:34:33 | | 9 | JOE | SWANK | 2006-02-15 04:34:33 | | 10 | CHRISTIAN | GABLE | 2006-02-15 04:34:33 | +----------+------------+--------------+---------------------+</description>
    </item>
    <item>
      <title>trdsql PostgreSQLエンジンの使用</title>
      <link>https://noborus.github.io/blog/12_postgres/index.html</link>
      <pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/12_postgres/index.html</guid>
      <description>trdsqlは組込みのSQLite3を利用してSQLを実行していますが、データベースの処理を別のデータベースに変更出来ます。
ここではPostgreSQLを使用する方法を説明します。
PostgreSQLに接続 SQLite3と違いPostgreSQLは動作しているPostgreSQLサーバーが必要です。接続できテーブルが作成できる権限があるデータベースを作成しておきます。
オプションの -driver に postgres を指定し、-dsn にサーバーへの接続情報を指定します。
dsnの項目には以下が指定できます。デフォルトの場合は省略可能です。
項目名 説明 dbname データベース名（デフォルト:ログインユーザー名） user ユーザー名（デフォルト:ログインユーザー名） password パスワード（デフォルト:なし） host ホスト名又はIPアドレス（デフォルト:localhost） port ポート番号(デフォルト: 5432) sslmode SSLモード（デフォルト: require） fallback_application_name （提供されない場合の）アプリケーション名（デフォルト:なし） connect_timeout 接続の最大待機時間 sslcert 証明書ファイルの場所 sslkey 秘密鍵ファイルの場所 sslrootcert ルート証明書ファイルの場所 項目=値をスペース区切りで指定します。
DSN指定 例えば、ローカルホストのportが5433でデータベース名がtrdsql_testに接続するには以下のようにします。
trdsql -driver postgres -dsn &amp;#34;host=localhost port=5433 dbname=trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; UNIXドメインソケット UNIXドメインソケットへ接続もできます。
パッケージ等でPostgreSQLをインストールすると以下のような場所にUNIXドメインソケットファイルが作成されています。
/var/run/postgresql/.s.PGSQL.5432上記の場合、hostに/var/run/postgresql/を指定します。「/」から始まるとUnixドメインソケットとみなされます。portは.s.PGSQL.の後にある「5432」を指定します。
trdsql -driver postgres -dsn &amp;#34;host=/var/run/postgresql/ port=5432 dbname=trdsql_test&amp;#34; &amp;#34;SELECT VERSION()&amp;#34; &amp;#34;PostgreSQL 10.10 (Ubuntu 10.10-0ubuntu0.18.04.1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 7.</description>
    </item>
    <item>
      <title>trdsql 処理の概要</title>
      <link>https://noborus.github.io/blog/11_summary/index.html</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/11_summary/index.html</guid>
      <description>ここでtrdsqlの内部処理の概要を簡単に説明します。
trdsqlの内部処理は、以下のようになっています。
オプションやSQLコマンドの解釈 SQLコマンド内のファイル名をデータベースにインポート SQLの実行 指定された出力フォーマットで実行結果を出力 SQLの実行は実際のRDBMSを使用して実行されます（デフォルトではSQLite3のメモリデータベース)。
trdsqlはインポートとエクスポートの形式を整えているだけで、データベースに丸投げしているツールと言えます。
そのため、他の1行づつ処理するようなストリーミングができるツールとは違い、一旦全部のデータをインポートしてから実行されるため、非常に大きなデータではSQLの実行開始までに時間がかかります。
しかしながら、SQLライクではなく本当のSQLが使用できます。
これらの特徴を踏まえて使用すると良いでしょう。</description>
    </item>
    <item>
      <title>trdsql 標準入力</title>
      <link>https://noborus.github.io/blog/10_stdin/index.html</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/10_stdin/index.html</guid>
      <description>標準入力 trdsqlは他のUNIXツールのように標準入力からデータを受け取ることができます。ただSQLの文法上テーブル名を指定する必要があります。標準入力を使用するときは、「-」か「stdin」を使用します。
cat test.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; apple,100 orange,50 potato,30 trdsqlは標準入力から受け取りますが、標準入力をすべて受け取り終わってからSQLの実行が開始されます。 そのため終わらないコマンドからの出力を受け取ることはできません。
CSV、LTSV、JSONを出力するコマンドでは、ファイル名の代わりに標準入力を使えばそのまま利用できます。 例えば、文字コードがUTF-8でないファイルをUTF-8に変更してそのまま使用したり、
nkf -w sjis.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; 大きなファイルを処理する前に先頭の数行のみを処理して試してみたりできます。
head -100 big.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; それ以外にも、例えばUNIX系のコマンドでは、スペースを区切りとして解釈すればテーブルデータとして扱える出力をするコマンドが数多くあります。
例えば psコマンドでは、
ps PID TTY TIME CMD 1157 pts/3 00:00:00 ps 22590 pts/3 00:00:03 zshのようにヘッダーがあり、それぞれの列を出力しています（trdsqlでは連続したスペースの区切り文字は一つとして解釈するように動作します）。
そのため、以下のように実行すると Ascii Table形式で出力できます。
ps|trdsql -ih -id &amp;#34; &amp;#34; -oat &amp;#34;SELECT \`PID\`, \`TTY\`, \`TIME\`, \`CMD\` FROM -&amp;#34; +-------+-------+----------+--------+ | PID | TTY | TIME | CMD | +-------+-------+----------+--------+ | 1363 | pts/3 | 00:00:00 | ps | | 1364 | pts/3 | 00:00:00 | trdsql | | 22590 | pts/3 | 00:00:03 | zsh | +-------+-------+----------+--------+標準入力の解析 また、trdsqlの-a解析オプションは標準入力も使用することが出来ます。</description>
    </item>
    <item>
      <title>trdsql ワイルドカード、圧縮ファイル</title>
      <link>https://noborus.github.io/blog/09_wildcard/index.html</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/09_wildcard/index.html</guid>
      <description>Wildcard ここまでは一つのファイルを対象としてきましたが、ログファイル等はローテートされて複数のファイルになっている場合があります。
同じ列で構成されている対象ファイルであれば、ワイルドカードを使用して、複数のファイルを一つのテーブルとして扱うことができます。
ls test*.csv test1.csv test2.csv test3.csvtrdsql -icsv &amp;#34;SELECT COUNT(*) FROM test*.csv&amp;#34; 15圧縮ファイル また古いログファイルは圧縮されている場合があります。[gzip, bzip2, zstd, lz4, xz]圧縮であれば自動で伸長して実行します。
trdsql -iltsv &amp;#34;SELECT * FROM access.log.2.gz&amp;#34; 圧縮ファイルとワイルドカードを組み合わせて実行することもできます。
ls access.log access.log.1 access.log.2.gztrdsql -iltsv &amp;#34;SELECT * FROM access.log.*&amp;#34; </description>
    </item>
    <item>
      <title>trdsql Log集計</title>
      <link>https://noborus.github.io/blog/08_log/index.html</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/08_log/index.html</guid>
      <description>Log集計 ApacheやnginxなどのLogをLTSVフォーマットで出力する方法も定着してきました。
そのようなLogをtrdsqlで解析する例です。
出力する側は、apacheのLogFormatの設定を以下のようにカスタマイズフォーマットにします。
LogFormat &amp;#34;host:%h\tident:%l\tuser:%u\ttime:%t\treq:%r\tstatus:%&amp;gt;s\tsize:%b\treferer:\%{Referer}i\tua:%{User-Agent}i&amp;#34; combined_ltsvhost,ident,user,time,req,status,size,referer,uaの項目が出力されます。
実際のLogは以下のようになります。
host:176.99.192.42	ident:-	user:-	time:[21/Oct/2019:21:33:53 +0900]	req:GET /category/software HTTP/1.1	status:200	size:138	referer:-	ua:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0) host:192.54.157.102	ident:-	user:-	time:[21/Oct/2019:21:33:53 +0900]	req:GET /item/electronics/4478 HTTP/1.1	status:200	size:60	referer:/category/sports	ua:Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:9.0.1) Gecko/20100101 Firefox/9.0.1 host:88.60.137.115	ident:-	user:-	time:[21/Oct/2019:21:33:53 +0900]	req:POST /search/?c=Games+Electronics HTTP/1.1	status:200	size:98	referer:/item/networking/929	ua:Mozilla/5.0 (iPhone; CPU iPhone OS 5_0_1 like Mac OS X) AppleWebKit/534.</description>
    </item>
    <item>
      <title>trdsql GROUP集計</title>
      <link>https://noborus.github.io/blog/07_group/index.html</link>
      <pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/07_group/index.html</guid>
      <description>GROUP集計 全体の合計を計算することもありますが、グループ毎の合計をまとめて出力したい場合もあります。 そこで使うのがGROUP BYです。
前回の例をもう一度使用します。
name,price apple,100 orange,50 melon,500 apple,90 apple,90 orange,40 orange,40ここでappleやorange毎の合計を出したい場合は、以下のように検索条件で絞れば計算できますが、nameの種類の数だけ実行するとなると大変な作業になります。
trdsql -ih &amp;#34;SELECT name,SUM(CAST(price AS INT)) as sum FROM sample.csv WHERE name=&amp;#39;apple&amp;#39;&amp;#34; apple,280trdsql -ih &amp;#34;SELECT name,SUM(CAST(price AS INT)) as sum FROM sample.csv WHERE name=&amp;#39;orange&amp;#39;&amp;#34; orange,130そこでGROUP BYを使ってnameをグループとして扱うことで、それぞれの集計結果を求めることができます。
trdsql -ih &amp;#34;SELECT name,SUM(CAST(price AS INT)) as sum FROM sample.csv GROUP BY name&amp;#34; apple,280 melon,500 orange,130前回の集計を少し変えてname毎に出すように出力してみます。 出力は-oat(Ascii Table)を使うと見やすく表示できます。
trdsql -ih -oat \ &amp;#34;SELECT name, COUNT(name) as count, MIN(CAST(price AS INT)) AS min, MAX(CAST(price AS INT)) as max, SUM(CAST(price AS INT)) as sum, AVG(CAST(price AS INT)) as avg FROM sample.</description>
    </item>
    <item>
      <title>trdsql 集計計算</title>
      <link>https://noborus.github.io/blog/06_calculation/index.html</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/06_calculation/index.html</guid>
      <description>集計計算 集計には、COUNT()だけでなく集計計算することも当然できます。SQLには数値に対して計算をおこなう集計関数があらかじめ揃っています。
ここでは以下のようなCSVファイルを例に説明します。
name,price apple,100 orange,50 melon,500 apple,90 apple,90 orange,40 orange,40SUM 合計を計算します。price列をすべて足します。
trdsql -ih &amp;#34;SELECT SUM(price) FROM sample.csv&amp;#34; 910前にも書いたようにtrdsqlは列をテキスト型として扱いますので、本来はCASTして数値型にしてから計算する必要があります。ただ、集計の関数を使用する場合は、暗黙のCASTがされて省略できる場合があります（使用するデータベースによります）。
明示的にCASTする場合は以下のようにします。
trdsql -ih &amp;#34;SELECT SUM(CAST(price AS int)) FROM sample.csv&amp;#34; 910AVG 平均を計算します。合計/件数で計算できますが、関数が用意されているので、使用したほうがわかりやすく書けます。この例では、平均の意味はそれほどないかもしれませんが。
trdsql -ih &amp;#34;SELECT AVG(CAST(price AS int)) FROM sample.csv&amp;#34; 130MIN,MAX 最小値や最大値を出力します。
trdsql -ih -oh &amp;#34;SELECT MIN(CAST(price AS INT)),MAX(CAST(price AS INT)) FROM sample.csv&amp;#34; MIN(CAST(price AS INT)),MAX(CAST(price AS INT)) 40,500MINやMAXはテキスト型でも使用できるため、明示的にCASTする必要があります。
（MINやMAXのnameを知りたくなるところですが、SQLだとちょっと複雑になるので後に回します）。
前回書いたように、集計関数は一度に実行できます。
trdsql -ih -oat &amp;#34;SELECT COUNT(name) as count, COUNT(DISTINCT name) as uniq, MIN(CAST(price AS INT)) AS min, MAX(CAST(price AS INT)) as max, SUM(CAST(price AS INT)) as sum, AVG(CAST(price AS INT)) as avg FROM sample.</description>
    </item>
    <item>
      <title>trdsql 集計</title>
      <link>https://noborus.github.io/blog/05_aggregate/index.html</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/05_aggregate/index.html</guid>
      <description>COUNT(*) 最初はCOUNT(*)です。全体の件数を数えることが出来ます。
集計関数を使用すると元の行と列のデータは出力されず、そこから集計された結果が出力されます。
以下の例は結果が１行なので、CSVの様に見えませんが、1行1列(ヘッダー付き)のCSVとして出力されています。
単純に件数を数えるだけですが、ヘッダーと解釈して数に含まないか等の注意が必要です。
trdsql -icsv -ih -oh &amp;#34;SELECT COUNT(*) FROM header.csv&amp;#34; count(*) 3検索条件の指定が出来ます。検索条件にあてはまる件数を知りたい時に使用します。
trdsql -icsv -ih -oh &amp;#34;SELECT COUNT(*) FROM header.csv WHERE id&amp;lt;&amp;#39;1&amp;#39;&amp;#34; count(*) 2COUNT(列名) COUNT(列名) もよく使用します。RDBMSではNULLが除外されるので、COUNT(*)とは区別して使われます。
また、COUNTとDISTINCTを組み合わせると重複を省いた件数を出力できます。
以下のようなCSVファイルで実行してみます。
id,name 1,aaa 2,bbb 3,ccc 4,aaatrdsql -icsv -ih -oh &amp;#34;SELECT COUNT(name) FROM abc.csv&amp;#34; count(name) 4trdsql -ih -oh &amp;#34;SELECT COUNT(DISTINCT name) FROM abc.csv&amp;#34; COUNT(DISTINCT name) 3集計関数は一度に実行することもできます。
trdsql -ih -oh &amp;#34;SELECT COUNT(name), COUNT(DISTINCT name) FROM abc.csv&amp;#34; COUNT(name),COUNT(DISTINCT name) 4,3</description>
    </item>
    <item>
      <title>trdsql 簡単なSQL その２</title>
      <link>https://noborus.github.io/blog/04_sql2/index.html</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/04_sql2/index.html</guid>
      <description>検索条件 前回、列の並べ替え、抽出、行の並べ替えをしたので、今回は行の抽出です。 行を抽出するには、WHEREを付けて、検索条件を書きます。
前回と同じ例のファイルを使います。
trdsql -ih &amp;#34;SELECT id, \`name\` FROM header.csv WHERE id=1&amp;#34; 1,OrangeSQLのメインな機能ですね。検索条件を書くだけで、該当する行を出力できます。
AND, OR AND や OR や ()括弧を使用することにより複雑な条件が書けます。
trdsql -ih &amp;#34;SELECT id, \`name\` FROM header.csv WHERE id=&amp;#39;1&amp;#39; OR id=&amp;#39;2&amp;#39;&amp;#34; 1,Orange 2,Melontrdsql -ih &amp;#34;SELECT id, \`name\` FROM header.csv &amp;#34; &amp;#34;WHERE (id=&amp;#39;1&amp;#39; OR id=&amp;#39;2&amp;#39;) AND \`name\`=&amp;#39;Orange&amp;#39;&amp;#34; 1,Orange前回にも書いたようにtrdsqlでは、CSVやLTSV、JSONの値をtext型として扱っています。そのため、「=」の条件で書いているときには、暗黙のCASTが効いて型をそれほど意識しなくても良いですが、範囲を指定するときには結果が変わってしまうので、CASTする必要があります。
trdsql -ih &amp;#34;SELECT id,\`name\` FROM header.csv &amp;#34; &amp;#34;WHERE CAST(id as int)&amp;gt;1&amp;#34; 2,Melon 3,AppleSELECTを使用するときは、列の指定のところでCASTを使用して、そのCASTした列を指定して検索条件やORDER BYを書くことが出来ます。
その際には元の列名はCAST前の列を指しているので、AS 別名を使用してCAST後の列名を使用します（CAST後の列名に元の名前を付けることは出来ます）。
trdsql -ih &amp;#34;SELECT CAST(id AS int) AS id,\`name\` FROM header.</description>
    </item>
    <item>
      <title>trdsql 簡単なSQL</title>
      <link>https://noborus.github.io/blog/03_sql/index.html</link>
      <pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/03_sql/index.html</guid>
      <description>trdsqlと簡単なSQLを使用することで、他のUNIXツールを組み合わせて出来るようなことが一発で出来るようになります。
ファイル解析 SELECT * FROMから進んで簡単なSQLを実行する場合、あらかじめ列名を把握しておく必要があります。 trdsql に -aオプションにファイル名を付けて実行するとファイルを解析して情報を出力してくれます。
（CSVファイルの拡張子が.csvの様な場合は、-icsvを省略することが出来ます。-ih ヘッダを解釈、 -is スキップ数の指定等のオプションを必要に応じて付けないと意図しない解析結果になることがあります）。
trdsql -ih -a header.csv The table name is header.csv. The file type is CSV. Data types: +-------------+------+ | column name | type | +-------------+------+ | id | text | | \`name\` | text | +-------------+------+ Data samples: +----+----------+ | id | \`name\` | +----+----------+ | 1 | Orange | +----+----------+ Examples: trdsql -ih &amp;#34;SELECT id, \`name\` FROM header.csv&amp;#34; trdsql -ih &amp;#34;SELECT id, \`name\` FROM header.</description>
    </item>
    <item>
      <title>trdsql ファイルフォーマット変換</title>
      <link>https://noborus.github.io/blog/02_convert/index.html</link>
      <pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/02_convert/index.html</guid>
      <description>trdsqlはCSV等のファイルをSQLで処理するツールとして説明していますが、単純にファイル形式を変換するツールとしても使用できます。
その場合、SQLは以下の定型句さえ覚えておけば、十分です。 ファイル内のすべての行と列を出力します。
SELECT * FROM ファイル名後は、オプションとして入力形式(-i&amp;hellip;)と出力形式(-o&amp;hellip;)を指定してあげればファイル形式の変換が可能です。 CSV、LTSV、JSON等の相互変換ができます。
CSV(-icsv)からLTSV(-oltsv)への変換は以下のようにします。
trdsql -icsv -oltsv &amp;#34;SELECT * FROM ファイル名&amp;#34; CSV header CSVファイルはヘッダーに列名がついている場合 -ih でヘッダーを解釈して列名として使用できます。
header.csv
id,name 1,Orange 2,Melon 3,Appletrdsql -icsv -ih -oltsv &amp;#34;SELECT * FROM header.csv&amp;#34; &amp;gt; test.ltsv test.ltsv
id:1	name:Orange id:2	name:Melon id:3	name:Appleヘッダーが無い場合は、列名はc1,c2,c3&amp;hellip;の連番になります。
LTSV入力 上記で出力されたLTSVを入力に使用すれば、CSVに戻ります。
trdsql -iltsv -ocsv -oh &amp;#34;SELECT * FROM test.ltsv&amp;#34; id,name 1,Orange 2,Melon 3,Apple区切り文字の変更（TSV） また、CSVはComma-Separated Valuesではなく、Character-separated valuesとも呼ばれたりすることがあるように、区切り文字として「,」以外を使用できます。
-id オプションの後に文字を指定することにより変更ができます。 タブ区切りの場合（TSVとも呼ばれます）は、&amp;quot;\t&amp;quot;を使用します。
以下はTSVからCSVの変更になります。
trdsql -icsv -id &amp;#34;\t&amp;#34; -ih &amp;#34;SELECT * FROM test.</description>
    </item>
    <item>
      <title>trdsql インストール</title>
      <link>https://noborus.github.io/blog/01_install/index.html</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://noborus.github.io/blog/01_install/index.html</guid>
      <description>概要 trdsqlはテーブル（表）形式のテキストに対してSQLを実行するCLIツールです。 テーブル形式とは、行と列で構成される以下のようなデータです。
1列 2列 1行 a1 a2 2行 b1 b2 結果をざまざまなフォーマットに出力できるので、テーブル形式データのフォーマット変換にも使用できます。
インストール Linux/Windows/macOSの場合は、GitHubのリリースページからバイナリをダウンロードできます。 Goで作られていて、他に依存ライブラリがない１バイナリなので、展開してすぐに実行できます。
Docker Dockerが使用できる環境であればDockerでも実行できます。Docker Hubからdocker pullも使用できるので、以下のようにしてpullしてください。
docker pull noborus/trdsql 入力ファイルの場所をマウントして使用して下さい。結果は標準出力に出るので、そのままリダイレクトで受け取れます。
カレントディレクトリにあるtest.csvに対して実行するときは以下のようになります。
docker run --rm -it -v $(pwd):$(pwd) --workdir $(pwd) noborus/trdsql &amp;#34;SELECT * FROM test.csv&amp;#34; &amp;gt; test_new.csv Homebrew macOSが無いので、実際には試していませんが、以下でインストールできるのではないかと思ってます。
brew tap noborus/trdsql brew install trdsql go get go のビルド環境があれば自分でビルドすることもできます。
go get -u -d github.com/noborus/trdsql cd trdsql make 自分の環境用にビルドするのは難しくないと思いますが、クロスコンパイルする場合は、依存しているgo-sqlite3が cgo を使用しているので、注意が必要になります。
実行 実行はターミナル上から実行します。
trdsql [OPTIONS] [SQLコマンド] SQLコマンドでは、データベースのテーブルを指定しますが、テーブルの代わりにファイルをそのまま指定できます。</description>
    </item>
  </channel>
</rss>