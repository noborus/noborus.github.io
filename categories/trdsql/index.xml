<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>trdsql on Noboru Saito's page</title><link>https://noborus.github.io/categories/trdsql/</link><description>Recent content in trdsql on Noboru Saito's page</description><generator>Hugo -- gohugo.io</generator><language>ja</language><lastBuildDate>Wed, 27 Jan 2021 11:00:00 +0900</lastBuildDate><atom:link href="https://noborus.github.io/categories/trdsql/index.xml" rel="self" type="application/rss+xml"/><item><title>trdsql v0.8.0</title><link>https://noborus.github.io/blog/trdsql_080/</link><pubDate>Wed, 27 Jan 2021 11:00:00 +0900</pubDate><guid>https://noborus.github.io/blog/trdsql_080/</guid><description>trdsql v0.8.0をリリースしました。 リリースのページから各バイナリがダウンロードできます。
Contextを追加しました。 コマンドでは、killシグナルによって終了するので、変更はないですが、内部的にContextによるキャンセルを出来るようにしました。パッケージ使用する場合にプロセスの終了をせずにキャンセルする処理が書きやすく成ります。
JSON出力でJSONオブジェクトだった場合にjson.RawMessageで返すようになりました。 JSONは入れ子で配列、オブジェクトを入れられますが、これまでのtrdsqlではフラットな文字列として扱うため、JSONの入れ子構造を作ることが出来ませんでした。 json.RawMessageとして返すことで、SQLのJSON関数でJSON化した列をJSONとして扱えるようになりました。
JSON出力時にオブジェクトの順序が保持されるようになりました。 JSONのオブジェクト{&amp;quot;a&amp;quot;: &amp;quot;x&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;y&amp;quot;}が並んだときには順序は無いことになっています。そのため、{&amp;quot;a&amp;quot;: &amp;quot;x&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;y&amp;quot;}と{&amp;quot;b&amp;quot;, &amp;quot;y&amp;quot;,&amp;quot;a&amp;quot;: &amp;quot;x&amp;quot;,}は同じものです。 そのため、trdsqlでJSONやJSONL出力するときに &amp;quot;SELECT a,b FROM test.json&amp;quot;のようなSQLでもJSONに変換された時点でaとbの順序は不定でした。 しかしながら、不便な場合があるのでこの順序を守るようにしました。
~(tilde) を $HOMEに展開するようにしました。 ~/test.csv　などの ~(tilde) の指定は通常shellがおこなうため、&amp;quot;SELECT * FROM ~/test.csv&amp;quot;のようにした場合は~(tilde)が展開されませんでした。trdsqlではファイル名だった場合に自前で置き換えするようにしたので展開されることになります。</description></item><item><title>trdsql 0.7.5</title><link>https://noborus.github.io/blog/trdsql_075/</link><pubDate>Sat, 07 Mar 2020 10:00:00 +0900</pubDate><guid>https://noborus.github.io/blog/trdsql_075/</guid><description>trdsql 0.7.5をリリースしました。 リリースのページから各バイナリがダウンロードできます。
圧縮ファイルへの対応を強化 trdsql 圧縮ファイルに書いたように圧縮ファイルのサポートを増やしました。
また、圧縮しての出力をできるようにしました。
ファイルへの出力 trdsql outputに書いたように出力ファイルを指定して出力できるようになりました。
出力ファイル名から出力フォーマットと圧縮フォーマットを推測するのがデフォルトの動作になっています。
オプションが増加したため、-helpメッセージの出力を見直しました。 以下のようになります。
trdsql - Execute SQL queries on CSV, LTSV, JSON and TBLN. Usage: trdsql [OPTIONS] [SQL(SELECT...)] Options: -A string analyze the file but only suggest SQL. -a string analyze the file and suggest SQL. -config string configuration file location. -db string specify db name of the setting. -dblist display db information. -debug debug print. -driver string database driver. [ mysql | postgres | sqlite3 ] -dsn string database driver specific data source name.</description></item><item><title>trdsql output</title><link>https://noborus.github.io/blog/34_output/</link><pubDate>Mon, 02 Mar 2020 18:45:00 +0900</pubDate><guid>https://noborus.github.io/blog/34_output/</guid><description>今までは標準出力にのみ出力していましたが、-out ファイル名により、出力ファイルを指定できるようにしました。
-out ファイル名では出力ファイル名からファイル形式、圧縮形式を推測するモードをデフォルトで有効にしてあります。
出力ファイル名の拡張子が[.csv,.ltsv,json,jsonl,tbln,md,at,vf,raw]等の出力ファイル形式の拡張子だった場合は自動でその出力形式で出力します。
以下はLTSV形式で出力します。
trdsql -out test.ltsv &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 出力フォーマットを指定した場合は、出力フォーマットが優先されます。以下はjsonl形式で出力されます。
trdsql -ojsonl -out test.txt &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 圧縮形式も推測するので、test.csv.gzのようにした場合はCSV形式のgzip圧縮で出力されます。基本的ファイルの拡張子はファイル形式.圧縮形式の順です。
以下はLTSV形式でzstd圧縮で出力されます。
trdsql -out test.ltsv.zst &amp;#34;SELECT * FROM testdata/test.csv&amp;#34; 圧縮フォーマットも-oz 圧縮形式で指定した場合はそちらが優先されます。
例えば、.zstの拡張子を付けたいが圧縮してほしくない（理由はわかりませんが&amp;hellip;)の場合は、-out-without-guessを付けて実行して下さい。</description></item><item><title>trdsql 圧縮ファイル</title><link>https://noborus.github.io/blog/33_compression/</link><pubDate>Mon, 02 Mar 2020 17:52:00 +0900</pubDate><guid>https://noborus.github.io/blog/33_compression/</guid><description>圧縮ファイルに実行 0.7.4までは gzip(.gz)の圧縮形式のみの対応でしたが、最新のmaster(0.7.5以降の予定)では、gzip(gz)、bzip2(bz2)、zstd(zst)、lz4、xzの圧縮形式に対応しました。
従来は.gzの拡張子をみて判断していましたが、今回から圧縮形式のファイルの先頭のマジックナンバー（signatureの値）を見て判断するようになりました。そのため、拡張子が何であっても上記の圧縮形式はそのまま読み取ることが出来ます。
圧縮率にもよりますが、デフォルトレベルのzstdでの圧縮されたファイルをtrdsqlで処理すると、手元のマシンでの処理時間はほぼ変わらないか、少しzstdで圧縮されているファイルのほうが早いくらいです。
例えば以下のような145MBのファイルに対してzstdで圧縮すると44MBになりました。
145M worldcitiespop.csv 44M worldcitiespop.csv.zst timeを付けての結果は以下のようになりました。
/usr/bin/time -p trdsql -ih &amp;quot;SELECT count(*) FROM worldcitiespop.csv&amp;quot; real 11.47 user 11.76 sys 0.70 zstd圧縮
/usr/bin/time -p trdsql -ih &amp;quot;SELECT count(*) FROM worldcitiespop.csv.zst&amp;quot; real 9.76 user 11.00 sys 0.37 LTSVファイルでは、同じ内容のCSVファイルよりもファイルサイズが大きくなりますが、圧縮効率は良いので圧縮したときのファイルサイズの差は小さくなります。
330M worldcitiespop.ltsv 54M worldcitiespop.ltsv.zst 145MBをLTSVにすると330MBのファイルになっていたのが、圧縮するとCSV:44MB、LTSV:54MBになります。
処理時間は以下のようになりました。
/usr/bin/time -p trdsql &amp;quot;SELECT count(*) FROM worldcitiespop.ltsv real 16.72 user 17.41 sys 1.05 /usr/bin/time -p trdsql &amp;quot;SELECT count(*) FROM worldcitiespop.</description></item><item><title>trdsql 0.7.4</title><link>https://noborus.github.io/blog/trdsql_074/</link><pubDate>Wed, 05 Feb 2020 10:00:00 +0900</pubDate><guid>https://noborus.github.io/blog/trdsql_074/</guid><description>trdsql 0.7.4をリリースしました。 リリースのページから各バイナリがダウンロードできます。
全ての項目を二重引用符（”）で囲うオプション(-oaq)を追加 今回は、CSV出力に全ての項目を二重引用符（”）で囲うオプション(-oaq)を追加しました。
goのencoding/csvはRFC 4180に沿って実装されていますが、必要な項目を二重引用符（”）で囲うようになっていますが、全ての項目を囲う方法は用意されていません。要望はありましたが、却下されています。
trdsqlにも要望が以前より来ていましたが、encoding/csvが対応していないので、対応出来ないとして、カスタマイズする方法を提示していました。 今回別の方からも要望が来たので、実装しました。
encoding/csvでは対応出来ないので、別の方法で実装する必要がありますが、定番と言えるモジュールは無く実装自体は難しくないので、自前で実装することにしました。と言ってもencoding/csvのコードから少し変更しているだけです。
その際に、関連する箇所を見直して、全体の出力が速くなるように改善しました。多くの出力をする場合でないと違いは出ませんが、手元では317万行(145MB)あるファイルを &amp;quot;SELECT * FROM 〜&amp;quot;で出力してみたら、全体で10%ほど高速化していました。
またその他に、二重引用符（”）以外の引用符が使用できる(-oq)と改行文字をCRLFに変更する(-ocrlf)を追加しました。 CRLFはRFC 4180にあり、encoding/csvでも対応していたのですが、入れそびれていたので今回入れました。 引用符は変更してしまうとtrdsqlで読めないCSVになってしまうので注意が必要です。普通は使わないと思うのでかなり特殊用途だと思います。
GitHub Actions でのバイナリ作成に変更 これまで travis-ciでリリース時にビルドしてアップロードしていましたが、GitHub Actionsに変更しました。 途中まではtravis-ciと同様に各環境でビルドしてアップロードしていましたが、crazy-max/xgo(https://github.com/karalabe/xgoのfork版ですが、こちらでないとまだ問題がありました)で、クロスビルドが出来たので、こちらでビルドしてアップロードしています。
crazy-max/ghaction-xgoを使用した場合は、ビルドからアップロードまで簡単に出来るようになっていますが、zipでアーカイブしてアップロードしたかったため、Makefileでビルドまでおこないアップロードをおこなっています。
対応環境数が大幅に増えたため、ワイルドカードでファイルが指定できるAButler/upload-release-assetsを使用してアップロードしています。
armやmipsは環境が無いので自分では動かして試して見ることが出来ません。問題がありましたらお知らせ下さい。</description></item><item><title>trdsql CASE式</title><link>https://noborus.github.io/blog/32_case/</link><pubDate>Tue, 07 Jan 2020 10:18:00 +0900</pubDate><guid>https://noborus.github.io/blog/32_case/</guid><description>CASE式は、プログラム言語のif文やswitch文のような条件に分岐した処理をおこないます。単純な1を&amp;rsquo;A&amp;rsquo;に変換するような場合は、一時的なテーブルとJOINさせたり文字列の書き換えで可能ですが、 範囲を指定してグループ化したい場合はCASE式を使うと便利です。
CASE式には以下の2つのパターンどちらも使用できます。
CASEは CASE 式（列) WHEN 値 THEN 結果とCASEの後に式を書いて、WHENが値だけのパターンと CASE WHEN 式 THEN 結果 とCASEの式を省略してWHENに式を書くパターン 必要であれば、ELSE 結果で当てはまらない場合を書き、ENDで式の終わりを示します。
case.csv のようなCSVを使用して、scoreが80以上の場合は&amp;rsquo;A'、30以上の場合は、&amp;lsquo;B&amp;rsquo;、30より下の場合は、&amp;lsquo;F&amp;rsquo;と表示させてみます。
id,name,score 1,bob,89 2,alice,75 3,dave,23 trdsql -ih -oat \ &amp;quot;SELECT id,name,score, &amp;quot; \ &amp;quot; CASE WHEN CAST(score AS int) &amp;gt;= 80 THEN 'A' &amp;quot; \ &amp;quot; WHEN CAST(score AS int) &amp;gt;= 30 THEN 'B' &amp;quot; \ &amp;quot; ELSE 'F' &amp;quot; \ &amp;quot; END AS evaluation &amp;quot; \ &amp;quot; FROM case.</description></item><item><title>trdsql 合計を行に追加する</title><link>https://noborus.github.io/blog/31_rollup/</link><pubDate>Sat, 04 Jan 2020 13:38:00 +0900</pubDate><guid>https://noborus.github.io/blog/31_rollup/</guid><description>Window関数により元のファイルの内容に列を追加して、集計結果を出せました。 ただ、人が確認する場合は、集計の結果行が最後に出るほうが確認しやすくなります。
通常のSQLでも元の内容と集計結果を別々に出してUNIONを使うことで、一つの結果として出すことが出来ますが、一回で済むならばそれに越したことはありません。
SQLite3ではサポートされていませんが、PostgreSQLとMySQLならばサポートされている文があります。
ROLLUP Window関数でも使用した以下のCSVファイルを使用します。
id,class,name,score 1,A,bob,174 2,A,alice,248 3,A,carol,163 4,B,dave,289 5,B,eve,157 6,B,flank,272 通常のGROUP BYで全体の合計又は、class毎の合計が出せました。 ただし、class毎の合計と全体の合計を出すにはWindow関数を使用して別の列に出していました。
GROUP BYに ROLLUPを指定することで、両方を出力できます。
PostgreSQL PostgreSQLでは、GROUP BY 列名の代わりにGROUP BY ROLLUP(列名)を使用することで、通常のGROUP BYに加えて、全体の集計結果を出力します。
trdsql -driver &amp;quot;postgres&amp;quot; -dsn &amp;quot;dbname=trdsql_test&amp;quot; -oat -ih \ &amp;quot;SELECT class, SUM(score::int) AS score FROM score.csv GROUP BY ROLLUP(class) ORDER BY class&amp;quot; +-------+------+ | class | sum | +-------+------+ | A | 585 | | B | 718 | | | 1303 | +-------+------+ MySQL MySQLでは、GROUP BY 列名の後に WITH ROLLUPを付けると、通常のGROUP BYに加えて、全体の集計結果を出力します。</description></item><item><title>trdsql convert log</title><link>https://noborus.github.io/blog/30_convert_log/</link><pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/30_convert_log/</guid><description>既存のログをLTSVに変換する 既存のログをLTSVに変換にしてみます。
mingrammer/flog を使用するとフェイクのログが簡単に出力できるので、 これで出力されるログをLTSV形式に変換する方法を紹介します。
Apache common log 以下のコマンドにより apache_common形式のログをaccess.common.logとして保存します。
flog -f apache_common -t log -o access.common.log 内容は、以下のようになります。
92.129.44.198 - metz3917 [30/Dec/2019:17:02:27 +0900] &amp;quot;DELETE /infomediaries/e-markets HTTP/2.0&amp;quot; 500 24843 246.54.243.199 - - [30/Dec/2019:17:02:27 +0900] &amp;quot;POST /24%2f7 HTTP/1.1&amp;quot; 302 8879 9.172.27.159 - - [30/Dec/2019:17:02:27 +0900] &amp;quot;DELETE /convergence/best-of-breed HTTP/1.1&amp;quot; 203 3252 49.129.77.219 - kozey2248 [30/Dec/2019:17:02:27 +0900] &amp;quot;PUT /embrace HTTP/1.1&amp;quot; 301 2812 216.42.120.216 - - [30/Dec/2019:17:02:27 +0900] &amp;quot;HEAD /infomediaries HTTP/2.0&amp;quot; 204 12516 これを trdsqlの -id &amp;quot; &amp;quot; によりスペース区切りで解析すると c4とc5でタイムが分かれてしまいますが、それ以外は問題無さそうです。</description></item><item><title>trdsql generate_series</title><link>https://noborus.github.io/blog/29_generate_series/</link><pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/29_generate_series/</guid><description>generate_series PostgreSQLにはgenerate_series()という便利な関数があります。 これはUnixのseqコマンドと同じような働きをする関数です。またgenerate_series()は、タイムスタンプ型にも使用できる拡張があります。
使い方は簡単で「開始値」、「終了値」、「刻み値（省略可能）」を指定して実行します。
trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; &amp;quot;SELECT * FROM generate_series(1,10)&amp;quot; 1 2 3 4 5 6 7 8 9 10 generate_series()はテーブルを返す関数で、テーブルの代わりに使用できます。 （SELECT generate_series(1,10)と書くこともできます）。
もちろん、trdsqlでは、外部からの入力を簡単に取り入れられるので、seqコマンドで代用することもできます。
seq 1 10|trdsql &amp;quot;SELECT * FROM -&amp;quot; 1 2 3 4 5 6 7 8 9 10 seqコマンドは、引数の順序が「開始値」、「刻み値（省略可能）」「終了値」になります。 2つの値を渡すときには同じですが、刻み値を指定する場合は、順序が異なるので注意が必要です。
タイムスタンプ generate_series()では、タイムスタンプを扱えるので、2020年のカレンダーを日本語で出すと少々トリッキーですが、以下のようになります。
trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; \ &amp;quot;SET LC_TIME='ja_JP.UTF-8'; &amp;quot; \ &amp;quot;SELECT to_char(day,'YYYY年TMMonthDD日 (TMDay)') &amp;quot; \ &amp;quot; FROM generate_series('2020-01-1'::timestamp,'2020-12-31','1 day') as day&amp;quot; 2020年1月01日 (水曜日) 2020年1月02日 (木曜日) 2020年1月03日 (金曜日) 2020年1月04日 (土曜日) .</description></item><item><title>trdsql CROSS JOIN</title><link>https://noborus.github.io/blog/28_cross_join/</link><pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/28_cross_join/</guid><description>CROSS JOINは、総当りを簡単に作り出せる方法です。
a.csv
aa ab ac b.csv
ba bb bc の２つのCSVをCROSS JOINすると 3×3で全ての組み合わせを出力できます。
trdsql &amp;quot;SELECT * FROM a.csv CROSS JOIN b.csv&amp;quot; aa,ba aa,bb aa,bc ab,ba ab,bb ab,bc ac,ba ac,bb ac,bc また一つのファイルに対して自己結合をすることもできます。 例えば、ホーム＆アウェーの総当り表を作成してみます。
cleague.csv
team 巨人 DeNA 阪神 広島 中日 ヤクルト 単純にCROSS JOINするには以下のようになります（JOIN条件は無いので書けません）。
trdsql -ih \ &amp;quot;SELECT h.team,a.team &amp;quot;\ &amp;quot; FROM cleague.csv AS h &amp;quot;\ &amp;quot; CROSS JOIN cleague.csv AS a&amp;quot; 自分のチームとは対戦出来ないので、同じチームのときをWHERE h.team != a.teamにより除外します。
trdsql -ih -omd \ &amp;quot;SELECT h.</description></item><item><title>trdsql config</title><link>https://noborus.github.io/blog/27_config/</link><pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/27_config/</guid><description>trdsqlは設定ファイルが無くても動作しますが、設定ファイルによりデフォルトのデータベースのエンジンを変更できます。
configファイルの場所 -configオプションで、直接ファイルの場所を指定できます。
-configオプションを使用しないデフォルトの場所は以下です。
Linux等のWindows以外 ${HOME}/.config/trdsql/config.json Windows %APPDATA%trdsql\config.json です。多くは以下の位置になります。
C:\Users\{&amp;quot;User&amp;quot;}\AppData\Roaming\trdsql\config.json configファイルの内容 以下がサンプルです。
{ &amp;quot;db&amp;quot;: &amp;quot;pdb&amp;quot;, &amp;quot;database&amp;quot;: { &amp;quot;sdb&amp;quot;: { &amp;quot;driver&amp;quot;: &amp;quot;sqlite3&amp;quot;, &amp;quot;dsn&amp;quot;: &amp;quot;&amp;quot; }, &amp;quot;pdb&amp;quot;: { &amp;quot;driver&amp;quot;: &amp;quot;postgres&amp;quot;, &amp;quot;dsn&amp;quot;: &amp;quot;user=test dbname=test&amp;quot; }, &amp;quot;mdb&amp;quot;: { &amp;quot;driver&amp;quot;: &amp;quot;mysql&amp;quot;, &amp;quot;dsn&amp;quot;: &amp;quot;user:password@/dbname&amp;quot; } } } &amp;ldquo;database&amp;rdquo; に &amp;ldquo;名前&amp;rdquo;: {&amp;ldquo;driver&amp;rdquo;: ドライバ名(sqlite3 or postgres or mysql), &amp;ldquo;dsn&amp;rdquo;: &amp;ldquo;ドライバに沿ったDSN&amp;rdquo;} でデータベースを定義しておき、最初の &amp;ldquo;db&amp;quot;に定義した&amp;quot;名前&amp;quot;を書くとデフォルトのエンジンが変更されます。
上記では、&amp;ldquo;pdb&amp;quot;がデフォルトになり、&amp;ldquo;postgres&amp;quot;エンジンが使用されます。
デフォルトの変更だけでなく、ここで定義しておくと trdsqlのオプション -db mdb を指定することにより、簡単にmysqlドライバのエンジンに切り替えられます。
確認方法 configファイルが無くても動作するため、実際にエンジンが変更されているかわかりにくいことがあります。
trdsqlを-debugオプション付きで起動すると詳細が表示されますので、そこで確認して下さい。
設定ファイルが見つからなかった場合 1 2 3 4 5 6 trdsql -debug -db pdb &amp;#34;SELECT * FROM testdata/test.</description></item><item><title>trdsql SQLファイル指定</title><link>https://noborus.github.io/blog/26_file_sql/</link><pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/26_file_sql/</guid><description>SQLファイル名指定オプション「-q」 trdsql &amp;ldquo;SQLコマンド&amp;quot;の形式だと、長いSQLを書くのが難しいですし、シェルに対してエスケープしなければならない文字があって見た目もわかりにくい場合があります。
trdsqlではファイルにSQLを書いておき、そのファイルのSQLを実行させるオプションがあります。
以下のように記述したSQLをtest.sqlで保存しておきます。
test.sql
SELECT id, `name` FROM testsql.csv （コマンドの引数で渡していたときは「\`」のように「`」をエスケープする必要がありましたが、ファイルのSQLを実行する場合は必要ありません）。
testsql.csv は対象となるCSVファイルです。
id,name 1,tarou 2,jirou &amp;ldquo;SQLコマンド&amp;rdquo; の代わりに 「-q ファイル名.sql」で実行します。それ以外のオプションは代わりません。
trdsql -ih -oat -q test.sql +----+-------+ | id | name | +----+-------+ | 1 | tarou | | 2 | jirou | +----+-------+</description></item><item><title>trdsql ライブラリ使用</title><link>https://noborus.github.io/blog/25_library/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/25_library/</guid><description>trdsqlは初期の頃は、main packageで構成されていましたが、現在はtrdsql packageをmainから呼び出す構成になっていて、trdsql packageをライブラリとして使用できます。
trdsqlのパッケージは、以下の構成になっていて、それぞれ呼び出し可能です。
簡単なサンプルを示します。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import ( &amp;#34;log&amp;#34; &amp;#34;github.com/noborus/trdsql&amp;#34; ) func main() { trd := trdsql.NewTRDSQL( trdsql.NewImporter(trdsql.InDelimiter(&amp;#34;:&amp;#34;)), trdsql.NewExporter(trdsql.NewWriter()), ) err := trd.Exec(&amp;#34;SELECT c1 FROM /etc/passwd&amp;#34;) if err != nil { log.Fatal(err) } } 上記のプログラムは/etc/passwdに対してSQL文を実行しています。 Importer(データベースにインポートするインターフェイス）とExporter(データベースから結果を出力するインターフェイス）を与えてTRDSQLをNewし、Execで実行するのが、おおまかな流れです。
func NewTRDSQL(im Importer, ex Exporter) *TRDSQL このImporter,Exporterはインターフェイスに沿っていれば、置き換えられます（例えば、SQL内のファイルをインポートするのではなく、独自にインポートするにはImporterのインターフェイスに沿った関数を作成します）。
Importer デフォルトのImporterは、trdsql.NewImporter()を呼び出せば作成できます。 デフォルトのImporterはtrdsql.</description></item><item><title>trdsql グラフ</title><link>https://noborus.github.io/blog/24_graph/</link><pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/24_graph/</guid><description>trdsqlは、グラフ作成機能は持っていないためグラフを作成したいときには別のツールを使用して作成することになります。
ExcelやLibreOfficeで描画するのが定番でしょうが、ここではmarianogappa/chartでグラフを描画する方法を紹介します。
marianogappa/chartは、Goで作られていて、や多くのプラットフォームで動作して、標準入力から受け取ったデータをブラウザに描画します。
複雑なグラフには向いていませんが、簡単なグラフを少ないオプションを指定するだけで描画できます。
chartに与えるデータは表示したいグラフによりますが、1列又は2列のデータです。
例えばchartのデフォルトのpieでは、以下のような文字列が並んでいるようなデータを集計して円グラフにしてくれます。
aaa bbb ccc aaa aaa aaa cat aaa.csv|chart （ブラウザが開いて表示されます）
これを使用して例えば、ログ集計で使用したログのリクエストをグラフにすると以下のようになります。
trdsql &amp;quot;SELECT req FROM log.ltsv&amp;quot;|chart また、他のグラフでは、1列目がx項目名で、2列目が値として与えます。デフォルトはタブ区切りのデータを受け取るので、タブ区切りで出力します。
ログ集計のリクエストが多い順をTOP 20に変えて出力すると以下のようになります。
trdsql -od &amp;quot;\t&amp;quot; \ &amp;quot;SELECT req, count(req) as count &amp;quot; \ &amp;quot;FROM log.ltsv &amp;quot; \ &amp;quot;GROUP BY req &amp;quot; \ &amp;quot;ORDER BY count DESC LIMIT 20&amp;quot; |chart bar marianogappa/chartは、Chart.jsを使用してグラフを描画しています。Chart.js自体が簡単なJavaScriptを用意すれば描画してくれるので、もう少し複雑なグラフを描きたい場合は直接利用するのが良いでしょう。</description></item><item><title>trdsql 差分、比較</title><link>https://noborus.github.io/blog/23_except/</link><pubDate>Mon, 23 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/23_except/</guid><description>CSV同士やCSVとテーブルなどで、値の比較をしたい場合があります。
同じ形式で一部が違うCSVファイルであれば、diffを取る方法もありますが、trdsqlのSQLを使用して比較すると形式が違う場合の比較にも使用できます。
差分の出力 SQLで比較して、差分を出すには、EXCEPTを使用します。EXCEPTは Aのテーブルから Bのテーブルを引いた残りのAの内容を出力します。
Bの方に多くの行があっても関係なく、AにあってBにない行を出力します。
以下のCSVファイルで比較してみます。new.csvで、3の更新と4の追加があるCSVファイルです。
old.csv
1,AAA 2,BBB 3,CCC new.csv
1,AAA 2,BBB 3,CCB 4,DDD 単純に全列を比較すると1と2の行が同じであるため、消されて残った3と4が出力されます。 この場合old.csv側にnew.csvにない行があっても出力されません。diffの比較とは違いますね。
trdsql &amp;quot;SELECT * FROM new.csv EXCEPT SELECT * FROM old.csv &amp;quot; 3,CCB 4,DDD テーブルとファイルの差分出力 既存のデータベースに接続すれば、テーブルとの比較もできます。
例えば、trdsql DBインポートでインポートしたテーブルと更新されたCSVとの比較をしたいときには、以下のようにすると良いでしょう。
CSVファイル側をキャストして型を合わせています。
trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; -ih -oh \ &amp;quot;SELECT id::int,name FROM fruits.csv &amp;quot; \ &amp;quot;EXCEPT &amp;quot; \ &amp;quot;SELECT id,name FROM fruits &amp;quot; id,name 4,Grape データベース側のテーブルが更新されて新しい場合は、逆にテーブル EXCEPT CSVファイルとすれば、良いでしょう。
共通の行の出力 また、EXCEPTとは逆に共通の行を出力させたいときには、INTERSECT を使用します。</description></item><item><title>trdsql JSON出力</title><link>https://noborus.github.io/blog/22_json_output/</link><pubDate>Sun, 22 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/22_json_output/</guid><description>CSVやLTSVなどのフラットな形式のデータは、JSONにしたいときには（-ojsonによる）JSON出力をすれば良いですが、JSONは本来より深い階層も表現できるフォーマットです。
そのようなJSONは、データベースのJSON関数を使用することにより作成できます。
以下のCSVからJSON関数でJSON出力をしてみます。
id,name 1,Orange 2,Melon 3,Apple JSON関数で出力する場合は、「”」等がエスケープされない-orawを使用して出力すると、有効なJSONとして出力できます。
SQLite3、MySQL SQLite3、MySQLでは、json_array()やjson_object()を使用することによりJSONを生成できます。 ここでは「名前:値」の形式で出力するためjson_objectを使用します。2つペアの引数で、指定していきます。
trdsql -ih -oraw &amp;#34;SELECT json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name) FROM header.csv&amp;#34; {&amp;quot;id&amp;quot;:&amp;quot;1&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Orange&amp;quot;} {&amp;quot;id&amp;quot;:&amp;quot;2&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Melon&amp;quot;} {&amp;quot;id&amp;quot;:&amp;quot;3&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Apple&amp;quot;} 階層を深くするには、json_object()を内部でさらに使います。 SQLite3にはjson_pretty()関数が無いので、jqで見やすくしています。
trdsql -ih -oraw &amp;#34;SELECT json_object(&amp;#39;fruits&amp;#39;, json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name)) FROM header.csv&amp;#34;|jq . { &amp;quot;fruits&amp;quot;: { &amp;quot;id&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Orange&amp;quot; } } { &amp;quot;fruits&amp;quot;: { &amp;quot;id&amp;quot;: &amp;quot;2&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Melon&amp;quot; } } { &amp;quot;fruits&amp;quot;: { &amp;quot;id&amp;quot;: &amp;quot;3&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;Apple&amp;quot; } } 上記の結果は1行1JSONで出力されています。これをさらに配列にして、一つのJSONにするには、SQLite3では json_group_array()、MySQLではjson_arrayagg()でグループ化して出力できます。
SQLite3 trdsql -ih -oraw &amp;#34;SELECT json_group_array(json_object(&amp;#39;fruits&amp;#39;, json_object(&amp;#39;id&amp;#39;,id,&amp;#39;name&amp;#39;,name))) FROM header.</description></item><item><title>trdsql JSON解析</title><link>https://noborus.github.io/blog/21_json_parse/</link><pubDate>Sat, 21 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/21_json_parse/</guid><description>これまでtrdsqlでは、JSONの入力が可能と書きましたが、例として書いたのは基本的にフラットな構造のJSONでした。 ただ、２階層以上の階層構造が含まれるJSONはエラーになる訳ではなく、そのまま文字列として扱われます。
以下のようなJSONがあるとします。
sample.json
[ { &amp;quot;color&amp;quot;: &amp;quot;white&amp;quot;, &amp;quot;category&amp;quot;: &amp;quot;value&amp;quot;, &amp;quot;code&amp;quot;: { &amp;quot;rgba&amp;quot;: [0, 0, 0, 1], &amp;quot;hex&amp;quot;: &amp;quot;#FFF&amp;quot; } }, { &amp;quot;color&amp;quot;: &amp;quot;red&amp;quot;, &amp;quot;category&amp;quot;: &amp;quot;hue&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;primary&amp;quot;, &amp;quot;code&amp;quot;: { &amp;quot;rgba&amp;quot;: [255, 0, 0, 1], &amp;quot;hex&amp;quot;: &amp;quot;#FF0&amp;quot; } }, { &amp;quot;color&amp;quot;: &amp;quot;blue&amp;quot;, &amp;quot;category&amp;quot;: &amp;quot;hue&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;primary&amp;quot;, &amp;quot;code&amp;quot;: { &amp;quot;rgba&amp;quot;: [0, 0, 255, 1], &amp;quot;hex&amp;quot;: &amp;quot;#00F&amp;quot; } } ] これをそのままtrdsqlを実行すると以下のようになります(見やすいように-oatを付けています。CSV出力にすると「&amp;quot;」が含まれる文字列のためエスケープされて出力されます。)
trdsql -oat &amp;#34;SELECT color,category,code FROM sample.json&amp;#34; +-------+----------+-----------------------------------+ | color | category | code | +-------+----------+-----------------------------------+ | white | value | {&amp;quot;hex&amp;quot;:&amp;quot;#FFF&amp;quot;,&amp;quot;rgba&amp;quot;:[0,0,0,1]} | | red | hue | {&amp;quot;hex&amp;quot;:&amp;quot;#FF0&amp;quot;,&amp;quot;rgba&amp;quot;:[255,0,0,1]} | | blue | hue | {&amp;quot;hex&amp;quot;:&amp;quot;#00F&amp;quot;,&amp;quot;rgba&amp;quot;:[0,0,255,1]} | +-------+----------+-----------------------------------+ このcodeは文字列の扱いですが、各データベースは既にJSONを扱える関数を備えているため、データベース側の関数を使って変更できます。</description></item><item><title>trdsql 日付・時刻処理</title><link>https://noborus.github.io/blog/20_date/</link><pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/20_date/</guid><description>ファイル内に入っている日付、時刻をそのまま扱う場合は良いですが、変換等の処理をしたい場合があります。
その場合は、一旦日付や時刻と解釈させてから扱う方が扱いやすくなります。
SQLite3の日付、時刻処理 デフォルトのSQLite3の日付、時刻処理では、以下のフォーマットであれば、日付、時刻として解釈することができます。 もしSQLite3のエンジンで処理したい場合は、このフォーマットにしておくと良いでしょう。
YYYY-MM-DD YYYY-MM-DD HH:MM YYYY-MM-DD HH:MM:SS YYYY-MM-DD HH:MM:SS.SSS YYYY-MM-DDTHH:MM YYYY-MM-DDTHH:MM:SS YYYY-MM-DDTHH:MM:SS.SSS HH:MM HH:MM:SS HH:MM:SS.SSS now DDDDDDDDDD 以下のようなログファイルのtimeを処理したい場合、
time:2015-09-06T05:58:05+09:00 method:POST ... time:2015-09-06T05:58:41+09:00 method:POST ... time:2015-09-06T06:00:42+09:00 method:GET ... datetime(time)で日時として、認識させれば、strftime()で再フォーマットがしやすくなります。
trdsql -iltsv &amp;#34;SELECT strftime(&amp;#39;%Y年%m月%d日%H時%M分%S秒&amp;#39;,datetime(time)) FROM log.ltsv&amp;#34; 2015年09月05日20時58分05秒 2015年09月05日20時58分41秒 2015年09月05日21時00分42秒 上記以外のフォーマットの場合は、SQLite3では文字列をまず書き換える必要があります。
PostgreSQLの日付、時刻処理 PostgreSQLの日付、時刻処理は、より豊富なフォーマットを処理できます。
多くの場合は、dateやtimestampにCASTするだけで、多くの有名なフォーマットは解釈されます。
trdsql -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; &amp;#34;SELECT to_char(CAST(time AS timestamp),&amp;#39;YYYY年MM月dd日HH24時MI分ss秒&amp;#39;) FROM log.ltsv&amp;#34; 2015年09月06日05時58分05秒 2015年09月06日05時58分41秒 2015年09月06日06時00分42秒 日付、時刻型に変換されるので、そこから表示するフォーマットに変換するにはto_char()を使用します。指定の仕方はマニュアルを参照して下さい。
さらに独特なフォーマットの場合は、 to_dateやto_timestampにより自分で定義したフォーマットで解釈させることが出来ます。
例えば上記で出力したフォーマットの場合、to_charと同じフォーマット指定でto_timestampを実行すれば逆にタイムスタンプとして扱われます。
trdsql -ih -oh -driver postgres -dsn &amp;#34;dbname=trdsql_test&amp;#34; &amp;#34;SELECT to_timestamp(\&amp;#34;日時\&amp;#34;,&amp;#39;YYYY年MM月dd日HH24時MI分ss秒&amp;#39;) FROM d.</description></item><item><title>trdsql Window関数</title><link>https://noborus.github.io/blog/19_window/</link><pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/19_window/</guid><description>これまでグループ集計による集計を紹介していますが、グループ集計は元の行とはまったく別にグループ毎の行を出力していました。 つまり、元のファイルとは別に集計の結果を出力していた訳です。
そうではなくて、元のファイルの情報にプラスして集計結果を出して欲しい場合があります。 例えば、点数の列では、点数の平均との差を出力したり、柔軟な計算が出来るようになります。これまでの方法では、一旦集計してからJOINするしかありませんでしたが、SQLのWindow関数を使うとそういった集計も出すことが出来ます。
古いバージョンではSQLite3では、Window関数を使用できませんでしたが、現在のtrdsqlに含まれているSQLite3では、Window関数を使用できます。
PostgreSQLやMySQLでもWindow関数が使用できますが、MySQLは8.0からなので、注意が必要です。
合計の表示 合計の計算は集計計算で出しましたが、最後の結果のみを出力していました。 Window関数では、行毎に結果を表示できます。
例えば、以下のような点数のCSVについて結果を表示してみます。
id,class,name,score 1,A,bob,174 2,A,alice,248 3,A,carol,163 4,B,dave,289 5,B,eve,157 6,B,flank,272 Window関数は集約関数の関数にOVER ()句を付けることにより範囲や、順序を指定することにより計算をおこないます。 OVER ()句があることで、他の列とは独立して対象の行以外を計算できます。
OVER()句を空で指定すると全行が対象となります。
trdsql -ih -omd \ &amp;quot;SELECT id,name,score, SUM(CAST(score AS int)) OVER () FROM score.csv&amp;quot; | id | name | score | sum | |----|-------|-------|------| | 1 | bob | 174 | 1303 | | 2 | alice | 248 | 1303 | | 3 | carol | 163 | 1303 | | 4 | dave | 289 | 1303 | | 5 | eve | 157 | 1303 | | 6 | flank | 272 | 1303 | SUM()で合計が求められるので、AVG()で平均も求められます。</description></item><item><title>trdsql 列の編集</title><link>https://noborus.github.io/blog/18_edit_columns/</link><pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/18_edit_columns/</guid><description>これまで列の並べ替えはしてきましたが、列の内容はそのままでした。 SQLでは、文字列の書き換えが得意分野とは言えませんが、SQLの関数を使うことにより、それなりできる機能は揃っています。
列の連結 「||」を使って、列名をつなげば、２つ以上の列を連結して一つの列になります。
trdsql -ih -oh \ &amp;quot;SELECT id,name||id AS name_id FROM header.csv&amp;quot; id,name_id 1,Orange1 2,Melon2 3,Apple3 列と列だけでなく、文字列をそのまま連結も可能です。SQLの文字列は「'」シングルクオートで括ります。
trdsql -ih -oh \ &amp;quot;SELECT id,name||'_'||id AS name_id FROM header.csv&amp;quot; id,name_id 1,Orange_1 2,Melon_2 3,Apple_3 PostgreSQL、MySQL またPostgreSQLとMySQLでは、複数の列をつなげたいときには concat(列名or文字列,列名or文字列,&amp;hellip;) が使用できます。
trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; -ih -oh \ &amp;quot;SELECT concat(id,name,'個') FROM header.csv&amp;quot; concat 1Orange個 2Melon個 3Apple個 接続文字を付けてつなげたい場合は、concat_ws(接続文字,列名or文字列,列名or文字列,&amp;hellip;)が使用できます。
trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; -ih -oh \ &amp;quot;SELECT concat_ws(' ',id,name,'個') FROM header.csv&amp;quot; concat_ws 1 Orange 個 2 Melon 個 3 Apple 個 SQLite3 SQLite3では、concat,concat_wsはありませんが、printfが使用できますので、より柔軟に文字列を生成できます。</description></item><item><title>trdsql ファイルとテーブルのJOIN</title><link>https://noborus.github.io/blog/17_file_table/</link><pubDate>Tue, 17 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/17_file_table/</guid><description>既にテーブルが存在するデータベースに接続することにより、ファイルとテーブルをJOINすることもできます。
例えば、データベース内にfruitsというテーブルがあった場合に、前回のabc.csvとJOINできます。
trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; \ &amp;quot;SELECT a.c1, a.c2, f.name FROM abc.csv AS a &amp;quot;\ &amp;quot;LEFT JOIN fruits AS f ON (CAST(a.c1 AS int) = f.id)&amp;quot; 1,AAA,Orange 2,BBB,Melon 3,CCC,Apple 例えば、データベース上にusersテーブルがあり、抽出したいリストがCSVファイルであった場合に、リストをWHERE user IN (...)で並べる等を検討するところですが、trdsqlではダイレクトにJOINして抽出できます。
list.csv
tarou jirou noborus usersテーブル
id,name 1,taizou 2,momo 3,tarou trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; \ &amp;quot;SELECT u.id, u.name FROM users AS u &amp;quot;\ &amp;quot;INNER JOIN list.csv AS l ON (u.name = l.c1)&amp;quot; 3,tarou 逆にCSVファイルにデータベースのテーブルから情報を足すといったことも考えられます。</description></item><item><title>trdsql JOIN</title><link>https://noborus.github.io/blog/16_join/</link><pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/16_join/</guid><description>これまで一つのファイルにSQLを実行してきましたが、複数のファイルをJOINするSQLも実行できます。
以下の2つのCSVファイルがあったとして、
abc.csv
1,AAA 2,BBB 3,CCC price.csv
1,100 2,500 3,50 以下のように連結するのが、JOINです。
1,AAA,100 2,BBB,500 3,CCC,50 trdsqlではテーブルの代わりにファイル名を使用すれば、そのままSQLのJOINが書けます。
trdsql &amp;quot;SELECT a.c1, a.c2, p.c2&amp;quot; \ &amp;quot;FROM abc.csv AS a&amp;quot; \ &amp;quot;LEFT JOIN price.csv AS p&amp;quot; \ &amp;quot;USING (c1)&amp;quot; 同じ件数で対応する同じ列がある1対1のJOINのため、INNER JOINと同じ結果になります。 LEFT JOINの場合は、先に指定したabc.csvの行はすべて表示され、price.csvは対応する行がある場合のみ表示されます。 今回はヘッダーがないCSVなので、列名はc1,c2&amp;hellip;の共通になるため、一番左側(c1)が共通の列としてUSINGを使用してます。これは ON a.c1 = p.c1 と同じ意味になります。
複数のCSVをJOINするときには、ヘッダーの有無を統一しておく必要があります。
しかしながら、自動判別可能な拡張子になっていれば、CSVとLTSV等の混在は可能です。
unit.ltsv
id:1 unit:個 id:2 unit:箱 先程のCSVのJOINの結果に更にLTSVをJOINします。
trdsql -oat \ &amp;quot;SELECT a.c1, a.c2, p.c2, unit&amp;quot; \ &amp;quot; FROM abc.csv AS a&amp;quot; \ &amp;quot;LEFT JOIN price.</description></item><item><title>trdsql DBインポート</title><link>https://noborus.github.io/blog/15_import/</link><pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/15_import/</guid><description>trdsqlにはデータベースにインポートするオプションはありません。 しかしながら、SELECT以外のSQLの実行も可能なので、SQLによるインポートが可能です。
以下は、メモリデータベースにインポートしても終了すると消えてしまうので、メモリデータベース以外のデータベースに接続して実行します。
CREATE TABLE AS テーブルを作成してインポートするには CREATE TABLE ASを使用します。
PostgreSQL で CREATE TABLE AS まず、PostgreSQLへデータをインポートしてみます。 これまで、SELECTで実行してきた内容に CREATE TABLE テーブル名 AS を前につければ、テーブルが作成されデータがインポートされます。
trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; -ih \ &amp;quot;CREATE TABLE test AS SELECT * FROM header.csv&amp;quot; 成功した場合、何も表示されずに終了します。失敗した場合、エラーが表示されます。
SELECTの結果がインポートされるため、SELECT側で列名の変更、列の型指定、インポートするデータの条件指定をすれば良いことになります。
trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; -ih \ &amp;quot;CREATE TABLE fruits AS SELECT id::int AS num, name::VARCHAR(20) FROM header.csv&amp;quot; trdsql -driver postgres -dsn &amp;quot;dbname=trdsql_test&amp;quot; -ih -oh\ &amp;quot;SELECT * FROM fruits&amp;quot; num,name 1,Orange 2,Melon 3,Apple もし、テーブルの作成のみを先にして、INSERTを後でおこないたい場合はWITH NO DATAを付けます。</description></item><item><title>trdsql SQLite3エンジンの使用</title><link>https://noborus.github.io/blog/14_sqlite3/</link><pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/14_sqlite3/</guid><description>SQLite3への接続方法を説明します。
SQLite3に接続 そもそもtrdsqlのデフォルトはSQLite3のメモリデータベースに接続していますが、メモリデータベース以外にも接続できます。
オプションの -driver に sqlite3 を指定し、-dsn にサーバーへの接続情報を指定します。
dsnはsqlite3のデータファイル名を指定すれば、そのファイルをデータベースとして使用します。 （ファイル名の指定の仕方はfile: や file:// 等も可能です）。
あらかじめファイルが無い場合もエラーにはなりません。
trdsql -driver sqlite3 -dsn &amp;#34;test.sqlite&amp;#34; -oat &amp;#34;SELECT * FROM test&amp;#34; +----+--------+-------+ | id | name | price | +----+--------+-------+ | 1 | Orange | 50 | | 2 | Melon | 500 | | 3 | Apple | 100 | +----+--------+-------+ さらに「?」で続けて、オプションを渡すこともできます。 メモリデータベースでオプションを渡すときには 「:memory:?」の後にオプションを続けて下さい。
例えば、LIKEで大文字小文字を区別するように変更するには以下のようにします。
デフォルトではLIKEは大文字小文字が区別されない。
trdsql -driver sqlite3 -dsn &amp;#34;:memory:&amp;#34; -ih &amp;#34;SELECT * FROM header.</description></item><item><title>trdsql MySQLエンジンの使用</title><link>https://noborus.github.io/blog/13_mysql/</link><pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/13_mysql/</guid><description>前回はPostgreSQL接続の話でしたが、今度はMySQLに接続して使用する方法を説明します。
MySQLに接続 MySQLに接続するには動作しているMySQLサーバーが必要です。接続できテーブルが作成できる権限があるデータベースを作成しておきます。
オプションの -driver に mysql を指定し、-dsn にサーバーへの接続情報を指定します。
MySQLのdsnは以下のような形式です。
ユーザー名:パスワード@プロトコル(ホスト名:ポート番号)/データベース名?param=value param=valueのパラメーターは多くの種類がありますので、go-sql-driverを参照して下さい。
UNIXドメインソケット ローカルホストのデフォルトのUNIXドメインソケットを使用する場合は、ユーザー名、パスワード、データベース名を指定すれば接続できます。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; UNIXドメインソケットのパスを指定するには、プロトコルにunixを指定して、unix(パス)で指定します。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@unix(/var/run/mysqld/mysqld.sock)/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; TCP接続 TCPはプロトコルにtcpを指定して、tcp(ホスト名:ポート番号)を指定します。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@tcp(localhost:3306)/trdsql_test&amp;#34; &amp;#34;SELECT 1&amp;#34; 実テーブルの出力 接続できれば、これまでと同じようにSQLが実行できますが、実際に実行されるのはMySQL上なので、MySQLが実行できるSQLを書く必要があります。
前回のPostgreSQLと同様にMySQLのテーブルに対してSQLを実行し、オプションで指定したフォーマットで出力することが出来ます。
trdsql -driver mysql -dsn &amp;#34;noborus:noborus@/trdsql_test&amp;#34; -oat -ih &amp;#34;SELECT * FROM actor LIMIT 10&amp;#34; +----------+------------+--------------+---------------------+ | actor_id | first_name | last_name | last_update | +----------+------------+--------------+---------------------+ | 1 | PENELOPE | GUINESS | 2006-02-15 04:34:33 | | 2 | NICK | WAHLBERG | 2006-02-15 04:34:33 | | 3 | ED | CHASE | 2006-02-15 04:34:33 | | 4 | JENNIFER | DAVIS | 2006-02-15 04:34:33 | | 5 | JOHNNY | LOLLOBRIGIDA | 2006-02-15 04:34:33 | | 6 | BETTE | NICHOLSON | 2006-02-15 04:34:33 | | 7 | GRACE | MOSTEL | 2006-02-15 04:34:33 | | 8 | MATTHEW | JOHANSSON | 2006-02-15 04:34:33 | | 9 | JOE | SWANK | 2006-02-15 04:34:33 | | 10 | CHRISTIAN | GABLE | 2006-02-15 04:34:33 | +----------+------------+--------------+---------------------+</description></item><item><title>trdsql PostgreSQLエンジンの使用</title><link>https://noborus.github.io/blog/12_postgres/</link><pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/12_postgres/</guid><description>trdsqlは組込みのSQLite3を利用してSQLを実行していますが、データベースの処理を別のデータベースに変更出来ます。
ここではPostgreSQLを使用する方法を説明します。
PostgreSQLに接続 SQLite3と違いPostgreSQLは動作しているPostgreSQLサーバーが必要です。接続できテーブルが作成できる権限があるデータベースを作成しておきます。
オプションの -driver に postgres を指定し、-dsn にサーバーへの接続情報を指定します。
dsnの項目には以下が指定できます。デフォルトの場合は省略可能です。
項目名 説明 dbname データベース名（デフォルト:ログインユーザー名） user ユーザー名（デフォルト:ログインユーザー名） password パスワード（デフォルト:なし） host ホスト名又はIPアドレス（デフォルト:localhost） port ポート番号(デフォルト: 5432) sslmode SSLモード（デフォルト: require） fallback_application_name （提供されない場合の）アプリケーション名（デフォルト:なし） connect_timeout 接続の最大待機時間 sslcert 証明書ファイルの場所 sslkey 秘密鍵ファイルの場所 sslrootcert ルート証明書ファイルの場所 項目=値をスペース区切りで指定します。
DSN指定 例えば、ローカルホストのportが5433でデータベース名がtrdsql_testに接続するには以下のようにします。</description></item><item><title>trdsql 処理の概要</title><link>https://noborus.github.io/blog/11_summary/</link><pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/11_summary/</guid><description>ここでtrdsqlの内部処理の概要を簡単に説明します。
trdsqlの内部処理は、以下のようになっています。
オプションやSQLコマンドの解釈 SQLコマンド内のファイル名をデータベースにインポート SQLの実行 指定された出力フォーマットで実行結果を出力 SQLの実行は実際のRDBMSを使用して実行されます（デフォルトではSQLite3のメモリデータベース)。
trdsqlはインポートとエクスポートの形式を整えているだけで、データベースに丸投げしているツールと言えます。
そのため、他の1行づつ処理するようなストリーミングができるツールとは違い、一旦全部のデータをインポートしてから実行されるため、非常に大きなデータではSQLの実行開始までに時間がかかります。
しかしながら、SQLライクではなく本当のSQLが使用できます。
これらの特徴を踏まえて使用すると良いでしょう。</description></item><item><title>trdsql 標準入力</title><link>https://noborus.github.io/blog/10_stdin/</link><pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/10_stdin/</guid><description>標準入力 trdsqlは他のUNIXツールのように標準入力からデータを受け取ることができます。ただSQLの文法上テーブル名を指定する必要があります。標準入力を使用するときは、「-」か「stdin」を使用します。
cat test.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; apple,100 orange,50 potato,30 trdsqlは標準入力から受け取りますが、標準入力をすべて受け取り終わってからSQLの実行が開始されます。 そのため終わらないコマンドからの出力を受け取ることはできません。 CSV、LTSV、JSONを出力するコマンドでは、ファイル名の代わりに標準入力を使えばそのまま利用できます。 例えば、文字コードがUTF-8でないファイルをUTF-8に変更してそのまま使用したり、
nkf -w sjis.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; 大きなファイルを処理する前に先頭の数行のみを処理して試してみたりできます。
head -100 big.csv|trdsql -icsv &amp;#34;SELECT * FROM -&amp;#34; それ以外にも、例えばUNIX系のコマンドでは、スペースを区切りとして解釈すればテーブルデータとして扱える出力をするコマンドが数多くあります。
例えば psコマンドでは、
ps PID TTY TIME CMD 1157 pts/3 00:00:00 ps 22590 pts/3 00:00:03 zsh のようにヘッダーがあり、それぞれの列を出力しています（trdsqlでは連続したスペースの区切り文字は一つとして解釈するように動作します）。
そのため、以下のように実行すると Ascii Table形式で出力できます。
ps|trdsql -ih -id &amp;#34; &amp;#34; -oat &amp;#34;SELECT \`PID\`, \`TTY\`, \`TIME\`, \`CMD\` FROM -&amp;#34; +-------+-------+----------+--------+ | PID | TTY | TIME | CMD | +-------+-------+----------+--------+ | 1363 | pts/3 | 00:00:00 | ps | | 1364 | pts/3 | 00:00:00 | trdsql | | 22590 | pts/3 | 00:00:03 | zsh | +-------+-------+----------+--------+ 標準入力の解析 また、trdsqlの-a解析オプションは標準入力も使用することが出来ます。</description></item><item><title>trdsql ワイルドカード、圧縮ファイル</title><link>https://noborus.github.io/blog/09_wildcard/</link><pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/09_wildcard/</guid><description>Wildcard ここまでは一つのファイルを対象としてきましたが、ログファイル等はローテートされて複数のファイルになっている場合があります。
同じ列で構成されている対象ファイルであれば、ワイルドカードを使用して、複数のファイルを一つのテーブルとして扱うことができます。
ls test*.csv test1.csv test2.csv test3.csv trdsql -icsv &amp;#34;SELECT COUNT(*) FROM test*.csv&amp;#34; 15 圧縮ファイル また古いログファイルは圧縮されている場合があります。[gzip, bzip2, zstd, lz4, xz]圧縮であれば自動で伸長して実行します。
trdsql -iltsv &amp;#34;SELECT * FROM access.log.2.gz&amp;#34; 圧縮ファイルとワイルドカードを組み合わせて実行することもできます。
ls access.log access.log.1 access.log.2.gz trdsql -iltsv &amp;#34;SELECT * FROM access.log.*&amp;#34;</description></item><item><title>trdsql Log集計</title><link>https://noborus.github.io/blog/08_log/</link><pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/08_log/</guid><description>Log集計 ApacheやnginxなどのLogをLTSVフォーマットで出力する方法も定着してきました。
そのようなLogをtrdsqlで解析する例です。
出力する側は、apacheのLogFormatの設定を以下のようにカスタマイズフォーマットにします。
LogFormat &amp;quot;host:%h\tident:%l\tuser:%u\ttime:%t\treq:%r\tstatus:%&amp;gt;s\tsize:%b\treferer:\%{Referer}i\tua:%{User-Agent}i&amp;quot; combined_ltsv host,ident,user,time,req,status,size,referer,uaの項目が出力されます。
実際のLogは以下のようになります。
host:176.99.192.42 ident:- user:- time:[21/Oct/2019:21:33:53 +0900] req:GET /category/software HTTP/1.1 status:200 size:138 referer:- ua:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0) host:192.54.157.102 ident:- user:- time:[21/Oct/2019:21:33:53 +0900] req:GET /item/electronics/4478 HTTP/1.1 status:200 size:60 referer:/category/sports ua:Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:9.0.1) Gecko/20100101 Firefox/9.0.1 host:88.60.137.115 ident:- user:- time:[21/Oct/2019:21:33:53 +0900] req:POST /search/?c=Games+Electronics HTTP/1.1 status:200 size:98 referer:/item/networking/929 ua:Mozilla/5.0 (iPhone; CPU iPhone OS 5_0_1 like Mac OS X) AppleWebKit/534.</description></item><item><title>trdsql GROUP集計</title><link>https://noborus.github.io/blog/07_group/</link><pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/07_group/</guid><description>GROUP集計 全体の合計を計算することもありますが、グループ毎の合計をまとめて出力したい場合もあります。 そこで使うのがGROUP BYです。
前回の例をもう一度使用します。
name,price apple,100 orange,50 melon,500 apple,90 apple,90 orange,40 orange,40 ここでappleやorange毎の合計を出したい場合は、以下のように検索条件で絞れば計算できますが、nameの種類の数だけ実行するとなると大変な作業になります。
trdsql -ih &amp;#34;SELECT name,SUM(CAST(price AS INT)) as sum FROM sample.csv WHERE name=&amp;#39;apple&amp;#39;&amp;#34; apple,280 trdsql -ih &amp;#34;SELECT name,SUM(CAST(price AS INT)) as sum FROM sample.csv WHERE name=&amp;#39;orange&amp;#39;&amp;#34; orange,130 そこでGROUP BYを使ってnameをグループとして扱うことで、それぞれの集計結果を求めることができます。
trdsql -ih &amp;#34;SELECT name,SUM(CAST(price AS INT)) as sum FROM sample.csv GROUP BY name&amp;#34; apple,280 melon,500 orange,130 前回の集計を少し変えてname毎に出すように出力してみます。 出力は-oat(Ascii Table)を使うと見やすく表示できます。
trdsql -ih -oat \ &amp;#34;SELECT name, COUNT(name) as count, MIN(CAST(price AS INT)) AS min, MAX(CAST(price AS INT)) as max, SUM(CAST(price AS INT)) as sum, AVG(CAST(price AS INT)) as avg FROM sample.</description></item><item><title>trdsql 集計計算</title><link>https://noborus.github.io/blog/06_calculation/</link><pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/06_calculation/</guid><description>集計計算 集計には、COUNT()だけでなく集計計算することも当然できます。SQLには数値に対して計算をおこなう集計関数があらかじめ揃っています。
ここでは以下のようなCSVファイルを例に説明します。
name,price apple,100 orange,50 melon,500 apple,90 apple,90 orange,40 orange,40 SUM 合計を計算します。price列をすべて足します。
trdsql -ih &amp;#34;SELECT SUM(price) FROM sample.csv&amp;#34; 910 前にも書いたようにtrdsqlは列をテキスト型として扱いますので、本来はCASTして数値型にしてから計算する必要があります。ただ、集計の関数を使用する場合は、暗黙のCASTがされて省略できる場合があります（使用するデータベースによります）。
明示的にCASTする場合は以下のようにします。
trdsql -ih &amp;#34;SELECT SUM(CAST(price AS int)) FROM sample.csv&amp;#34; 910 AVG 平均を計算します。合計/件数で計算できますが、関数が用意されているので、使用したほうがわかりやすく書けます。この例では、平均の意味はそれほどないかもしれませんが。
trdsql -ih &amp;#34;SELECT AVG(CAST(price AS int)) FROM sample.csv&amp;#34; 130 MIN,MAX 最小値や最大値を出力します。
trdsql -ih -oh &amp;#34;SELECT MIN(CAST(price AS INT)),MAX(CAST(price AS INT)) FROM sample.csv&amp;#34; MIN(CAST(price AS INT)),MAX(CAST(price AS INT)) 40,500 MINやMAXはテキスト型でも使用できるため、明示的にCASTする必要があります。</description></item><item><title>trdsql 集計</title><link>https://noborus.github.io/blog/05_aggregate/</link><pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/05_aggregate/</guid><description>COUNT(*) 最初はCOUNT(*)です。全体の件数を数えることが出来ます。
集計関数を使用すると元の行と列のデータは出力されず、そこから集計された結果が出力されます。
以下の例は結果が１行なので、CSVの様に見えませんが、1行1列(ヘッダー付き)のCSVとして出力されています。
単純に件数を数えるだけですが、ヘッダーと解釈して数に含まないか等の注意が必要です。 trdsql -icsv -ih -oh &amp;#34;SELECT COUNT(*) FROM header.csv&amp;#34; count(*) 3 検索条件の指定が出来ます。検索条件にあてはまる件数を知りたい時に使用します。
trdsql -icsv -ih -oh &amp;#34;SELECT COUNT(*) FROM header.csv WHERE id&amp;lt;&amp;#39;1&amp;#39;&amp;#34; count(*) 2 COUNT(列名) COUNT(列名) もよく使用します。RDBMSではNULLが除外されるので、COUNT(*)とは区別して使われます。
また、COUNTとDISTINCTを組み合わせると重複を省いた件数を出力できます。
以下のようなCSVファイルで実行してみます。
id,name 1,aaa 2,bbb 3,ccc 4,aaa trdsql -icsv -ih -oh &amp;#34;SELECT COUNT(name) FROM abc.csv&amp;#34; count(name) 4 trdsql -ih -oh &amp;#34;SELECT COUNT(DISTINCT name) FROM abc.csv&amp;#34; COUNT(DISTINCT name) 3 集計関数は一度に実行することもできます。</description></item><item><title>trdsql 簡単なSQL その２</title><link>https://noborus.github.io/blog/04_sql2/</link><pubDate>Wed, 04 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/04_sql2/</guid><description>検索条件 前回、列の並べ替え、抽出、行の並べ替えをしたので、今回は行の抽出です。 行を抽出するには、WHEREを付けて、検索条件を書きます。
前回と同じ例のファイルを使います。
trdsql -ih &amp;#34;SELECT id, \`name\` FROM header.csv WHERE id=1&amp;#34; 1,Orange SQLのメインな機能ですね。検索条件を書くだけで、該当する行を出力できます。
AND, OR AND や OR や ()括弧を使用することにより複雑な条件が書けます。
trdsql -ih &amp;#34;SELECT id, \`name\` FROM header.csv WHERE id=&amp;#39;1&amp;#39; OR id=&amp;#39;2&amp;#39;&amp;#34; 1,Orange 2,Melon trdsql -ih &amp;#34;SELECT id, \`name\` FROM header.csv &amp;#34; &amp;#34;WHERE (id=&amp;#39;1&amp;#39; OR id=&amp;#39;2&amp;#39;) AND \`name\`=&amp;#39;Orange&amp;#39;&amp;#34; 1,Orange 前回にも書いたようにtrdsqlでは、CSVやLTSV、JSONの値をtext型として扱っています。そのため、「=」の条件で書いているときには、暗黙のCASTが効いて型をそれほど意識しなくても良いですが、範囲を指定するときには結果が変わってしまうので、CASTする必要があります。
trdsql -ih &amp;#34;SELECT id,\`name\` FROM header.csv &amp;#34; &amp;#34;WHERE CAST(id as int)&amp;gt;1&amp;#34; 2,Melon 3,Apple SELECTを使用するときは、列の指定のところでCASTを使用して、そのCASTした列を指定して検索条件やORDER BYを書くことが出来ます。</description></item><item><title>trdsql 簡単なSQL</title><link>https://noborus.github.io/blog/03_sql/</link><pubDate>Tue, 03 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/03_sql/</guid><description>trdsqlと簡単なSQLを使用することで、他のUNIXツールを組み合わせて出来るようなことが一発で出来るようになります。
ファイル解析 SELECT * FROMから進んで簡単なSQLを実行する場合、あらかじめ列名を把握しておく必要があります。 trdsql に -aオプションにファイル名を付けて実行するとファイルを解析して情報を出力してくれます。
（CSVファイルの拡張子が.csvの様な場合は、-icsvを省略することが出来ます。-ih ヘッダを解釈、 -is スキップ数の指定等のオプションを必要に応じて付けないと意図しない解析結果になることがあります）。
trdsql -ih -a header.csv The table name is header.csv. The file type is CSV. Data types: +-------------+------+ | column name | type | +-------------+------+ | id | text | | \`name\` | text | +-------------+------+ Data samples: +----+----------+ | id | \`name\` | +----+----------+ | 1 | Orange | +----+----------+ Examples: trdsql -ih &amp;quot;SELECT id, \`name\` FROM header.</description></item><item><title>trdsql ファイルフォーマット変換</title><link>https://noborus.github.io/blog/02_convert/</link><pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/02_convert/</guid><description>trdsqlはCSV等のファイルをSQLで処理するツールとして説明していますが、単純にファイル形式を変換するツールとしても使用できます。
その場合、SQLは以下の定型句さえ覚えておけば、十分です。 ファイル内のすべての行と列を出力します。
SELECT * FROM ファイル名 後は、オプションとして入力形式(-i&amp;hellip;)と出力形式(-o&amp;hellip;)を指定してあげればファイル形式の変換が可能です。 CSV、LTSV、JSON等の相互変換ができます。
CSV(-icsv)からLTSV(-oltsv)への変換は以下のようにします。
trdsql -icsv -oltsv &amp;#34;SELECT * FROM ファイル名&amp;#34; CSV header CSVファイルはヘッダーに列名がついている場合 -ih でヘッダーを解釈して列名として使用できます。
header.csv
id,name 1,Orange 2,Melon 3,Apple trdsql -icsv -ih -oltsv &amp;#34;SELECT * FROM header.csv&amp;#34; &amp;gt; test.ltsv test.ltsv
id:1 name:Orange id:2 name:Melon id:3 name:Apple ヘッダーが無い場合は、列名はc1,c2,c3&amp;hellip;の連番になります。
LTSV入力 上記で出力されたLTSVを入力に使用すれば、CSVに戻ります。
trdsql -iltsv -ocsv -oh &amp;#34;SELECT * FROM test.ltsv&amp;#34; id,name 1,Orange 2,Melon 3,Apple 区切り文字の変更（TSV） また、CSVはComma-Separated Valuesではなく、Character-separated valuesとも呼ばれたりすることがあるように、区切り文字として「,」以外を使用できます。</description></item><item><title>trdsql インストール</title><link>https://noborus.github.io/blog/01_install/</link><pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate><guid>https://noborus.github.io/blog/01_install/</guid><description>概要 trdsqlはテーブル（表）形式のテキストに対してSQLを実行するCLIツールです。 テーブル形式とは、行と列で構成される以下のようなデータです。
1列 2列 1行 a1 a2 2行 b1 b2 結果をざまざまなフォーマットに出力できるので、テーブル形式データのフォーマット変換にも使用できます。
インストール Linux/Windows/macOSの場合は、GitHubのリリースページからバイナリをダウンロードできます。 Goで作られていて、他に依存ライブラリがない１バイナリなので、展開してすぐに実行できます。
Docker Dockerが使用できる環境であればDockerでも実行できます。Docker Hubからdocker pullも使用できるので、以下のようにしてpullしてください。
docker pull noborus/trdsql 入力ファイルの場所をマウントして使用して下さい。結果は標準出力に出るので、そのままリダイレクトで受け取れます。
カレントディレクトリにあるtest.csvに対して実行するときは以下のようになります。
docker run --rm -it -v $(pwd):$(pwd) --workdir $(pwd) noborus/trdsql &amp;#34;SELECT * FROM test.csv&amp;#34; &amp;gt; test_new.csv Homebrew macOSが無いので、実際には試していませんが、以下でインストールできるのではないかと思ってます。
brew tap noborus/trdsql brew install trdsql go get go のビルド環境があれば自分でビルドすることもできます。
go get -u -d github.</description></item></channel></rss>